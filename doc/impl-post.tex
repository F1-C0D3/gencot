The Cogent code generated for C expressions and statements in the first translation phase as described in 
Section~\ref{impl-ccode-cexpr} and~\ref{impl-ccode-cstats} is in general neither correct nor efficient.
Therefore it must be improved, which is done by postprocessing. The postprocessing is done directly in the Cogent AST.

This approach taken by Gencot has several advantages over generating the Cogent code in a single phase.
First, the actual translation step ist rather simple and straightforward. Second, the postprocessing
is done on a restricted subset of a purely functional language where
there is no difference between statements and expressions, so it tends to be simpler. Third, it can be separated
into arbitrary many different processing steps which can be freely combined, since they all process the same
data structures (the Cogent AST). The drawback is that the code generation is not very efficient, because it
first builds a quite voluminous code which is then simplified by the postprocessing. However, the quality 
of the resulting code has been considered more important than the performance of the Gencot translation.

In the following sections the postprocessing steps are described independently of each other and the last
section describes how they are combined.

Every postprocessing step corresponds to a transformation from a Cogent expression to a Cogent expression.
All required information is already present in the processed expression, in particular, the Cogent types
which have been added as described in Section~\ref{impl-ccode-type}. The C symbol table and other global state
information is not used. However, a postprocessing step may detect error situations. In this case usually a
dummy expression is inserted into the Cogent AST, as described in Section~\ref{design-cstats-dummy}, and an
error message is registered for display. For the latter the language-c \code{Trav} monad is used, as described
in Section~\ref{impl-ccode-trav}. Since no other global information is required, the monad is always used
with an empty user state and an empty symbol table. The type \code{ETrav} is defined in module
\code{Gencot.Cogent.Post.Util} for monads of this kind.

All postprocessing steps are defined in submodules of \code{Gencot.Cogent.Post}, they are either implemented
by a monadic action of the form
\begin{verbatim}
  Xproc :: GenExpr -> ETrav GenExpr
\end{verbatim}
or, if no error messages are generated, by a Haskell function of the form
\begin{verbatim}
  Xproc :: GenExpr -> GenExpr
\end{verbatim}

Postprocessing is applied to all expressions which occur in the generated Cogent program. These are function 
body expressions, the expressions in constant definitions, and the expressions in array type size specifications.

\subsection{Restricted Form of the Cogent AST}
\label{impl-post-ast}

The Cogent AST generated by the translation described in Sections~\ref{impl-ccode-cexpr} and~\ref{impl-ccode-cstats}
is highly restricted: it only uses some of the constructs and uses them in specific restricted form. The postprocessing
implementation exploits these restrictions and most postprocessing steps preserve them for being exploited by following
steps.

The Cogent AST types are defined in the Cogent implementation in module \code{Cogent.Surface}. Syntactic expressions
are defined by the datatype \code{Expr}. Gencot only uses the following expression variants: \code{Unitel} for the unit
expression, \code{IntLit, BoolLit, CharLit, StringLit} for literals, \code{Var} for variable references, \code{Tuple}
for tuple expressions, \code{PrimOp, App} for applications of operators and functions, \code{Upcast} for application
of the \code{upcast} operator, \code{Match, If} for conditional
expressions, \code{Let} for expressions with variable bindings, \code{Lam} for lambda expressions, \code{TLApp} for
specifying instances of polymorphic functions, \code{Member} for record member accesses, \code{Put, ArrayPut} for record
and array put operations, and \code{UnboxedRecord} for unboxed record structures.

The variants \code{BoolLit, Upcast, Match, Member} are only inserted during postprocessing. The variant \code{TLApp} is only
used for specifying instances of the Gencot operations which are usually polymorphic. The variants \code{UnboxedRecord}
and \code{Lam} are only used for specifying the arguments of the \code{repeat} operation in translations of loops.

Bindings in \code{Let} expressions mainly consist of a pattern defined by the datatype \code{IrrefutablePattern} and
the expression bound to the pattern. Gencot only uses the following pattern variants: \code{PUnitel} for the unit
pattern, \code{PVar} for a variable, \code{PTuple} for a tuple pattern, \code{PTake} and \code{PArrayTake} for
\code{take} operation patterns, and \code{PUnderscore} for the wildcard pattern.

Additional restrictions are the following. Here a ``variable tuple'' means either a \code{Tuple} expression where all
sub expressions are \code{Var} expressions or a single \code{Var} expression. A ``control tuple'' means either a
\code{Tuple} expression where the first sub expression is an \code{IntLit} expression and the other sub expressions
are \code{Var} expressions or a single \code{IntLit} expression. A ``variable pattern'' means a \code{PVar}, \code{PUnitel},
or \code{PUnderscore} pattern or a \code{PTuple} pattern with components of these variants. A ``take pattern'' means
a \code{PTake} or \code{PArrayTake}.

All patterns are either variable patterns or take patterns.

The body of a \code{Let} expression is either a variable or control tuple or an \code{If} or \code{Match} expression.
The branch of an \code{If} or \code{Match} expression is either a variable or control tuple or a \code{Let} expression.
The body of a \code{Lam} expression is a \code{Let} expression or an operator application.

The arguments of a \code{PrimOp} expression and the argument of an \code{Upcast} expression are single \code{Var} expressions.
The argument of an \code{App} expression
is a variable tuple. The only exception are applications of the Cogent standard library function \code{repeat} which
is used for translating loops and where the argument is an \code{UnboxedRecord}.

In a \code{Put} or \code{ArrayPut} expression the container expression is a \code{Var} expression and the list of put
specifications contains a single element where the put value is specified by a \code{Var} expression. In an \code{ArrayPut}
the put index is also specified by a \code{Var} expression. In a take pattern the list of take specifications contains
a single element where the taken value is specified by a \code{PVar} pattern. In an \code{ArrayTake} the take index is
specified by a \code{Var} expression.

Together, the structure of arbitrary deep syntax trees only consists of \code{Let}, \code{If}, and \code{Match} expressions
where all leaf expressions are variable or control tuples. All other expression variants only occur as bound expression in
a binding and have as subexpressions only variable and control tuples with the following exceptions:
\begin{itemize}
\item in an \code{App} expression the function subexpression may be a \code{TLApp} expression and the argument subexpression
may be an \code{UnboxedRecord} expression,
\item in an \code{UnboxedRecord} expression the subexpressions may be arbitrary expressions,
\item in a \code{Lam} expressions the body subexpression may be a \code{Let} or \code{PrimOp} expression.
\end{itemize}
In all these exception cases the type of the expression is fully determined by the type of the subexpression, so no type
clashes may occur between the subexpressions and their context. Expressions for unboxed records are only used in the translation
of loops as argument for the \code{repeat} operation. The type of the record is always determined from the types of the
specified component values, the type of the \code{repeat} instance is determined from this record type.

For simplicity, Gencot strictly avoids introducing additional value variables or other variables during postprocessing.

\subsection{Evaluating Constant Expressions}
\label{impl-post-const}

In several cases the original translation phase or postprocessing steps result in constant expressions built
from predefined operators. Such expressions can be statically evaluated and the resulting constant then may
enable other postprocessing steps. Therefore a constant expression evaluation is defined as auxiliary 
function for other postprocessing steps. It never detects and signals an error. Therefore it is implemented
by the function
\begin{verbatim}
  evalproc :: GenExpr -> GenExpr
\end{verbatim}
defined in module \code{Gencot.Cogent.Post.Simplify}.

The \code{evalproc} step is not applied on its own to arbitrary expressions. The reason is that a constant
expression may be intentionally present in the C program to show how a value is calculated. In that case the 
translation should also result in a constant expression in Cogent. Only if the evaluation is useful for other 
postprocessing steps it is applied.

The \code{evalproc} step only processes operator expressions. For them it recurses into the arguments. If all arguments
are constants it evaluates the operator and replaces the expression by the resulting constant. All other forms
of expressions are left unmodified, in particular, \code{evalproc} does not recurse into subexpressions which are
not operator applications.

\subsection{Simplifying Operator Application}
\label{impl-post-op}

If an expression cannot be completely evaluated statically, there are cases where it can be simplified.
The following cases are implemented by Gencot postprocessing.

If the first argument of a boolean operation evaluates to a constant the operation can be simplified according 
to the rules
\begin{verbatim}
  True  || e --> True
  False || e --> e
  True  && e --> e
  False && e --> False
\end{verbatim}
Currently only the first argument is treated this way, because only that case occurs in actual examples of translation
and postprocessing, mainly for the translation of \code{switch} statements.

Simplifying operator expressions using these rules never detects and signals an error, therefore is implemented by the function
\begin{verbatim}
  opproc :: GenExpr -> GenExpr
\end{verbatim}
defined in module \code{Gencot.Cogent.Post.Simplify}.

\subsection{Simplifying \code{let}-Expressions}
\label{impl-post-let}

One of the simplest and most straightforward postprocessing steps is substitution of bound variables by the
expression bound to them. In Cogent variables can be bound by \code{let} expressions and by \code{match} and \code{lambda}
expressions. Variables bound in \code{match} and \code{lambda} expressions can usually only be substituted in special cases, 
therefore this processing step only substitutes variables bound in \code{let} expressions. 

The basic transformation is for an expression
\begin{verbatim}
  let v = expr1 in expr2
\end{verbatim}
to replace it by \code{expr2} where every free occurrence of \code{v} is substituted by \code{expr1}. This is only 
possible if after the substitution all free variables in \code{expr1} are still free in the resulting expression, i.e., 
they are not ``drawn under a binding'' in \code{expr2}. This could be avoided by consistent renaming of variables bound in 
\code{expr2}. Gencot never renames variables and does not substitute in this case.

The Gencot translation may produce code where the types of \code{v} and \code{expr1} differ. Then the type differences are
resolved by postprocessing, as described in Section~\ref{impl-post-types}. If the substitution would be performed before,
it may be more difficult to resolve the difference, because the variable and its type have been eliminated and the type
difference may now occur between \code{expr1} and its context in \code{expr2} at several places. Therefore Gencot performs
the substitution only if the types of \code{v} and \code{expr1} are the same.

This scheme can directly be extended to expressions of the form \code{let v1 = e1 and ... vn = en in e} using the
equivalence to an expression of the form \code{let v1 = e1 in let ... in let vn = en in e}.

As of February 2022, Cogent does not support closures for lambda expression. This means that a lambda expression must not
contain free variables, therefore lambda expressions in \code{expr2} are never inspected for substituting.

In a Cogent \code{let} expression instead of a variable \code{v} an (irrefutable) pattern \code{p} can be used:
\begin{verbatim}
  let p = expr1 in expr2
\end{verbatim}
An irrefutable pattern
is a variable or wildcard or it is a pattern for a tuple, record, array or the unit value were the components are again
irrefutable patterns. In other words, it is a complex structure of variables which is bound to an expression \code{expr1}
of a type for which the values have a corresponding structure. Every variable may occur only once in a pattern.

Currently, the translation phase only creates bindings with patterns which are either a single variable, or a flat tuple pattern where
all components are variables, or a take pattern where all sub patterns are variables. The postprocessing does not
introduce more complex patterns. However, to make the code more robust, these restrictions are not assumed for binding processing,
the processing is always implemented to work for arbitrary patterns.

If the pattern occurs as a whole in \code{expr2} it can be
substituted by \code{expr1} as described above. If only parts of the pattern occur (such as a single variable) it depends
on the structure of \code{expr1} whether such a part can be substituted. Gencot tries to substitute as much parts as possible 
and only retains those parts of the pattern for which a substitution is not possible.

If the substitution is successful the \code{let} expression is replaced by \code{expr2} which may again be a \code{let}
expression or any other kind of expression. Therefore the simplification may reduce the number of \code{let} expressions
and may replace a \code{let} expression by an expression of another kind.

Substitution of bound variables may lead to exponentially larger code, which must be avoided. Gencot uses an expression metrics
which roughly measures the size of the printed expression in the Cogent surface syntax. A binding is only substituted if the 
resulting expression is not much larger than the original \code{let} expression.

Simplifying a \code{let} expression by substitution can reduce the variables which occur free in it. This is the case if no
parts of the pattern \code{p} occur free in \code{expr2}, then \code{expr1} is removed and all variables which only occur free
in \code{expr1} are removed with it.

Simplifying \code{let} expressions can never detect and signal an error, therefore it is implemented by the function
\begin{verbatim}
  letproc :: GenExpr -> GenExpr
\end{verbatim}
defined in module \code{Gencot.Cogent.Post.Simplify}.

\subsubsection{Processing Subexpressions}

When an expression \code{let p = expr1 in expr2} is simplified, first the subexpressions \code{expr1} and \code{expr2} are
simplified by processing all contained \code{let} expressions. Simplifying \code{expr1} has the following advantages for the 
substitution:
\begin{itemize}
\item The resulting expression usually is smaller. Then its substitution into \code{expr2} leads to a lower increase of
size and may be allowed whereas substitution of the original \code{expr1} would not be accepted.
\item Simplifying may reduce the free variables so that it may be possible to substitute it in more places than
the original expression without drawing free variables under a binding.
\item If \code{expr1} is again a \code{let} expression the pattern can only be substituted as a whole. After simplification 
it may have a form which corresponds more with the pattern so that also parts of the pattern can be substituted.
\end{itemize}
Simplifying \code{expr2} has the following advantages for the substitution:
\begin{itemize}
\item Simplifying may reduce the free variables so that there are fewer places for substituting the pattern
or parts of it. This may allow substitutions of patterns which where not possible in the original \code{expr2}.
It may also allow substitutions which would have lead to a too large growth of the original \code{expr2}.
\end{itemize}

Since an expression \code{let p1 = expr1 and p2 = expr2 in expr3} is equivalent to \code{let p1 = expr1 in (let p2 = expr2
in expr3)} this means that a sequence of bindings connected by \code{and} in a \code{let} expression is processed
from its end backwards.

\subsubsection{Pattern Substitution}

If (after its simplification) \code{expr1} has the same structure as the pattern \code{p} the binding could be split and 
the parts could be substituted independently. This would correspond to the transformation of the binding \code{p = expr1}
to the sequence 
\begin{verbatim}
  p1 = expr11 and ... pn = expr1n
\end{verbatim}
where the \code{pi} are the subpatterns of \code{p} and the \code{expr1i} are the corresponding subexpressions of \code{expr1}.
Note that the variables in the \code{pi} are pairwise disjunct since every variable may occur only once in \code{p}.
Then the sequence could be processed from its end, as described above.

However, the transformation is only correct, if no variable in \code{pi} occurs free in an expression \code{expr1j} with 
\code{j > i}, otherwise the transformation would draw it under the binding \code{pi = expr1i}. It could be tried to sort
the bindings to minimize this problem but in general it cannot be avoided. Additionally, there may be cases where \code{expr1}
even after its simplification has no structure corresponding with that of \code{p}, which also prevents the transformation.

For this reason, instead of transforming the binding and substituting it sequentially, Gencot deconstructs the pattern while
searching for matches. Whenever it searches the binding \code{p = expr1} in an expression (starting with \code{expr2}) 
it determines the variables occurring free in the expression and ``reduces'' the binding to these. Reducing a binding to
a set of variables is done by first replacing in \code{p} all variables which are not in the set by a wildcard (underscore) 
pattern. This is always possible. Then it is tried to remove as much wildcard parts from the binding, this is only possible if
the corresponding part can be removed from \code{expr1}.

If \code{p} is a tuple pattern where some components are wildcards
they can be removed if \code{expr1} is a corresponding tuple expression. If \code{expr1} is an application of a function to
an argument the wildcard parts cannot be removed, since the tuple returned by the function is not available.
If \code{expr1} is a \code{let} or \code{if} expression or a \code{match} expression the binding cannot be reduced or split directly.
In these cases Gencot constructs the reduced or split binding by recursively reducing or splitting the subexpressions (the
let-body, the if-branches, the match-alternatives).

If no variable in the set occurs in the pattern all variables are replaced by wildcards and the binding is reduced to the
empty binding, represented by the ``unit binding'' \code{() = ()}.

If after reducing it the binding is not empty, it is matched with the expression, which is successful if it has the same structure with the same
variables (which is only possible if the pattern contains no wildcards). If it matches the search stops, if not the binding 
is searched recursively in all subexpressions (by first reducing it to the subexpression). When the search reaches a single 
variable, the binding has been reduced to that variable. If the pattern consists of the same variable it matches there.

Otherwise the pattern is empty or it contains the variable together with other parts which means that it cannot be used to substitute the 
variable at that position in the expression. In this case at least the binding for that variable must be retained. Gencot 
determines all variables in \code{expr2} for which that is the case. Then it reduces the original binding \code{p = expr1}
to that set to determine the binding \code{p' = expr1'} which must be retained in the \code{let} expression. Only if no
such variable exists the binding can be completely removed from the \code{let} expression.

If \code{p} contains a \code{take} pattern for a record or array it can only match a \code{put} subexpression 
of exactly the same form in \code{expr2}. That is only present if the component is taken and put back without modifying it or the 
remaining record or array. In this case the \code{put} expression is replaced by the part of \code{expr1} corresponding to 
the \code{take} pattern. Wildcards in a \code{take} pattern can only be removed if the corresponding part of \code{expr1}
is a \code{put} expression.

Even if a part of the binding successfully matches in \code{expr2}, substitution may be prevented because it would draw a 
free variable in \code{expr1} under a binding. Such a binding may be the retained part of the original binding or it may 
be a binding in a \code{let} subexpression which has been retained during the simplification of \code{expr2}
or it may be a binding in a \code{match} expression which is not processed by the simplification. These cases are handled
by splitting the binding for which matches are searched whenever it is drawn under another binding in a (maximal) part allowed
to draw under the binding and a rest which must be retained. The rest is still searched under the binding to determine whether
the variables in it occur at all, if that is not the case it is not required in the expression and is not retained.

A binding is split according to a set of variables not to occur free by first determining all bound variables so that the 
corresponding part of the bound expression contains a free occurrence of a variable from the set. Then the binding is reduced
to this set and to its complement, yielding the binding to retain and the binding for substitution.

The substitution and binding simplification is implemented in two phases. In the first phase the matches for the pattern are 
searched in \code{expr2}, resulting in the part to be retained and for every matching part the number of successful matches
The matching parts are actually substituted in \code{expr2} in the second phase. If the retained part is not empty it is 
prefixed to the result.

\subsubsection{Banged Variables}

A binding may have ``banged'' variables, i.e., be of the form
\begin{verbatim}
  p = expr1 !v1 ... !vn
\end{verbatim}
which makes the variables \code{v1,...,vn} readonly in \code{expr1}. Banged variables are introduced by readonly processing 
(see~\ref{impl-post-readonly}). Simplification of \code{let}-expressions may be executed after readonly processing, therefore it
must deal with banged variables.

In Cogent banged variables can only appear at specific places in the code: in a \code{let} binding, in a \code{match}-expression, 
and in the condition of an \code{if}-expression. Therefore it is in general not possible to substitute (a part of) the pattern \code{p}
at arbitrary occurrences in \code{expr2} by \code{expr1} together with the banged variables. Gencot never tries, it retains those
parts of the binding in which the banged variables occur free in \code{expr1}.

The same mechanism for splitting a binding used to prevent drawing variables under a binding is used for banged variables. Whenever
a binding is split, the banged variables are added to the set of variables not to occur free.

\subsubsection{Growth Restriction}

As size metrics for an expression the number of characters appearing in its surface representation is used. It could be determined
by actually prettyprinting the expression and measuring the size of the resulting string. However, it is assumed to be more
efficient to traverse the expression and calculate the size from the number of characters in the names and literals and in
the keywords, special characters and separating blanks needed for constructing composed expressions.

After the first phase the metrics of the \code{let} expression is calculated. Since for each matching part to be substituted it 
has been determined in the first phase how often it occurs in \code{expr2} the metrics for the simplified expression can be 
calculated and it is known how much each subpattern contributes to its size. If the size is larger than for the original 
expression and its growth exceeds a fixed limit factor additional binding parts are determined which are retained. 
Beginning with the binding part with the largest contribution, parts are retained until the growth is below the limit.

Instead of only taking its contribution to the size into account, binding parts could also be selected according to the kind of
variables they contain. 
Gencot uses different kinds of variables in its generated code (see Section~\ref{impl-ccode-cexpr}): value variables, component
variables, the control and result variables, and variables corresponding to C object names. These could be prioritized
as follows: first as many value 
variables are substituted as possible in a complete expression, then the control variables, then the component variables and
finally the C object names. In this way the most ``technical'' variables are substituted before the more ``semantical''.

The reference metrics is calculated for the expression after simplifying its subexpressions. This means that the growth limit factor
applies to every subexpression simplification step separately. This has two implications. First, a subexpression simplification
may strongly reduce the size of the subexpression and that may also reduce the size of the \code{let} expression, which becomes 
the reference for its own simplification. Thus it is not possible to tolerate a larger growth after strongly reducing the size for
subexpressions. Alternatively, the reference size could be measured before simplifying the subexpressions. In the code generated
by Gencot there are typically large nestings of \code{let} expressions with unnecessary ``chain bindings''. It is assumed that it
does not yield good results when these unnecessary large expressions are used as reference, therefore Gencot uses the first approach.

Second, in the worst case each simplification step grows the expression by the limit factor which still results in an overall exponential growth
relative to the number of subexpressions. Therefore the growth limit factor should not be much larger than 1. The effect of this
factor and a good selection for it must be determined by practical tests. Alternatively the factor could be specified as an input 
parameter for Gencot so that it can be selected specifically for every translated C program.

\subsubsection{Variables of Linear Type}

If a variable of linear type occurs free in \code{expr1} and \code{expr1} is substituted more than once in \code{expr2} this
usually results in a ``double use'' of the variable, which is not allowed in Cogent. Therefore Gencot tests for this situation
and retains the (parts of) the binding which would cause a double use error when substituted.

More specifically, a double use error only results if the expression is substituted more than once in the same alternative
execution branch, i.e., in the same branch of an \code{if} expression or the same alternative of a \code{match} expression.
When Gencot counts matches of (sub)patterns of \code{p} in \code{expr2} it also counts the maximal number of matches in an
alternative execution branch. It then uses this count to decide whether the corresponding part of the binding must be retained
to avoid double use errors.

\subsubsection{Pre-Simplifying Unused Variables}

If in an expression
\begin{verbatim}
  let p = expr1 in expr2
\end{verbatim}
a variable bound in \code{p} does not occur free in \code{expr2} it can be removed from the binding \code{p = expr1} as described above,
without substituting it in \code{expr2}. This case is much simpler than the general case described above in several aspects:
\begin{itemize}
\item it is not necessary to search for matchings in \code{expr2},
\item it is not possible to draw free variables in \code{expr1} under a binding,
\item the expression will never grow by the simplification,
\item type differences between \code{p} and \code{expr1} do not matter.
\end{itemize}

The Gencot translation produces many such cases of unused variables, because it translates expressions without regarding whether
their values are used in the context. For example, the value of an assignment expression is normally not used in the context. On the
other hand unused variables may prevent resolving a type difference by banging, if the variable has non-escapeable type (possibly
caused by the banging itself) and leaves the scope of the banging. Therefore it is crucial to remove bindings of unused variables
early during postprocessing, in particular, before trying to apply banging, whereas normal simplification of \code{let} expression
is only done after resolving type differences. Early removal of unused variables is called pre-simplification here.

An exception is made for \code{put} operations. Every \code{put} binding is always generated together with a preceding \code{take}
binding and both are usually also processed together (see Section~\ref{impl-post-takeput}). If only the component variable of a
\code{take} binding is used but not the container variable, pre-simplification would remove the \code{put} binding and would preserve
the \code{take} binding. Since the \code{put} bindings do not affect the banging possibilities, they are excluded from
pre-simplification. Since every \code{put} binding uses both the container and component variable of the corresponding \code{take}
binding, that will always be preserved as well.

Pre-simplification is facilitated by implementing the removal of unused variables in a separate postprocessing step
\begin{verbatim}
  presimp :: GenExpr -> GenExpr
\end{verbatim}
also defined in module \code{Gencot.Cogent.Post.Simplify}. Thus it can be applied independently from \code{letproc}. Note, that
\code{letproc} will still remove variables which have become unused by other postprocessing steps after applying \code{presimp}.

\subsection{Simplifying If-Expressions}
\label{impl-post-if}

The most straightforward simplification of a conditional expression is replacing it by one of the branches, if the condition can be
statically evaluated. Gencot tries this, by recursing into the condition and then using \code{evalproc} (see Section~\ref{impl-post-const})
for evaluating the condition, before it recurses into the branches. This avoids processing a branch which is removed afterwards. 
If the condition cannot be statically evaluated, both branches are processed recursively.

\subsubsection{Other Used Transformations}

Afterwards, the following additional simplification rules are applied, if possible.
\begin{itemize}
\item If both branches are the same expression, the conditional expression is replaced by this expression.
\item If both branches statically evaluate to a boolean constant, the conditional expression is replaced
by the condition or the negated condition according to the rules
\begin{verbatim}
  if c then True else False --> c
  if c then False else True --> not c
\end{verbatim}
\item The condition is substituted by \code{True} in the \code{then} branch and by \code{False} in the \code{else} branch. This 
may enable additional simplifications in subsequent iterations (see Section~\ref{impl-post-combine}).
\end{itemize}

The following rule is applied to operator expressions where the first argument is a conditional expression and the second argument
can be statically evaluated:
\begin{verbatim}
  (if c then e1 else e2) <op> e -->
  if c then e1 <op> e else e2 <op> e
\end{verbatim}
This transformation may enable the static evaluation of the resulting branches. 

All these rules have been selected, because they specifically apply to conditional expressions resulting from the Gencot translation
and postprocessing, in particular for the control variable.

Simplifying \code{if} expressions using these rules never detects and signals errors, therefore it is implemented by the function
\begin{verbatim}
  ifproc :: GenExpr -> GenExpr
\end{verbatim}
defined in module \code{Gencot.Cogent.Post.Simplify}.

\subsubsection{Unused Transformations}

Other rules would transform conditional expressions where one branch can be statically evaluated to a boolean value according to
\begin{verbatim}
  if c then True else e  --> c || e
  if c then False else e --> not c && e
  if c then e else True  --> not c || e
  if c then e else False --> c && e
\end{verbatim}
This is not used, because it removes boolean constants which may be useful for static evaluation after other processing steps.

Other rules for simplifying conditionals with boolean values are
\begin{verbatim}
  if c then e else not e --> c == e
  if c then not e else e --> c /= e
\end{verbatim}
These are not used because they turn conditional expressions into equations, which currently are not processed any further.

If a branch is again a conditional expression, the following transformation is possible:
\begin{verbatim}
  if c then (if c' then e1 else e2) else e -->
  if c' then (if c then e1 else e)
        else (if c then e2 else e)
\end{verbatim}
It is not used because it duplicates expression \code{e} and does not reduce the structure of conditional expressions,
so there is the danger of cyclic transformation.

Another rule would split conditional tuples into a tuple of conditionals according to
\begin{verbatim}
  if c then (t1,..,tn) else (e1,..,en) --> 
  (if c then t1 else e1, .., if c then tn else en)
\end{verbatim}
which would allow further simplification for all components with \code{ti = ei} and it could allow additional substitutions
by \code{letproc}, because the components can be substituted or omitted separately. However, if both are not applicable, it 
tends to enlarge the expression by copying the condition \code{c}. Therefore the effect on \code{letproc} has been implemented
there by the way how conditional expressions are split and the rule is not used here for \code{ifproc}.

The substitution of the condition in the branches could be generalized by substituting values for variables which can be
inferred from the condition, such as in
\begin{verbatim}
  if i == 0 then e1 else e2
\end{verbatim}
where it is possible to substitute \code{i} by \code{0} in \code{e1}. Even more general, the condition can be interpreted as
a set of equations for its free variables, if it can be solved for some of them they can be substituted by their solution
in the first branch. It has not yet been considered whether such substitutions would have an effect that would pay for the 
additional complexity.

If the condition is itself a conditional expression, it may be possible to derive substitutions, although the condition does
not occur as a whole in the branches. As an example, the following transformation could be applied:
\begin{verbatim}
  if (if c then x else y) 
     then (if c then (if x then e1 else e2) else e3) 
     else e4 
  -->
  if (if c then x else y) 
     then (if c then e1 else e3)
     else e4
\end{verbatim}
It has not yet been considered, whether such transformations would be useful for cases occurring during translations of C programs.

\subsection{General Type Difference Processing}
\label{impl-post-types}

Even if the translated C program is type-correct, the Gencot translation may result in type incompatibilities in the generated
Cogent code. These originate from three possible sources:
\begin{itemize}
\item Type differences in the C program which are automatically resolved by the C compiler by conversions.
\item Application of item properties which affect the item's type during the Gencot translation.
\item Type bool and arithmetic types, which are different in Cogent but not in C.
\end{itemize}

The first case only occurs for C operators. They are conceptually polymorphic, the actual function is determined by the type
of the argument(s). For binary operators the argument types may be different, then in some cases they are adapted to a common
type which then determines the function of the operator. The same holds for the ternary conditional operator for the two
branches. Operators in C are either arithmetic, relational or comparison operators or the conditional operator. The first
two kinds are only applied to numeric arguments. Since Gencot does not support floating point types only integer arguments
are relevant here. The comparison operators \code{==} and \code{!=} can also be applied to pointer arguments and the branches
of a conditional operator can be of arbitrary type. In some cases the type differences can also be resolved in Cogent by
applying conversion functions, in other cases Gencot does not support a translation and signals an error.

The second case may occur for the item properties Read-Only, Not-Null, and No-String. All three only affect items of pointer
types. Since they may be specified manually, differences may be errors which should be detected and signaled by Gencot. In some
cases it is also possible to resolve differences by inserting conversions during postprocessing.

The third case may occur whenever an expression or context is recognized as boolean, which is the case for the result of
comparison operators and for the condition in conditional expressions and statements.

Gencot preserves the restricted form of the Cogent AST described in Section~\ref{impl-post-ast} until all these type clashes
have been resolved. Therefore type clashes need only be detected and handled in the restricted form of expressions. This form
mainly consists of a tree structure built from \code{Let}, \code{If}, and \code{Match} expressions where all leaf expressions
are variables, possibly wrapped in tuples. In these cases (except for conditions in \code{If}-expressions and branches in \code{If}
and \code{Match} expressions) and also for the exceptions listed in Section~\ref{impl-post-ast} the type of an expression is
always determined from the type(s) of the subexpressions, therefore no type clashes can occur.

The remaining cases where type clashes may occur are conditions in \code{If}, \code{Match}, and bindings in \code{Let}:
\begin{enumerate}
\item For a branch in an \code{If} or \code{Match} the type may be different from the expected type which may be determined
by both branches together.
\item For a condition subexpression the type may be different from the expected type \code{Bool}.
\item For the bound expression in a binding the type of a subexpression may be different from the expected type. The following
cases for subexpressions exist:
\begin{itemize}
\item argument of an operator (list of variables) or function application (tuple of variables), then the expected type for
each variable is determined by the operator or by a formal argument type of the function,
\item container variable in a \code{Put} or \code{ArrayPut}, then the expected type is a writable not-null container with
the specified component,
\item index in an \code{ArrayPut}, then the expected type is a numeric type,
\item condition in an \code{If} expression, as above.
\end{itemize}
If the subexpression is a branch in an \code{If} or \code{Match} expression the bound expression is treated separately
as in case 1 above.
In all other cases of subexpressions (container of a \code{Member}, function in an \code{App}, body in a \code{Lam} or \code{Let})
no type clashes can occur. An expression for a component value in a \code{put} operation is always the corresponding component
variable for which the type has been determined by the component type, so no type clash can occur here.
\item For a pattern in a binding the type of a subpattern or subexpression may be different from the expected type. The following
cases exist:
\begin{itemize}
\item container variable in a \code{Take} or \code{ArrayTake}, then the expected type is a writable not-null container with
the specified component,
\item index in an \code{ArrayTake}, then the expected type is a numeric type.
\end{itemize}
All other cases of patterns with subpatterns are tuple patterns, for them the type is always determined by the type of the
subpatterns, so type clashes cannot occur.
\item For a binding the type of the pattern may be different from the type of the bound expression. This may only happen for
a variable pattern or a variable in a tuple pattern which is no value variable. The type of value variable, unit and wildcard
patterns is always determined by the (corresponding component of) the bound expression. For a take pattern the bound expression
is always a value variable bound to the container variable used in the pattern, so no type clash can occur.
\end{enumerate}

In the cases 2-5 either the subexpression (cases 2-4) or the
context (case 5) consists of a single variable. If it is possible to resolve the type clash by applying a conversion function
to the value, this application can be added as a separate binding of the form
\begin{verbatim}
  v = conv v
\end{verbatim}
where \code{v} is the variable involved in the type clash and \code{conv} is the conversion function. The \code{v} on the right
has its original type, the \code{v} on the left has the expected type. Adding the conversion
in this form preserves the restricted form of the Cogent AST. This would not be the case if conversion function applications
would be directly wrapped around the occurrence of the variable as subexpression in its context. This technique of inserting
additional bindings is used by all postprocessing steps which resolve type clashes by value conversion.

In cases 2-4 above the binding must be inserted so that the conflicting occurrence of the variable as subexpression is in the
scope of the binding, but no other occurrences. Conditions, operator or function arguments, and array indexes always origin from
C subexpressions and are bound by the translation to unique value variables for each occurrence, so the variable occurs only
once. Type clashes for container variables in take/put operations are never resolved by application of a conversion function.
Therefore, in cases 4 and 4 the conversion binding(s) can simply be inserted before the binding containing the type clash(es).
In case 2, according to the restricted form of the Cogent AST, the \code{If} expression can only occur as a \code{Let} body.
Then the conversion binding(s) can be inserted at the end of the binding list of this \code{Let} expression, immediately before
the body. In all these cases the type of the subexpression (and possibly its surrounding tuple) is changed to the expected type,
thus the type clash is resolved.

In case 5 the variable in the conversion binding is that which occurs in the pattern involved in the type clash. Then the conversion
binding is inserted after the binding containing the type clash. The type of the variable in the pattern and possibly the type
of the surrounding tuple is changed to the type of the (component of the) bound expression, thus the type clash is resolved.

In case 1 the branch may be a variable tuple or a \code{Let} expression. In the first case the type clash is caused by one or
more variables in the tuple and can be resolved by according conversion bindings. These bindings are inserted by replacing the branch
by a \code{Let} expression with the conversion bindings and the original branch as body, which preserves the restricted form
of the Cogent AST. In the second case the type clash is caused by the \code{Let} body. Due to the restricted Cogent AST it is
either a variable or control tuple, then the type clash can be resolved by inserting conversion bindings at the end of the
binding list immediately before the body, or it is an \code{If} or \code{Match} expression, then the clash is caused by both
branches and can be resolved by recursively resolving it for both branches.

Whenever Gencot cannot resolve a type difference it signals an error and additionally replaces sub expressions with the wrong type
by dummy expressions which specify the error reason and have the correct expected type according to the context of the expression.
Thus, after processing them no type clashes remain in the resulting Cogent code, even if there where errors.

Resolving type clashes by applying a conversion function or signalling an error is implemented in a generic way by the monadic
action (because it may signal errors)
\begin{verbatim}
  resolveExpr :: ConvVarFun -> GenExpr -> ETrav GenExpr
\end{verbatim}
defined in module \code{Gencot.Cogent.Post.MatchTypes}. Here the first argument is a function which specifies conversion for
some type(s). Its type is defined as
\begin{verbatim}
  type ConvVarFun = GenExpr -> GenType -> ETrav (Maybe GenBnd)
\end{verbatim}
It takes an expression \code{e} and a type \code{t} as arguments. If \code{e} is a single variable \code{v} and the function supports
converting its type to \code{t} by applying a conversion function \code{conv} it returns a binding
\begin{verbatim}
  e' = conv e
\end{verbatim}
where \code{e'} is the same variable but with type \code{t}. If the function determines that \code{e} cannot be converted to
\code{t} it returns a binding
\begin{verbatim}
  e' = gencotDummy "..."
\end{verbatim}
where the string argument specifies the reason for the error and additionally it signals an error. In all other cases the
function returns \code{Nothing}. The function \code{resolveExpr} resolves all type clashes which are handled by the \code{ConvVarFun}
argument as described above by inserting the returned binding and modifying the type of the subexpression or context. In
all other cases it leaves the type clash untouched. Therefore \code{resolveExpr} may be invoked several times with different
\code{ConvVarFun} arguments, each resolving clashes for some specific types.

\subsection{Detecting Readonly Modifications}
\label{impl-post-romod}

Applying the Read-Only item property changes the item's Cogent type \code{t} to the readonly type \code{t!}. The main incompatibility
for values of readonly types occurs when they are modified. Modifications can only be applied to container values, by replacing
or setting a component.

As described in Section~\ref{impl-ccode-cexpr} container modifications are translated to a pair of \code{take}- and \code{put}-bindings
with a re-binding of the component variable to a new value in between. In case of a nested component there are several \code{take}-
and \code{put}-bindings surrounding the re-binding.

If the container has readonly type every modification of a component is an error, independent of the component type. Gencot detects
such modifications as follows: for every \code{take}-binding with readonly container type all bindings of the component
variable in their scope which are not \code{put}-bindings are modifications. A \code{put}-binding without a re-binding of the
component variable puts back the original value and does not cause a modification.

Since it is not possible to convert a readonly type back to a modifyable type these modifications cannot be corrected by
applying a conversion. Hence Gencot always signals an error message and also replaces the component variable in the erroneous
binding by the error variable \code{err'}. This will remove all such modifications, the resulting code never modifies a
readonly container. Since \code{err'} is never referenced the binding will be eliminated when unused variables are eliminated
in later postprocessing steps.

Postprocessing for detecting and removing modifications of readonly containers is implemented by the monadic action
\begin{verbatim}
  romodproc :: GenExpr -> ETrav GenExpr
\end{verbatim}
defined in module \code{Gencot.Cogent.Post.MatchTypes}.

\subsection{Readonly Processing}
\label{impl-post-bang}

Another incompatibility for readonly types are type clashes with the corresponding linear type. Since values of linear type
can be converted to values of readonly type by applying the ``bang'' operation, such type clashes may be resolved by conversion
so that both types are readonly.

However, the application of the bang operator in Cogent is strongly restricted. It cannot be applied to arbitrary expressions
but only to single variables. It can only be applied at specific positions in the code (at bindings, at conditions in conditional
expressions, and at match expressions). The effect of the bang operator is restricted to a scope determined by the position of
application. No value with escape-restricted type (containing a read-only part) may leave this scope. Due to these restrictions
a systematic construction of bang applications so that a maximum of readonly type clashes are resolved, is a complex optimization
problem.

\subsubsection{Determine Variables for Banging to Resolve Type Clashes}

Gencot uses a specific heuristics to find bang applications which resolve readonly type clashes. Remaining clashes are then
resolved by dummy expressions and signaling them as errors. In such cases it may be possible to remove readonly type clashes
manually with the help of the Read-Only item property.

The heuristics only bangs variables which correspond to translated C variables and parameters. If a component variable would
be banged, the scope of the banging would either include the putback binding, which would cause a type clash with the type of
the container component, or it would exclude it, then the value has to leave the scope because it is required for the putback
binding, but that is not possible, since by banging it its type has become non-escapeable. If a value variable would be banged
this makes only sense if its single use is in the scope of the banging. But then the value outside the scope is not used, it
is discarded which is not allowed for a value of linear type in Cogent. If the result variable would be banged, it must always
leave the scope of the banging, since its value must be returned by the function body, again, that is not possible because its
type is non-escapeable by the banging. The other variable kinds (control, switch, and case variables) cannot have a linear
type, therefore banging is not applicable to them.

When Gencot searches for readonly type clashes which may be resolved by banging, it maintains a map of ``source variables'' for
value and component variables. These are the C variables which, if banged, change the type of the value variable or component
variable to readonly. For a component variable the source variables are those of the container. Usually, a variable has only
one source variable, but for a variable bound to a conditional expression there may be different source variables in the branches,
so in general every variable has a set of source variables. If the set is empty the variable's type cannot be made readonly
by banging variables, this is the case for example for a variable bound to the result of a function application.

The scope of a bang application is always an expression. In the case of a conditional, it is the condition expression, in the
case of a binding it is the bound expression.

When Gencot processes an expression as possible bang scope it searches all
contained readonly type clashes. If the subexpression at the type clash is of linear type and has source variables, so that
its type can be converted to readonly by banging the source variables they are collected. In all other cases the type clash
is signaled as an error and is resolved by replacing the sub expression by a dummy expression with the same type as for the
context. If the set of collected source variables is empty all readonly type clashes have been resolved without the need to
bang variables.

Otherwise in a next step the scope is traversed and for all expressions and patterns which depend on the collected source
variables the type is changed to readonly. This may cause new inconsistencies: either modifications of readonly containers
or readonly type clashes. The former are detected and treated as error, as described above, the latter are resolved by either
collecting additional source variables for banging or by treating them as error. This step is repeated as long as it collects
additional variables for banging. Since the scope only uses a finite number of variables the repetition terminates. If the
collected source variables are banged and the scope is replaced by the processed scope and this scope has an escapeable type
all readonly type clashes in it have been resolved.

Postprocessing for resolving readonly type clashes by banging variables is implemented by the monadic action
\begin{verbatim}
  bangproc :: GenExpr -> ETrav GenExpr
\end{verbatim}
defined in module \code{Gencot.Cogent.Post.MatchTypes}.

\subsubsection{Determine Variables for Additional Banging}

Values of readonly type can be freely copied and discarded in Cogent, the can be used in much more flexibel ways than
values of linear type. Therefore Gencot tries to bang variables also if it is not required to resolve type clashes.

The most relevant kind of uses where banging provides an advantage is for a container when components are accessed.
Therefore Gencot also applies the banging heuristics to all variables which occur as container in a \code{take}
operation in the scope of the banging. As described above, a variable is only banged if it does not cause a readonly type
clash. Therefore banging additional variables is most effective if all readonly type clashes have been resolved, so
that detected type clashes are always caused by the banging and are not due to other reasons.

This is implemented by the monadic action
\begin{verbatim}
  ebangproc :: GenExpr -> ETrav GenExpr
\end{verbatim}
defined in module \code{Gencot.Cogent.Post.MatchTypes}.

\subsubsection{Selecting Bang Positions and Scopes}

As described in Section~\ref{impl-ccode-cexpr} Gencot translates C expressions in a way that they are either trivial and cannot
contain a readonly type clash, or they contain atleast one binding and thus a bang position. The heuristics tentatively tries
bang positions in bindings and conditions. Match expressions are not tried, they are always generated by NULL pointer processing
(see Section~\ref{impl-post-null}) in a way that banging the match will make its result non-escapeable.

The heuristics starts with the outermost bang positions, i.e. those with the largest bang scopes. If it is successful without
causing errors it uses the bang position by banging all variables in the collected set (which may be empty) and does not try
inner bang positions in the scope. If it caused errors but there are no inner bang positions in the scope it uses the bang
position with the processed scope and signals the corresponding errors. If there are inner bang positions the bang position
is not used at all, discarding all errors caused by the tentative processing, and processing recurses into the scope expression.
In this way the most effective bang positions (with the largest scope) are tried first.

A bang position may fail because the banged scope has a non-escapeable type. A condition in a conditional expression always
has type \code{Bool} which is escapeable, hence a non-escapeable type can only result for a bang position in a binding. There
it is treated as follows. First, the scope result is reduced as much as possible by removing unused parts from it.
This is done by performing the pre-simplification step \code{presimp} described in Section~\ref{impl-post-let} and the step
\code{romodproc} described above before processing readonly type clashes. Moreover, containers which are banged in the scope
are also removed, because although they may be used afterwards, they cannot be modified in the scope (otherwise the banging
would cause an error), therefore their value before the scope is still valid.

Second, if the result of a single binding prevents banging because it is not escapeable, it may be possible to bang the binding
together with subsequent bindings where the result of the first binding is used. Then the bindings form a common bang scope
and the result of the first binding is only used inside this scope and need not leave it.

A sequence of bindings can be converted to a common binding scope by converting it to a single binding in a similar way as by
the function \code{cmbBinds} described in Section ~\ref{impl-ccode-cexpr}. A binding sequence \code{b1, ..., bn} is converted
to the binding
\begin{verbatim}
  (v1,...,vm) =
  let b1 and ... and bn
  in (v1,...,vm)
\end{verbatim}
where the variables \code{v1,...,vm} are all variables bound in \code{b1, ..., bn} and used after the binding sequence, either
in subsequent bindings or in the body of the surrounding \code{let} expression.

When the heuristics processes a binding sequence it tries the scopes resulting from combined bindings in a similar way as it
tries scopes in general: it starts with the largest scope which results from converting the whole sequence to a single binding.
If not successful it removes bindings from the end of the sequence and tries the resulting smaller scopes until it reaches the
single first binding in the sequence. If that also causes errors it is used as it is, then the rest of the sequence is processed
in the same way. In this way all possible subsequences are tried as bang scopes.

\subsubsection{MayNull Operations}

The Gencot operations for \code{MayNull} types defined in Section~\ref{design-operations-null} must be treated in a specific
way since they are available both for linear and readonly types. Therefore, a readonly type clash for an argument or result
of such an operation can be resolved by replacing the operation. The relevant operations are \code{mayNull}, \code{notNull},
and \code{null} with their readonly alternatives \code{roMayNull}, \code{roNotNull}, and \code{roNull}. For the first two,
either the argument and result are both linear, or both readonly. Applications are generated by the NULL pointer processing
(see Section~\ref{impl-post-null}), it always inserts the linear version, independent of the argument type. The third is only
generated after readonly processing, it is still present in the form of the value \code{cogent\_NULL}.

Occurrences of \code{NULL} in C are treated as follows. They are syntactically translated by Gencot to a reference to a
variable \code{cogent\_NULL} of type \code{MayNull CVoidPtr}. Instead of banging this variable, the type of every single
occurrence may be converted to readonly type, if necessary. This is implemented by temporarily renaming every occurrence of
\code{cogent\_NULL} to \code{cogent<n>\_NULL} where \code{<n>} is a unique number. The heuristics then adds all instances
with a readonly type clash to the source variables collected for banging as usual. Thus their types and that of all variables
with them as source are converted to readonly. For the actual banging these variables are omitted.

Applications of \code{mayNull} may occur at arbitrary places in the generated code, the result type is readonly whenever the
argument type is readonly. Thus, if the argument is affected by banging variables, it transfers to the result. This is taken
into account by transferring the source variables from argument to result. Then readonly type clashes between a linear result
and its context can be resolved as usual. If the result is readonly and the context is linear, the corresponding type clash
existed between the argument and the context before \code{mayNull} has been inserted, thus the clash is resolved as usual
by replacing the \code{mayNull} application by a dummy and signaling an error. If

Applications of \code{notNull} occur only in a match expression in the form
\begin{verbatim}
  notNull v
  | Nothing -> e1
  | Some v -> e2
\end{verbatim}
where \code{v} is a C variable or component variable.

Here, whenever the type of \code{v} is readonly, the result of \code{notNull} and the two alternative patterns have readonly type,
thus there cannot be a readonly type clash for the result of \code{notNull} which could cause \code{v} to be banged. Therefore
the source variables of \code{v} need not be transferred to the result of \code{notNull}.

If the source variables of \code{v} are decided to be banged, the type of the result of \code{notNull} and the two patterns must
be converted to readonly. The type for the occurrences of \code{v} in \code{e1} and \code{e1} will be converted as usual.

In all cases only the types of \code{mayNull} and \code{notNull} are converted, the operations are only replaced by their readonly
alternatives in a later processing step.

\subsection{Boolean Value Processing}
\label{impl-post-bool}

The type \code{Bool} is used in the Cogent AST although it does not result from translating a C type. As described in
Section~\ref{impl-ccode-type} it is specified by the translation for all results of applications of equational, relational,
and boolean operators. Moreover, it is implicitly expected for the arguments of boolean operators and for conditions in conditional
expressions. The use of type \code{Bool} can clash with all types which result from translating a C type which can be used to
represent a boolean value. These are all ``scalar'' types in C, which are the arithmetic types and the pointer types.

Arithmetic types are always translated to the Cogent integer types \code{U8, U16, U32,} and \code{U64}. Type clashes between
them and \code{Bool} can always be resolved by conversion. An expression \code{e} of integer type can be converted
to \code{Bool} by
\begin{verbatim}
  e /= 0
\end{verbatim}
because the type of the literal \code{0} is automatically adapted to the type of \code{e} here.

An expression \code{e} of type \code{Bool} can be converted to any arithmetic type by
\begin{verbatim}
  if e then 1 else 0
\end{verbatim}
because the literals \code{1} and \code{0} are automatically adapted to the expected arithmetic type.

Pointer types are translated to linear types and are represented by boxed record types or boxed abstract types, possibly wrapped
by \code{MayNull}. An expression \code{e} of type \code{MayNull a} can be converted to \code{Bool} by comparing it with NULL:
\begin{verbatim}
  e /= cogent_NULL
\end{verbatim}
Here \code{cogent\_NULL} denotes the Gencot translation of the C constant \code{NULL} of Cogent type \code{MayNull CVoidPtr}. This
Cogent expression resulting from the conversion is the same as the translation of the C expression \code{expr != NULL}, if
\code{e} is the translation of \code{expr}. Clashes between the type of \code{e} and \code{MayNull CVoidPtr} will be resolved
by further postprocessing for pointer types as described below.

It would be possible to convert the value \code{False} to a NULL pointer using the Gencot basic operations \code{null} and
\code{roNull} defined in Section~\ref{design-operations-null}. However, for the value \code{True} no sensible conversion exists.
More general, conversion from a numerical value to a pointer would correspond to a form of pointer arithmetics which is
deliberately not supported by Gencot. Therefore Gencot never converts from type \code{Bool} to a pointer type.

Type clashes with \code{Bool} are resolved as follows. A sub-expression with non-boolean type in a context expecting type \code{Bool}
is converted by comparing with \code{0} or \code{cogent\_NULL}. A sub-expression with type \code{Bool} in a context not expecting
type \code{Bool} is always converted to arithmetic type \code{U32} as described above. If necessary, further type clashes are resolved
in later postprocessing steps. If the type clash is between two operator arguments
or two components of the branches of a conditional expression the conversion is always to type \code{Bool}, since that is always
possible.

Postprocessing for boolean values in this way is implemented using function \code{resolveExpr} described in Section~\ref{impl-post-types}.
Although it cannot cause errors, it is thus implemented by the monadic action
\begin{verbatim}
  boolproc :: GenExpr -> ETrav GenExpr
  boolproc = resolveExpr convVarBoolDiffs
\end{verbatim}
defined in module \code{Gencot.Cogent.Post.MatchTypes}, where \code{convVarBoolDiffs} is the function of type \code{ConvVarFun}
for boolean conversions.

\subsection{NULL Pointer Processing}
\label{impl-post-null}

Pointer values may be NULL in C. In Cogent this property is modeled in the type using the \code{MayNull} wrapper type. Type clashes
may result between \code{MayNull} types and not-null (unwrapped) types.

Values of not-null type can be converted to \code{MayNull} type using the Gencot provided operations \code{mayNull} and \code{roMayNull}
introduced in Section~\ref{design-operations-null}. Values of \code{MayNull} type can only be converted to not-null type by testing them
for being NULL using the Gencot provided functions \code{notNull} and \code{roNotNull} and then modifying the type in the corresponding
conditional branch. In the other branch the value can be substituted using the Gencot provided functions \code{null} and \code{roNull}.

Values of not-null type are needed when the pointer shall be dereferenced. It would be possible for Gencot to generate the required
NULL tests, but then it must generate a working code alternative for the case that the pointer is NULL. It is usually not possible to
do this automatically. Therefore Gencot never generates NULL test, it only uses those which are present in the C code.

A NULL test has the form \code{v op cogent\_NULL} or \code{cogent\_NULL op v} where \code{op} is either \code{==} or \code{/=}. It origins
either from translating corresponding C code or by resolving a boolean type clash by converting a value of pointer type to \code{Bool}, as
described above. If the variable \code{v} has not-null type it can be immediately substituted by \code{True} or \code{False}. Otherwise the
test result can be used to specialize occurrencies of \code{v} in conditional code which depends on the test result.

In C the test result can be stored and used later as condition to guard code parts. To detect all those code parts would require a full
data flow analysis of the test result. Gencot does not perform this analysis, it only uses the test result if the test is immediately
present in the condition of a conditional expression or statement. Conditional expressions and statements are both translated to Cogent
conditional expressions. Then the scopes affected by the test are syntactically available as the branches of the conditional expression.

Postprocessing for values of \code{MayNull} type in this way is implemented by the monadic action
\begin{verbatim}
  maynullproc :: GenExpr -> ETrav GenExpr
\end{verbatim}
defined in module \code{Gencot.Cogent.Post.MatchTypes}.

\subsubsection{Splitting Conditions}

A NULL test in C may occur as part of a complex boolean expression using the operators \code{\&\&}, \code{||}, and \code{!}. In this form
the test cannot be used for specializing the tested variable, because the complex condition may have no direct consequence for the tested
variable. Therefore, in a separate pass, Gencot splits complex conditions so that contained NULL tests are isolated as condition in a
conditional subexpression.

As described in Section~\ref{impl-ccode-cexpr}, the operators \code{\&\&}, \code{||} are translated to a conditional expression. Therefore
a complex boolean condition is always translated to an expression using (possibly nested) conditional expressions and the \code{not} operator.
If such an expression occurs as condition in another conditional expression this expression can be split according to the transformation
\begin{verbatim}
  if (if x then x1 else x2) then y1 else y2
  -->
  if x then (if x1 then y1 else y2)
       else (if x2 then y1 else y2)
\end{verbatim}
When the condition results from translating a \code{\&\&}, \code{||} operator, one of \code{x1} and \code{x2} is typically \code{True}
or \code{False}, then the result of the splitting can immediately be simplified by removing one occurrence of \code{y1} or \code{y2}.
Note however, that even then the splitting will duplicate one of the branches \code{y1} and \code{y2} of the original conditional expression.

The \code{not} operators can be eliminated by swapping the branches according to
\begin{verbatim}
  if (not x) then y1 else y2
  -->
  if x then y2 else y1
\end{verbatim}

Gencot reduces and splits complex conditions according to these rules until the remaining conditions are either a single NULL test
or a (possibly complex) condition which does not contain a NULL test.

The duplication of branches caused by the splitting rule may result in an exponential growth of the code size. To mitigate this, Gencot
tries to move parts of the branches before the conditional expression, before applying the splitting rule. This is done according to the
transformation rule
\begin{verbatim}
  if y then (let b1 in y1) else (let b2 in y2)
  -->
  let b1 and b2 in (if y then y1 else y2)
\end{verbatim}
However, this is not always possible, since the variables bound in \code{b1} may not occur free in \code{let b2 in y2} and vice versa and
also not in \code{y}. Gencot extracts as much bindings from the branches as possible. If a branch binds only value variables (which may
not occur outside the branch), i.e., it has no side effects, all bindings can be extracted and the branch is reduced to a single variable
reference, then the code is minimally enlarged.

Extracting bindings from the branches prevents applying the implications of the NULL test in them, which is the main goal of the NULL
processing. Therefore bindings are only extracted from branches which are actually duplicated, because then they cannot be restricted
to a single branch of a NULL test condition and its effects cannot be applied to them, at least not to all copies.

Gencot also takes into account, that the condition \code{y} may have side effects in C. Then it will be translated to a tuple binding
\begin{verbatim}
  (v<n>',v1..) = e
\end{verbatim}
where \code{e} may be a conditional expression or a let expression and the value valiable \code{v<n>'} is used as condition \code{y}.
Then the splitting rule becomes more complex and must also deal with the side effect parts of \code{e}.

The code modifications done during condition splitting are rather complex. Banged variables in bindings would make it even more complex,
therefore Gencot performs NULL processing before performing readonly processing which may introduce banged variables, as described in
Section~\ref{impl-post-bang}.

\subsubsection{Transforming NULL Tests}

After splitting conditions Gencot uses a second pass to transform all conditional expressions with a NULL test as condition to a Cogent
match expression according to the transformation rule
\begin{verbatim}
  if v /= cogent_NULL then y1 else y2
  -->
  notNull v | Nothing -> y2
            | Some v -> y1
\end{verbatim}
Note that if the type of \code{v} is \code{MayNull T} the result of \code{notNull} has type \code{Option T} which can be discriminated
by the match expression. In the \code{Some}-branch the variable \code{v} has type \code{T}, so it is known to be not NULL. In \code{y1}
the type information in the Cogent AST is updated accordingly for every free occurrence of \code{v} and also after a re-binding to itself
and by a \code{take} or \code{put} binding which both do not change the value of \code{v}.

The transformation always inserts the operation \code{notNull}, even if \code{v} has a readonly type. The readonly processing is performed
after the NULL processing and may convert \code{v} to readonly by banging it, if it is not readonly. Therefore \code{notNull} is
only replaced by \code{roNotNull} after readonly processing.

If \code{v} is a value variable the occurrence in the condition is its single occurrence and it will not be present in \code{y1}, so the
transformation would have no effect. Therefore Gencot substitutes \code{v} by its bound expression, as long as it is a value variable.
Then it is either a C variable or a component variable, or it is some other expression, such as a function application or a conditional
expression. In the former case the variable may occur several times in \code{y1} and be affected by the NULL test implications. In the
latter case only the syntactically same expression could be affected and only, if variables used in it have not been re-bound to other
values. Even then the evaluation of the expression must be deterministic for the affecting being correct. Therefore Gencot only transforms
NULL tests where the tested expression is a C or component variable after substituting value variables.

In the \code{Nothing}-branch it is known that \code{v} has value NULL. This is exploited by replacing \code{y2} by the expression
\begin{verbatim}
  let v = cogent_NULL in y2
\end{verbatim}
However, this would be interpreted by the readonly processing as a modification of \code{v} which could prevent banging it. Therefore
this replacement is done in a separate postprocessing step which is executed after readonly processing. Then it has also been finally
decided whether \code{v} has readonly type or not and instead of \code{cogent\_NULL} the functions \code{null} or \code{roNull} can be
used.

\subsubsection{Resolving MayNull Clashes}

In a third processing step Gencot resolves type clashes between \code{MayNull} wrapped types and unwrapped types. There are two cases:
If the context expects an unwrapped type but the sub expression has a \code{MayNull} type this means that a pointer is expected to
be not NULL, but this information is not present at the position where the pointer is used. The reason may be a missing NULL test in
the C program or a too complex data flow dependency which is not detected by Gencot. This type clash is always resolved by replacing
the sub expression by a dummy expression with the unwrapped type and signaling an error.

The second case is a context which expects a \code{MayNull} type but the sub expression has an unwrapped type. This means, it is known
that the pointer is not NULL, but this information is not required in the context. This situation is always resolved by applying the
Gencot operation \code{mayNull} to the sub expression which corresponds to ``forgetting'' the information of being not NULL.

Like for \code{notNull}, this transformation always inserts \code{mayNull}, for expressions of readonly type it is only replaced by
\code{roMayNull} after readonly processing.

To preserve the restricted form of the Cogent AST described in Section~\ref{impl-post-ast} the \code{mayNull} application is always
inserted as a separate binding of the form
\begin{verbatim}
  v = mayNull[T] v
\end{verbatim}
where \code{v} is the subexpression of type \code{T} which must be converted to \code{MayNull T}. The variable \code{v} on the left side
of the binding has type \code{MayNull T}, therefore its type can be changed to \code{MayNull T} for every free occurrence in the scope
of the binding.

This is implemented using function \code{resolveExpr} described in Section~\ref{impl-post-types} together with a \code{ConvVarFun}
which specifies the conversion between \code{MayNull} wrapped and unwrapped types as described above.

\subsection{String Processing}
\label{impl-post-string}

**todo \code{stringproc}

\subsection{Integer Conversion}
\label{impl-post-int}

Cogent supports the four arithmetic types \code{U8}, \code{U16}, \code{U32}, and \code{U64}. They have as values unsigned
integers of the corresponding bitsize. In C values of the corresponding types are usually automatically converted according
to their context. In Cogent explicit conversions are required.

If the context bitsize is larger than that of the expressions the \code{upcast} operator is used for conversion in all cases.
If the context bitsize is lower than that of the expression the Cogent standard library provides abstract functions of the
form \code{u32\_to\_u16} for conversion between two specific types. Since there is no function for converting from \code{U64}
to \code{U8} this must be done in two steps via conversion to \code{U32}.

Gencot implements all these conversions between arithmetic types using function \code{resolveExpr} described in
Section~\ref{impl-post-types}. Although it cannot cause errors, it is thus implemented by the monadic action
\begin{verbatim}
  intproc :: GenExpr -> ETrav GenExpr
  intproc = resolveExpr convVarIntDiffs
\end{verbatim}
defined in module \code{Gencot.Cogent.Post.MatchTypes}, where \code{convVarIntDiffs} is the function of type \code{ConvVarFun}
for integer conversions. In the case of conversion using the upcast operator the inserted binding uses an \code{Upcast} expression
on the right hand side, this is the only case where Gencot generates this kind of expression.

\subsection{Pointer Adaptation}
\label{impl-post-pointer}

**todo \code{pointerproc}

\subsection{Processing \code{MayNull} Operations}
\label{impl-post-opnull}

The Gencot operations for values of \code{MayNull} type are defined in two variants for values which are readonly or not (see Section~\ref{design-operations-null}). The operations are introduced by the \code{NULL} pointer processing but the distinction
between readonly and modifiable values is only known after readonly processing. Therefore the \code{NULL} pointer processing
always generates the variants for modifiable values. They are replaced by the variants for readonly values in a separate
processing step.

The operation \code{null} and its readonly variant \code{roNull} are used to represent the value \code{NULL} in Cogent.
Gencot translates it to references of the variable \code{cogent\_NULL}. Since a variable reference is easier to handle
for the processing steps than an application of a (constant) function, \code{cogent\_NULL} is only converted to \code{null}
and possibly further to \code{roNull} after NULL pointer processing and readonly processing.

As described in Section~\ref{impl-post-null} in the Nothing branch of generated \code{match} expressions the tested pointer
variable is bound to NULL. Since that would be interpreted by readonly processing as a modification it would prevent
banging for the pointer variable. Therefore the binding is only inserted after readonly processing. Then it is known
whether the type is readonly or not, so the representation by the operation \code{null} or \code{roNull} can be used directly.

All these postprocessing steps cannot cause errors, hence they are implemented together by the function

\begin{verbatim}
  opnullproc :: GenExpr -> GenExpr
\end{verbatim}
defined in module \code{Gencot.Cogent.Post.MatchTypes}.

\subsection{Take/Put Processing}
\label{impl-post-takeput}

For struct and array accesses in C (\code{s.m}, \code{s->m}, \code{a[i]}) and also for pointer dereferences (\code{*p})
the translation described in Section~\ref{impl-ccode-cexpr} creates pairs of take/put bindings of the form
\begin{verbatim}
  <v>{m=p<k>} = v<n>
  ...
  <v> = <v>{m=p<k>}
\end{verbatim}
(for struct access and pointer dereferences) and
\begin{verbatim}
  <v> @{@v<l>=p<k>} = v<n>
  ...
  <v> = <v> @{@v<l>=p<k>}
\end{verbatim}
(for array access). Here, \code{<v>} is the variable used for the container (struct, array, or pointer) and \code{p<k>'} is the
component variable used to bind the component (member, element, or referenced data). The value variable \code{v<n>'} is the result
of the expression denoting the container. Since in C this expression is always a subexpression of the access expression, its
translation is positioned in one or more bindings before the \code{take} binding which ultimately bind \code{v<n>'}.
Since the take/put pair only covers the C access expression the container cannot be modified by a side effect between the
\code{take} and \code{put} bindings, i.e., the variable \code{<v>} cannot be re-bound between them.

There are several cases where the \code{put} binding is not present and has been replaced by a unit binding, either by the
translation (see Section~\ref{impl-ccode-cexpr}) or by postprocessing (see Sections~\ref{impl-post-romod} and~\ref{impl-post-bang}).
In all these cases the container is either specified by the error variable \code{err'} or it has readonly type.

If the container in a \code{take} binding is specified by the error variable, the container has been specified in C by an expression
which is not a variable or an access chain starting at a variable. This case is detected by the translation phase and no corresponding
\code{put} binding is generated. Note that the postprocessing described in Section~\ref{impl-post-romod} replaces occurrences of
component variables in binding patterns by the error variable, but only in normal bindings and not in \code{take} bindings for nested
accesses to components of the component.

There are three main postprocessing steps applied to take/put pairs:
\begin{itemize}
\item processing single \code{take} and \code{put} bindings according to the types of the container and the component.
\item eliminating the \code{take} and/or \code{put} binding of a pair according to how the component is used after the \code{take}.
\item converting take/put pairs to applications of \code{modify} or \code{modref}.
\end{itemize}

Postprocessing for \code{take} and \code{put} bindings is implemented by the function
\begin{verbatim}
  tpproc :: GenExpr -> GenExpr
\end{verbatim}
defined in module \code{Gencot.Cogent.Post.Takeput}.

The three substeps are implemented by the functions
\begin{verbatim}
  tpsingle :: GenExpr -> ETrav GenExpr
  tpelim :: GenExpr -> GenExpr
  tpmodify :: GenExpr -> GenExpr
\end{verbatim}
The first substep is implemented by a monadic action because it may signal errors. The other substeps never signal errors.
The substeps are executed sequentially for a whole function body. Every substep converts or removes some take/put pairs, the following
substep only processes the remaining pairs. After the third substep there may still remain take/put pairs which are usually valid
Cogent code.

\subsubsection{Processing Single \code{take} and \code{put} Bindings}

The first substep detects erroneous take/put pairs and pairs where the container has readonly type. In both cases the \code{put} binding
is simply removed. For erroneous pairs the \code{take} binding is replaced by a binding for the component variable to a
dummy expression and a corresponding error is signaled. For a readonly container previous postprocessing steps guarantee
that the component is not modified or replaced (see Sections~\ref{impl-post-romod} and~\ref{impl-post-bang}), therefore the
\code{put} binding is not needed and the \code{take} binding is replaced by a direct access to the component. Together, in
all these cases both the \code{take} and the \code{put} bindings are removed.

Moreover, if the container is an unboxed record of nonlinear type (i.e., without linear components) the \code{take} binding
can also be replaced by a direct access, but the \code{put} binding may still be needed, which is determined in the second
substep. That substep, however, only processes complete take/put pairs. Therefore here the case is processed where not \code{put}
binding is present, which is the case when the container has not been specified by a variable or access chain starting at a
variable in C. As described in Section~\ref{impl-ccode-cexpr} the translation uses the error variable as bound container variable
in the generated \code{take} binding. This property is used to recognize the case here.

Additionally the case is handled where a take/put pair represents a dereference \code{*p} where \code{p} has an array type in C,
which has the meaning of accessing the first array element (with index 0). The \code{take} resulting from the translation is a
record \code{take} for the array as container and the field \code{cont} as component (see Section~\ref{impl-ccode-cexpr}). Like
all arrays the container here is a wrapper record with a single field where the name encodes the number of array elements and
which is always different from the name \code{cont}. If this situation is detected for a \code{take} it is replaced by an array
\code{take} with index 0 and similar for a \code{put}. This is done before all other processing, so the resulting array take/put
pair is processed like every other array take/put pair as described below.

The following erroneous situations are detected:
\begin{itemize}
\item The container has a \code{MayNull} wrapped type. This means it is not statically known that the container pointer is
not NULL and the access may cause a NULL pointer exception. Gencot treats all these cases as error. This results in
preventing all NULL pointer derefences in the generated Cogent code which can be formally verified. Only if the container
type is unwrapped, either caused by a Not-Null item property (see Section~\ref{design-types-itemprops}) or caused by a
NULL test present in the C code and detected by NULL pointer postprocessing (see Section~\ref{impl-post-null}) the access
is translated to Cogent.
\item The container has type \code{CVoidPtr} or \code{CArrXX}. In the first case the C type was \code{void*} and no more
specific type could be inferred during postprocessing. Then the access cannot be represented in Cogent since the component
type is unknown. In the second case the C type is an array type where the number of elements could not be determined by
Gencot. Then it is not possible to check the access whether the index is valid, this access cannot be represented in
Cogent either. Since these are the only cases where the container has an abstract type, the error is detected by testing
the container type for being abstract.
\item The container has a linear type (either a boxed record or an unboxed record with a linear component) and is specified
by the error variable in the \code{take} binding. This means it has been specified in C by an expression which is not a
variable or an access chain starting at a variable, such as the result of a function application. Then an access to a
component would always discard the remaining container since there is no variable to which the remaining container can be
bound. This is not allowed in Cogent for a container of linear type and is treated by Gencot as an error. Note thatconstitutes in this
case the \code{put} binding needs not be removed since the translation does not generate it (see Section~\ref{impl-ccode-cexpr}).
If the container has a nonlinear type (readonly or unboxed without linear component) the access is processed as
described below or in the next substep.
\item The take/put pair represents a dereference \code{*p} where \code{p} is a pointer to a struct in C. The \code{take}
resulting from the translation is a record \code{take} for the boxed record corresponding to the struct as container and
the field \code{cont} as component (see Section~\ref{impl-ccode-cexpr}) with the unboxed record as its type. Even if the
record has a field named \code{cont} its type cannot be the unboxed record which contains it. Therefore this case is
recognized by Gencot by first testing whether the record has a field named \code{cont} and then checking its type. The
case is treated as an error because the conversion from a boxed to an unboxed record cannot be represented in Cogent.
\end{itemize}

If the container has readonly type a \code{take} binding \code{<v>{m=p<k>} = v<n>} with container type \code{T}
and component type \code{TC} is replaced by
\begin{itemize}
\item the pointer dereference application binding \code{p<k>' = getPtr[T,TC] v<n>'}, if \code{T} is a pointer type of the
form \code{CPtr TC},
\item otherwise the \code{getref} application binding \code{p<k>' = getrefFld\_m[T,TC] v<n>'} if the field \code{m} has unboxed
type in \code{T} but \code{TC} is the corresponding boxed type,
\item otherwise the member access binding \code{p<k>' = v<n>'.m}.
\end{itemize}
The array \code{take} binding \code{<v> @{@v<l>=p<k>} = v<n>} is replaced by
\begin{itemize}
\item the \code{getref} application binding \code{p<k>' = getrefArr[T,U32,TC] (v<n>',v<l>')} if the elements have unboxed
type in \code{T} but \code{TC} is the corresponding boxed type,
\item otherwise the \code{get} application binding \code{p<k>' = getArr[T,U32,TC] (v<n>',v<l>')}.
\end{itemize}
In all these cases the container variable \code{<v>} does not occur in the replacement binding. Thus the result is also valid
if the container variable was the error variable. Semantically this is correct because the remaining container after accessing
the component may be discarded because its type is readonly.

The case where the container is an unboxed nonlinear record and \code{<v>} is the error variable is handled in the same way.

\subsubsection{Eliminating \code{take} and \code{put} Bindings}

The second substep checks how the accessed component is used after the \code{take} binding.

\paragraph{Eliminating \code{take} Bindings}

If the component has nonlinear type and is not used before or after the \code{put} binding the \code{take} binding can be removed.
This corresponds in C to the case where the component value is overwritten by a plain assignment or it is neither used nor changed
so that the access is a no-op. In the second case the \code{put} binding is removed as well.
In the first case the \code{put} binding will be retained. This will result in a \code{put} binding which is not paired with
a preceding \code{take} binding, so that it is applied to a container with a type where the component is not taken. Cogent
accepts such \code{put} operations if the component has no linear type.

If the component is used the \code{take} binding cannot be removed, but if the container is an unboxed record of nonlinear type
Gencot replaces the \code{take} binding by a member access. This may also result in a valid unpaired \code{put} binding as above.

If the component has linear type it would be illegal to overwrite it since that would discard it. In this case the \code{take}
binding is retained unchanged, however, the Cogent compiler will signal an error because the taken component is discarded.

To determine whether the component is used, all free occurrences of the component variable after the \code{take} binding are
inspected. If such an occurrence is on the right side of a binding, the free occurrences of the bound variable are transitively
inspected in the same way. If the occurrence is in a tuple expression only the corresponding bound variable in the tuple pattern
is inspected. A variable is considered to be used if it occurs free in the final body of the \code{let} expression
which contains the \code{take} binding. The rationale for this is that normally a \code{let} expression corresponds to the
translation of a C expression and the body represents the result of the expression (as value or side effect). So Gencot considers
a component as used if it is part of the result of the expression which contains the component access. It is not guaranteed that
the component is actually used in that case, e.g., the expression could be an isolated expression statement where the result value is
discarded. However, such cases are assumed to be rare and, if they cause a problem, will be detected by the Cogent compiler.

If an array \code{take} is eliminated in this way and the corresponding array \code{put} binding
\begin{verbatim}
  <v> = <v> @{@v<l>=p<k>}
\end{verbatim}
is retained, it is converted to the \code{setArr} application
\begin{verbatim}
  (<v>,()) = setArr[T,U32,TC] (<v>,v<l>,p<k>)
\end{verbatim}
where \code{T} is the type of the container (array) and \code{TC} is the type of the component (array element).
This is necessary because the generated array \code{put} bindings are always illegal Cogent code and must be replaced
by Cogent array operations. The \code{setArr} operation is always applicable in this case because the array element has
nonlinear type.

\paragraph{Eliminating \code{put} Bindings}

If the component variable is not re-bound before the \code{put} binding and the container has nonlinear type (either readonly
or unboxed with no linear component) this means that the component is not modified or replaced. Then the \code{put} binding
can be removed. Note that the case of a readonly container has already been processed in the first substep described above.
Therefore here only the case of an unboxed container remains.

In this case the \code{take} binding is always eliminated as well or replaced by a direct access, as described above.
Therefore no unpaired \code{take} binding remains which would change the type of the container
to the type where the component is taken.

If the component variable is re-bound as container in the \code{put} binding of a nested access, it may depend on the
elimination of that \code{put} binding whether the outer \code{put} binding may be eliminated. Therefore nested take/put pairs
are processed for elimination starting with the innermost pairs. A nested \code{take} binding with the component as container
is irrelevant when checking for re-bindings of the component, since it is never retained without the corresponding \code{put}
binding.

If the container has linear type, the \code{put} cannot be removed, even if the component is not re-bound. The remaining
\code{take} binding cannot be replaced by a Gencot operation or member access in this case and would change the container
type to a type with a taken component which would lead to a type error in Cogent as described above.

\subsubsection{Converting take/put Pairs to \code{modify} or \code{modref} Expressions}

In the third substep remaining take/put pairs are converted to applications of the \code{modify} or \code{modref} operations
in the following cases:
\begin{itemize}
\item The pair consists of an array \code{take} and an array \code{put}, since these are always invalid Cogent code
and must be replaced by Gencot operations.
\item The container has linear type and in it the component has unboxed type but the component variable has the corresponding
boxed type. This case cannot be represented by \code{take} and \code{put} operations in Cogent, it must be converted to
an application of the Gencot \code{modref} operation.
\end{itemize}

The remaining take/put pairs after this step have the following properties: they consist of \code{take} and \code{put} bindings
for records. The container type is not \code{MayNull} wrapped and is a boxed record which has the component as a field. The
component variable has the type of this field. Together these \code{take} and \code{put} are always valid Cogent code and are
not further processed by Gencot. They could be replaced by an application of the \code{modify} operation, but since that must
be defined specifically for the accessed field it is easier and more flexible to use the Cogent \code{take} and \code{put}
operations.

If a take/put pair is converted to a \code{modify} or \code{modref} application the change function to be passed as argument
to the application must be determined. It is constructed as a Cogent lambda expression. It takes as arguments the component
and a tuple of additional inputs and returns the (possibly modified) component and a tuple of additional outputs. Its body
is completely determined by the bindings between the \code{take} and the \code{put} binding.

The additional outputs are all variables which are bound in these bindings and are used in the bindings and the let-body after
the \code{put} binding. Whether a variable is used is determined in the same way as described above for eliminating \code{take}
bindings. If there is no such variable the additional output is the unit value. If there is only one such variable its value
is used as additional output, otherwise all such variables organized in a tuple in some order.

The body of the change function is a \code{let} expression. Its bindings are the bindings between the \code{take} and the
\code{put} binding. Its body is the pair consisting of the component variable and the additional output. In Cogent a
tuple is always equivalent to a chain of right associatively nested pairs. Therefore in the case that the additional output
is a tuple the body is flattened to a tuple whith the component variable as first element. The component variable may also
be a part of the additional output, then it occurs twice in the body.

The additional inputs are all variables which are used in this body of the change function. The component variable cannot
be a part of the additional input since it is first bound in the \code{take} binding. The additional input variables are
organized in a tuple together with the component variable in the same way as the output variables. The corresponding variable
tuple pattern is used as argument pattern in the change function lambda expression.

If converted to a \code{modify} application a sequence of bindings
\begin{verbatim}
  <v> @{@v<l>=p<k>} = v<n>
  <bs>
  <v> = <v> @{@v<l>=p<k>}
\end{verbatim}
is replaced by the single binding
\begin{verbatim}
  (<v>,ov..) = modifyArr[T,U32,TC,_,_]
    (<v>,v<l>,
     \(p<k>',iv..) => let <bs> in (p<k>',ov..),
     iv..)
\end{verbatim}
where \code{<bs>} are the bindings between \code{take} and \code{put}, \code{ov..} is the sequence of additional output
variables or unit \code{()}, \code{iv..} is the sequence of additional input variables or unit \code{()}, \code{T} is the
container type, \code{TC} is the component type. The types of \code{iv..} and \code{ov..} for \code{modifyArr} are specified
by \code{\_}, Gencot assumes that they can always be derived by the Cogent compiler. A \code{modref} application for an array
has the same form, only the name is different (\code{modrefArr}).

A \code{modref} application for a record take/put has the form
\begin{verbatim}
  (<v>,ov..) = modrefFld_m[T,TC,_,_]
    (<v>,
     \(p<k>',iv..) => let <bs> in (p<k>',ov..),
     iv..)
\end{verbatim}
where \code{m} is the accessed field. The main difference is the missing index type and variable \code{v<l>'}. If the
container type has the form \code{CPtr TC} the take/put pair is always replaced by a \code{modify} application which
has the same form with the name \code{modifyPtr}.

If a take/put pair is nested in another take/put pair the \code{put} bindings are generated immediately after each other.
Between the \code{take} bindings there is always a binding \code{v<n>' = p<k>'} where \code{p<k>'} is the component variable
of the outer pair and \code{v<n>'} is the container on the right side of the inner \code{take} binding. When processing
the outer pair this binding is always eliminated by substituting \code{p<k>'} for \code{v<n>'} in the inner \code{take} so
that also the \code{take} bindings follow each other immediately. From this it follows that the additional output variables
of the outer pair are the same as for the inner pair and analogously for the additional input variables.

Gencot first processes the inner take. If it is replaced by a \code{modify} or \code{modref} application, the resulting single
binding is the only content of the outer binding. If the outer binding is also replaced the resulting binding in case of two
nested pairs for records has the form
\begin{verbatim}
  (<v>,ov..) = modouter[T,TC,_,_]
    (<v>,
     \(p<k>',iv..) =>
       let (p<k>',ov..) = modinner[TC,TCC,_,_]
             (p<k>',chfun,iv..)
       in (p<k>',ov..),
     iv..)
\end{verbatim}
where \code{chfun} is the change function for the inner pair, \code{modouter} and \code{modinner} are the corresponding
\code{modify} or \code{modref} operations, and \code{TCC} is the type of the inner component. Now it is possible
to extend the outer change function by an additional argument for the inner change function and pass it this way to
the inner application:
\begin{verbatim}
  (<v>,ov..) = modouter[T,TC,_,_]
    (<v>,
     \(p<k>',cf,iv..) =>
       let (p<k>',ov..) = modinner[TC,TCC,_,_]
             (p<k>',cf,iv..)
       in (p<k>',ov..),
     chfun, iv..)
\end{verbatim}
Formally, the \code{chfun} has become an additional input to the outer change function, prepended to its own input
\code{iv..}. Thus, also the type of the additional input for \code{modouter} is now different from that for \code{modinner},
although this is not visible in the code because both are specified by \code{\_}.

This binding
can be simplified by substituting the inner binding in the \code{let} body followed by an eta reduction to
\begin{verbatim}
  (<v>,ov..) = modouter[T,TC,_,_]
    (<v>,
     modinner[TC,TCC,_,_],
     chfun, iv..)
\end{verbatim}

If the inner pair is for an array the \code{chfun} must be preceded by the array index used for the access, thus the
index also becomes an additional input for the outer change function.

More generally, Gencot applies this conversion whenever, after processing the bindings between the outer \code{take}
and \code{put}, these bindings consist of a single binding of the form
\begin{verbatim}
  (p<k>',ov..) = f (p<k>',iv..)
\end{verbatim}
even if the function \code{f} is not a \code{modify} or \code{modref} operation resulting from converting a take/put
pair.

Gencot iterates this conversion as long as applicable. Here it is important that the types of the additional input
are not specified explicitly for \code{modify} or \code{modref} functions. Every such type contains the type of the next inner
change function which may lead to an exponentially increased code size if all these types are explicitly specified.

\subsection{Combining the Steps}
\label{impl-post-combine}

All postprocessing steps are designed and implemented in a standalone way so that they can be applied to arbitrary Cogent expression
which are generated by the Gencot translation phase. However, to be most effective, they exploit several dependencies which must
be respected by the order of execution.

Generally, the postprocessing steps recurse into the structure of the processed expression. Thus it would be possible to combine them
on every recursion level by combining the non-recursive steps to a common postprocessing function which recurses into the expression
structure. Alternatively each step recurses on its own and the overall simplification applies the steps sequentially to the toplevel
expressions.

Some steps depend on each other in a cyclic way. These are in particular the functions \code{evalproc}, \code{letproc}, and \code{ifproc}.
After \code{letproc} substitutes variables it may be possible to evaluate more expressions by \code{evalproc} than before. This may
allow additional simplifications by \code{ifproc} since conditions may evaluate to a constant. These simplifications may remove code parts 
with occurrences of free variables which in turn may allow additional simplification by \code{letproc}. Therefore these steps must 
be applied in a loop until the expression does not change any more.

The \code{letproc} step works bottom up and is applied to subexpressions before it is applied to an expression. The \code{ifproc} step 
for a subexpression will only benefit if variables are substituted from the context. Thus it does not help to iterate these steps for
the same subexpression. Instead, both steps recurse on their own and are iterated on the toplevel expressions.

The \code{evalproc} step is only used as auxiliary step in other postprocessing steps. Since the other steps recurse into the control
structures like \code{if} and \code{let}, it is not necessary for \code{evalproc} to do this. Therefore \code{evalproc} only recurses
into operator subexpressions.

The \code{opproc} step recurses into arbitrary subexpressions. It processes cases which are typically created by \code{ifproc}.
Therefore it is executed after every toplevel execution of \code{ifproc}.

Many steps exploit the fact that the Cogent code has the restricted form described in Section~\ref{impl-post-ast}. Since the combined
steps \code{letproc}, \code{evalproc}, and \code{opproc} do not preserve this form, most other steps are executed before these. This
implies that they are usually executed on a code with larger size and redundant parts, before the code is simplified. The advantage
of an easier implementation on the restricted code form is prioritized by Gencot over an efficient execution of the postprocessing steps.

Moreover, variables can only be substituted by the expressions bound to them if both have the same type. As described in
Section~\ref{impl-post-types} this is in general not the case for the code generated by the translation phase. Therefore, all steps
which process and remove type clashes by changing the additional type information for expressions must be executed before the
simplification by \code{letproc}, until no type clashes remain. These steps are \code{bangproc} and \code{ebangproc} (\ref{impl-post-bang}),
\code{maynullproc} (\ref{impl-post-null}), \code{boolproc} (\ref{impl-post-bool}), \code{stringproc} (\ref{impl-post-string}),
\code{intproc} (\ref{impl-post-int}), and \code{pointerproc} (\ref{impl-post-pointer}) which are all implemented in the module
\code{Gencot.Cogent.Post.MatchTypes}.

The following dependencies are taken into account for the order of these postprocessing steps:
\begin{itemize}
\item The \code{ebangproc} step is executed after \code{bangproc} because it is most effective if all readonly type clashes
have been resolved for which that is possible.
\item The \code{maynullproc} step includes nonlocal code transformations when it splits conditions. This may be complicated when
variable bangings are present. Therefore it is executed before \code{bangproc}. Although it extends the generated code by introducing
\code{match} expression which contain additional positions for variable bangings, such bangings are never possible in the generated
\code{match} expressions. Therefore, these bang positions need not be taken into account by \code{bangproc}.
\item The \code{maynullproc} step depends on recognizing NULL tests. In C a NULL test can be specified by the pointer alone, which
is equivalent to the condition that it is not NULL. The \code{boolproc} step converts these cases into explicit NULL tests. Therefore
\code{maynullproc} is executed after \code{boolproc} because then it is sufficient to recognize explicit NULL tests.
\item The \code{intproc} step must be executed after \code{boolproc}, because that may convert boolean values to integer types
which must then be converted further. It is delayed until after \code{maynullproc}, \code{bangproc} and \code{ebangproc} so
that these need not process the additional bindings inserted for converting integer types.
\end{itemize}

The remaining postprocessing steps are \code{presimp}, (\ref{impl-post-let}), \code{romodproc} (\ref{impl-post-romod}),
\code{opnullproc} (\ref{impl-post-opnull}), and \code{tpproc} (\ref{impl-post-takeput}).
For them the following dependencies are taken into account:
\begin{itemize}
\item The \code{presimp} step removes bindings of unused variables. Other than for \code{letproc} type clashes are not a problem
for it. Therefore it may be applied before all type clashes are eliminated. Moreover, although it simplifies the Cogent code it
preserves the restricted form generated by the translation phase.
\item The \code{bangproc} step is more effective if unused values of non-escapeable type are removed, which would prevent banging
a scope from which returns them. Therefore \code{presimp} is executed before \code{bangproc}. Since it generally reduces the
code size and makes all other steps more efficient, \code{presimp} is executed as the first postprocessing step before all others.
\item Like the \code{presimp} step the \code{romodproc} step removes values of non-escapeable type and makes \code{bangproc}
more effective. The reason is that even if a container has readonly type it looks modified if accessed components are rebound.
This will prevent \code{bangproc} from discarding it when it is returned by a scope tried to be banged. Therefore, \code{romodproc}
is also executed before \code{bangproc}.
\item The \code{ebangproc} step is executed before \code{opnullproc} because the inserted NULL bindings would prevent \code{ebangproc}
from banging the corresponding variables.
\item A component may be re-bound but never used afterwards. In this case \code{romodproc} should not signal it as an error.
Since \code{presimp} removes all such unused bindings, \code{romodproc} is executed after \code{presimp}, so that it need not
consider the usage of re-bound components.
\item The \code{opnullproc} step can only be executed after \code{maynullproc} has inserted the operations \code{mayNull} and
\code{notNull}.
\item The \code{tpproc} step depends on the types of containers and components to decide how to process take/put pairs. Therefore
it must be executed after all steps which may modify the type of an expression.
\end{itemize}

The execution of every postprocessing step can be suppressed by adding a letter to the translation configuration string (see
Section~\ref{impl-ccomps-main}).

The resulting order of postprocessing steps with their suppress letters is
\begin{verbatim}
  p presimp
  r romodproc
  c boolproc
  n maynullproc
  b bangproc
  e ebangproc
  i intproc
  m opnullproc
  t tpproc
  l letproc <-
  f ifproc   |
  o opproc  -|
\end{verbatim}
The last three steps are repeated until no more changes occur. This order and the suppressing of steps is implemented
in module \code{Gencot.Cogent.Post.Proc}.
