 

\subsection{Including Files}

The filter \code{gencot-include <dirlist>} processes all quoted include directives and replaces them (transitively) by the 
content of the included file. Line directives are inserted at the begin and end of an included file, so that
for all code in the output the original source file name and line number can be determined. The \code{<dirlist>}
specifies the directories to search for included files.

\subsubsection{Filter \code{gencot-include}}

The filter for expanding the include directives is implemented as an awk script, heavily inspired by the ``igawk''
example program in the gawk infofile, edition 4.2, in Section 11.3.9.

As argument it expects a directory list specified with ``:'' as separator. The list corresponds
to directories specified with the \code{-I} cpp option, it is used for searching included files.
All directories for searching included files must be specified in the arguments, there are no defaults.

Similar to cpp, a file included by a quoted directive is first searched in the directory of the including file. 
If not found there, the argument directory list is searched.

Since the input of \code{gencot-include} is read from standard input it is not associated with a directory. Hence
if files are included from the same directory, that directory must also be specified explicitly in an argument directory
list.

\subsubsection{Generating Line Directives}

Line directives are inserted into the output as follows.

If the first line of the input is a line directive, it is copied to the output. Otherwise 
the line directive
\begin{verbatim}
  # 1 "<stdin>"
\end{verbatim}
is prepended to the output.

If after a generated line directive with file name \code{\"fff\"} the input line \code{NNN} contains the 
directive 
\begin{verbatim}
  #include "filepath"
\end{verbatim}
the directive is replaced in the output by the lines 
\begin{verbatim}
  # 1 "dir/filepath" 1
  <content of file filepath>
  # NNN+1 "fff" 2
\end{verbatim}

The \code{\"dir/\"} prefix in the line directives for included files is determined as follows. 
If the included file has been found in the 
directory of its includer, the directory pathname is constructed from \code{\"fff\"} by taking the pathname 
up to and including the last ``/'' (if present, otherwise the prefix is empty).
If the included file has been found in a directory from the argument directory list
the directory pathname is used as specified in the list.

\subsubsection{Multiple Includes}

The C preprocessor does not prevent a file from being included multiple times. Usually, C include files use
an ifdef directive around all content to prevent multiple includes. The \code{gencot-include} filter does
not interprete ifdef directives, instead, it simply prevents multiple includes for all files independent 
from their contents, only based on their full file pathnames. To mimic the behavior of cpp, if a file is 
not include due to repeated include, the corresponding line directives are nevertheless generated in the form
\begin{verbatim}
  # 1 "dir/filepath" 1
  # NNN+1 "fff" 2
\end{verbatim}

\subsection{Preprocessing}

The language-c parser supports an integrated invocation of an external preprocessor, the default is to use
the gcc preprocessor. However, the integrated invocation always reads the C code from a file (and checks
its file name extension) and not from standard input.

To implement C code processing as a filter, Gencot does not use the integrated preprocessor,
it invokes the preprocessor as an additional separate step. For consistency reasons it is wrapped in
the minimal filter script \code{gencot-cpp}. 

The preprocessor step only has the following purpose:
\begin{itemize}
\item process all system include directives by including the file contents,
\item process retained conditional directives to prevent conflicts in the C code.
\end{itemize}
All other preprocessing has already been done by previous steps.

\subsection{Reading the Input}

\subsubsection{Parsing}

To apply the parser to the standard input we invoke it using function \code{parseC}. It needs an \code{InputStream}
and an initial \code{Position} as arguments. 

The language-c parser defines \code{InputStream} to be the standard type \code{Data.ByteString}. To get the 
standard input as a \code{ByteString} the function \code{ByteString.getContents} can be used. 

The language-c parser uses type \code{Position} to describe a character position in a named file. It provides
the function \code{initPos} to create an initial position at the beginning of a file, taking a \code{FilePath}
as argument, which is a \code{String} containing the file name. Since Gencot and the C preprocessor create
line directives with the file name \code{\"<stdin>\"} for the standard input, this string is the correct argument
for \code{initPos}. 

The result of \code{parseC} is of type \code{(Either ParseError CTranslUnit)}. Hence it should be checked whether
an error occurred during parsing. If not, the value of type \code{CTranslUnit} is the abstract syntax tree for
the parsed C code.

Both \code{parseC} and \code{initPos} are exported by module \code{Language.C}. The function \code{ByteString.getContents}
is exported by the module \code{Data.Bytestring}. Hence to use the parser we need the following imports:
\begin{verbatim}
import Data.ByteString (getContents)
import Language.C (parseC,initPos)
\end{verbatim}

Then the abstract syntax tree can be bound to variable \code{ast} with
\begin{verbatim}
do
  input_stream <- Data.ByteString.getContents
  ast <- either (error . show) return $ parseC input_stream (initPos "<stdin>")
\end{verbatim}

\subsubsection{Analysis}

The language-c parser supports an additional ``analysis'' module for further processing the abstract syntax tree.
Although it is not complete and only processes toplevel declarations (including typedefs), and object definitions, it is very
useful for implementing Gencot translation. Function definition bodies are not covered by analysis, but they are
not covered by Gencot either.

The result of the analysis module is a map for all toplevel declarations and object definition, mapping the identifier
to its semantics, which is mainly its declared type. Whereas in the abstract syntax tree there may be several declarators
in a declaration, declaring identifiers with different types derived from a common type, the map maps every identifier
to its fully derived type. 

Also, tags for structs, unions and enums are contained in the map. In C their definitions can be embedded in other declarations.
The analysis module collects all these possibly embedded declarations in the map. The map also gives for every defined type name
the definition.

Together, the information in the map is much more appropriate for creating Cogent code, where all type definitions are on
toplevel. Therefore, Gencot uses the map resulting from the analysis step as starting point for its translation.

To use the analysis module, the following import is needed:
\begin{verbatim}
import Language.C.Analysis
\end{verbatim}

Then, if the abstract syntax tree has been bound to variable \code{ast}, it can be analysed by
\begin{verbatim}
  globals <- either (error . show) (return . fst) $ runTrav_ $ analyseAST ast
\end{verbatim}
which binds the resulting map to variable \code{globals}. \code{runTrav\_}
returns a result of type \code{Either [CError] (GlobalDecls, [CError])}, where \code{GlobalDecls}
is the semantics map. The error list in the first alternative contains fatal errors which made the analysis fail. 
The error list in the second alternative contains warnings about semantic inconsistencies, such as unknown identifiers,
which are returned together with the map. 

\subsubsection{Source Code Origin}

\subsection{Generating Cogent Code}

\subsubsection{Cogent Surface Syntax Tree}

\subsubsection{Extending the Cogent Surface Syntax}
