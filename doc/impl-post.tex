The Cogent code generated for C expressions and statements in the first translation phase as described in 
Section~\ref{impl-ccode-cexpr} and~\ref{impl-ccode-cstats} is in general neither correct nor efficient.
Therefore it must be improved, which is done by postprocessing. The postprocessing is done directly in the Cogent AST.

This approach taken by Gencot has several advantages over generating the Cogent code in a single phase.
First, the actual translation step ist rather simple and straightforward. Second, the postprocessing
is done on a restricted subset of a purely functional language where
there is no difference between statements and expressions, so it tends to be simpler. Third, it can be separated
into arbitrary many different processing steps which can be freely combined, since they all process the same
data structures (the Cogent AST). The drawback is that the code generation is not very efficient, because it
first builds a quite voluminous code which is then simplified by the postprocessing. However, the quality 
of the resulting code has been considered more important than the performance of the Gencot translation.

In the following sections the postprocessing steps are described independently of each other and the last
section describes how they are combined.

Every postprocessing step corresponds to a transformation from a Cogent expression to a Cogent expression.
All required information is already present in the processed expression, in particular, the Cogent types
which have been added as described in Section~\ref{impl-ccode-type}. The C symbol table and other global state
information is not used. However, a postprocessing step may detect error situations. In this case usually a
dummy expression is inserted into the Cogent AST, as described in Section~\ref{design-cstats-dummy}, and an
error message is registered for display. For the latter the language-c \code{Trav} monad is used, as described
in Section~\ref{impl-ccode-trav}. Since no other global information is required, the monad is always used
with an empty user state and an empty symbol table. The type \code{ETrav} is defined in module
\code{Gencot.Cogent.Post.Util} for monads of this kind.

All postprocessing steps are defined in submodules of \code{Gencot.Cogent.Post}, they are either implemented
by a monadic action of the form
\begin{verbatim}
  Xproc :: GenExpr -> ETrav GenExpr
\end{verbatim}
or, if no error messages are generated, by a Haskell function of the form
\begin{verbatim}
  Xproc :: GenExpr -> GenExpr
\end{verbatim}

Postprocessing is applied to all expressions which occur in the generated Cogent program. These are function 
body expressions, the expressions in constant definitions, and the expressions in array type size specifications.

\subsection{Restricted Form of the Cogent AST}
\label{impl-post-ast}

The Cogent AST generated by the translation described in Sections~\ref{impl-ccode-cexpr} and~\ref{impl-ccode-cstats}
is highly restricted: it only uses some of the constructs and uses them in specific restricted form. The postprocessing
implementation exploits these restrictions and most postprocessing steps preserve them for being exploited by following
steps.

The Cogent AST types are defined in the Cogent implementation in module \code{Cogent.Surface}. Syntactic expressions
are defined by the datatype \code{Expr}. Gencot only uses the following expression variants: \code{Unitel} for the unit
expression, \code{IntLit, BoolLit, CharLit, StringLit} for literals, \code{Var} for variable references, \code{Tuple}
for tuple expressions, \code{PrimOp, App} for applications of operators and functions, \code{Match, If} for conditional
expressions, \code{Let} for expressions with variable bindings, \code{Lam} for lambda expressions, \code{TLApp} for
specifying instances of polymorphic functions, \code{Member} for record member accesses, \code{Put, ArrayPut} for record
and array put operations, and \code{UnboxedRecord} for unboxed record structures.

The variants \code{BoolLit, Match, Member} are only inserted during postprocessing. The variant \code{TLApp} is only
used for specifying instances of the Gencot operations which are usually polymorphic. The variants \code{UnboxedRecord}
and \code{Lam} are only used for specifying the arguments of the \code{repeat} operation in translations of loops.

Additional restrictions are the following. Here a ``variable tuple'' means either a \code{Tuple} expression where all
sub expressions are \code{Var} expressions or a single \code{Var} expression. A ``control tuple'' means either a
\code{Tuple} expression where the first sub expression is an \code{IntLit} expression and the other sub expressions
are \code{Var} expressions or a single \code{IntLit} expression. A ``variable record'' means an \code{UnboxedRecord}
expression where all sub expressions are \code{Var} expressions.

The body of a \code{Let} expression is either a variable or control tuple or an \code{If} or \code{Match} expression.
The branch of an \code{If} or \code{Match} expression is either a variable or control tuple or a \code{Let} expression.
The body of a \code{Lam} expression is a \code{Let} expression.

The arguments of a \code{PrimOp} expression are single \code{Var} expressions. The argument of an \code{App} expression
is a variable tuple or a variable record.

In a \code{Put} or \code{ArrayPut} expression the container expression is a \code{Var} expression and the list of put
specifications contains a single element where the put value is specified by a \code{Var} expression. In an \code{ArrayPut}
the put index is also specified by a \code{Var} expression.

Together, the structure of arbitrary deep syntax trees only consists of \code{Let}, \code{If}, and \code{Match} expressions.
All other variants only occur as bound expression in a binding and have as subexpressions only variable and control tuples and
variable records. Exceptions are \code{Lam} expressions where the body may be a \code{Let} expression and \code{App}
expressions where the function may be a \code{TLApp} expression.

This form of the AST has the property that for every subexpression it is possible to modify the value and/or type of
a variable occurring free in it by inserting a binding which (re-)binds the variable to an expression for the modified value
so that only the subexpression is in the scope of the binding. For a \code{Let} expression the binding is inserted at the
beginning of its binding sequence. For the body of a \code{Let} expression the binding is inserted at the end of its
binding sequence. If the bound expression \code{e} in a binding is no \code{Let} expression the binding can be transformed
by the rule
\begin{verbatim}
  (v,v1..) = e
  -->
  (v,v1..) = let b and (v,v1..) = e in (v,v1..)
\end{verbatim}
where \code{b} is the inserted binding with \code{e} in its scope. Alternatively, \code{b} can be inserted in the binding
sequence before the binding of \code{e}, if it is no problem that it also affects the following bindings and the \code{Let}
body. This technique of inserting additional bindings is used by several postprocessing steps.

\subsection{Evaluating Constant Expressions}
\label{impl-post-const}

In several cases the original translation phase or postprocessing steps result in constant expressions built
from predefined operators. Such expressions can be statically evaluated and the resulting constant then may
enable other postprocessing steps. Therefore a constant expression evaluation is defined as auxiliary 
function for other postprocessing steps. It never detects and signals an error. Therefore it is implemented
by the function
\begin{verbatim}
  evalproc :: GenExpr -> GenExpr
\end{verbatim}
defined in module \code{Gencot.Cogent.Post.Simplify}.

The \code{evalproc} step is not applied on its own to arbitrary expressions. The reason is that a constant
expression may be intentionally present in the C program to show how a value is calculated. In that case the 
translation should also result in a constant expression in Cogent. Only if the evaluation is useful for other 
postprocessing steps it is applied.

The \code{evalproc} step only processes operator expressions. For them it recurses into the arguments. If all arguments
are constants it evaluates the operator and replaces the expression by the resulting constant. All other forms
of expressions are left unmodified, in particular, \code{evalproc} does not recurse into subexpressions which are
not operator applications.

\subsection{Simplifying Operator Application}
\label{impl-post-op}

If an expression cannot be completely evaluated statically, there are cases where it can be simplified.
The following cases are implemented by Gencot postprocessing.

If the first argument of a boolean operation evaluates to a constant the operation can be simplified according 
to the rules
\begin{verbatim}
  True  || e --> True
  False || e --> e
  True  && e --> e
  False && e --> False
\end{verbatim}
Currently only the first argument is treated this way, because only that case occurs in actual examples of translation
and postprocessing, mainly for the translation of \code{switch} statements.

Simplifying operator expressions using these rules never detects and signals an error, therefore is implemented by the function
\begin{verbatim}
  opproc :: GenExpr -> GenExpr
\end{verbatim}
defined in module \code{Gencot.Cogent.Post.Simplify}.

\subsection{Simplifying \code{let}-Expressions}
\label{impl-post-let}

One of the simplest and most straightforward postprocessing steps is substitution of bound variables by the
expression bound to them. In Cogent variables can be bound by \code{let} expressions and by \code{match} and \code{lambda}
expressions. Variables bound in \code{match} and \code{lambda} expressions can usually only be substituted in special cases, 
therefore this processing step only substitutes variables bound in \code{let} expressions. 

The basic transformation is for an expression
\begin{verbatim}
  let v = expr1 in expr2
\end{verbatim}
to replace it by \code{expr2} where every free occurrence of \code{v} is substituted by \code{expr1}. This is only 
possible if after the substitution all free variables in \code{expr1} are still free in the resulting expression, i.e., 
they are not ``drawn under a binding'' in \code{expr2}. This could be avoided by consistent renaming of variables bound in 
\code{expr2}. Gencot never renames variables and does not substitute in this case.

The Gencot translation may produce code where the types of \code{v} and \code{expr1} differ. Then the type differences are
resolved by postprocessing, as described in Section~\ref{impl-post-types}. If the substitution would be performed before,
it may be more difficult to resolve the difference, because the variable and its type have been eliminated and the type
difference may now occur between \code{expr1} and its context in \code{expr2} at several places. Therefore Gencot performs
the substitution only if the types of \code{v} and \code{expr1} are the same.

This scheme can directly be extended to expressions of the form \code{let v1 = e1 and ... vn = en in e} using the
equivalence to an expression of the form \code{let v1 = e1 in let ... in let vn = en in e}.

As of February 2022, Cogent does not support closures for lambda expression. This means that a lambda expression must not
contain free variables, therefore lambda expressions in \code{expr2} are never inspected for substituting.

In a Cogent \code{let} expression instead of a variable \code{v} an (irrefutable) pattern \code{p} can be used:
\begin{verbatim}
  let p = expr1 in expr2
\end{verbatim}
An irrefutable pattern
is a variable or wildcard or it is a pattern for a tuple, record, array or the unit value were the components are again
irrefutable patterns. In other words, it is a complex structure of variables which is bound to an expression \code{expr1}
of a type for which the values have a corresponding structure. Every variable may occur only once in a pattern.

Currently, the translation phase only creates bindings with patterns which are either a single variable, or a flat tuple pattern where
all components are variables, or a take pattern where all sub patterns are variables. The postprocessing does not
introduce more complex patterns. However, to make the code more robust, these restrictions are not assumed for binding processing,
the processing is always implemented to work for arbitrary patterns.

If the pattern occurs as a whole in \code{expr2} it can be
substituted by \code{expr1} as described above. If only parts of the pattern occur (such as a single variable) it depends
on the structure of \code{expr1} whether such a part can be substituted. Gencot tries to substitute as much parts as possible 
and only retains those parts of the pattern for which a substitution is not possible.

If the substitution is successful the \code{let} expression is replaced by \code{expr2} which may again be a \code{let}
expression or any other kind of expression. Therefore the simplification may reduce the number of \code{let} expressions
and may replace a \code{let} expression by an expression of another kind.

Substitution of bound variables may lead to exponentially larger code, which must be avoided. Gencot uses an expression metrics
which roughly measures the size of the printed expression in the Cogent surface syntax. A binding is only substituted if the 
resulting expression is not much larger than the original \code{let} expression.

Simplifying a \code{let} expression by substitution can reduce the variables which occur free in it. This is the case if no
parts of the pattern \code{p} occur free in \code{expr2}, then \code{expr1} is removed and all variables which only occur free
in \code{expr1} are removed with it.

Simplifying \code{let} expressions can never detect and signal an error, therefore it is implemented by the function
\begin{verbatim}
  letproc :: GenExpr -> GenExpr
\end{verbatim}
defined in module \code{Gencot.Cogent.Post.Simplify}.

\subsubsection{Processing Subexpressions}

When an expression \code{let p = expr1 in expr2} is simplified, first the subexpressions \code{expr1} and \code{expr2} are
simplified by processing all contained \code{let} expressions. Simplifying \code{expr1} has the following advantages for the 
substitution:
\begin{itemize}
\item The resulting expression usually is smaller. Then its substitution into \code{expr2} leads to a lower increase of
size and may be allowed whereas substitution of the original \code{expr1} would not be accepted.
\item Simplifying may reduce the free variables so that it may be possible to substitute it in more places than
the original expression without drawing free variables under a binding.
\item If \code{expr1} is again a \code{let} expression the pattern can only be substituted as a whole. After simplification 
it may have a form which corresponds more with the pattern so that also parts of the pattern can be substituted.
\end{itemize}
Simplifying \code{expr2} has the following advantages for the substitution:
\begin{itemize}
\item Simplifying may reduce the free variables so that there are fewer places for substituting the pattern
or parts of it. This may allow substitutions of patterns which where not possible in the original \code{expr2}.
It may also allow substitutions which would have lead to a too large growth of the original \code{expr2}.
\end{itemize}

Since an expression \code{let p1 = expr1 and p2 = expr2 in expr3} is equivalent to \code{let p1 = expr1 in (let p2 = expr2
in expr3)} this means that a sequence of bindings connected by \code{and} in a \code{let} expression is processed
from its end backwards.

\subsubsection{Pattern Substitution}

If (after its simplification) \code{expr1} has the same structure as the pattern \code{p} the binding could be split and 
the parts could be substituted independently. This would correspond to the transformation of the binding \code{p = expr1}
to the sequence 
\begin{verbatim}
  p1 = expr11 and ... pn = expr1n
\end{verbatim}
where the \code{pi} are the subpatterns of \code{p} and the \code{expr1i} are the corresponding subexpressions of \code{expr1}.
Note that the variables in the \code{pi} are pairwise disjunct since every variable may occur only once in \code{p}.
Then the sequence could be processed from its end, as described above.

However, the transformation is only correct, if no variable in \code{pi} occurs free in an expression \code{expr1j} with 
\code{j > i}, otherwise the transformation would draw it under the binding \code{pi = expr1i}. It could be tried to sort
the bindings to minimize this problem but in general it cannot be avoided. Additionally, there may be cases where \code{expr1}
even after its simplification has no structure corresponding with that of \code{p}, which also prevents the transformation.

For this reason, instead of transforming the binding and substituting it sequentially, Gencot deconstructs the pattern while
searching for matches. Whenever it searches the binding \code{p = expr1} in an expression (starting with \code{expr2}) 
it determines the variables occurring free in the expression and ``reduces'' the binding to these. Reducing a binding to
a set of variables is done by first replacing in \code{p} all variables which are not in the set by a wildcard (underscore) 
pattern. This is always possible. Then it is tried to remove as much wildcard parts from the binding, this is only possible if
the corresponding part can be removed from \code{expr1}. If \code{p} is a tuple pattern where some components are wildcards
they can be removed if \code{expr1} is a corresponding tuple expression. If \code{expr1} is an application of a function to
an argument the wildcard parts cannot be removed, since the tuple returned by the function is not available.

If no variable in the set occurs in the pattern all variables are replaced by wildcards and the binding is reduced to the 
empty binding, represented by the ``unit binding'' \code{() = ()}.

If after reducing it the binding is not empty, it is matched with the expression, which is successful if it has the same structure with the same
variables (which is only possible if the pattern contains no wildcards). If it matches the search stops, if not the binding 
is searched recursively in all subexpressions (by first reducing it to the subexpression). When the search reaches a single 
variable, the binding has been reduced to that variable. If the pattern consists of the same variable it matches there.

Otherwise the pattern is empty or it contains the variable together with other parts which means that it cannot be used to substitute the 
variable at that position in the expression. In this case at least the binding for that variable must be retained. Gencot 
determines all variables in \code{expr2} for which that is the case. Then it reduces the original binding \code{p = expr1}
to that set to determine the binding \code{p' = expr1'} which must be retained in the \code{let} expression. Only if no
such variable exists the binding can be completely removed from the \code{let} expression.

If \code{p} contains a \code{take} pattern for a record or array it can only match a \code{put} subexpression 
of exactly the same form in \code{expr2}. That is only present if the component is taken and put back without modifying it or the 
remaining record or array. In this case the \code{put} expression is replaced by the part of \code{expr1} corresponding to 
the \code{take} pattern. Wildcards in a \code{take} pattern can only be removed if the corresponding part of \code{expr1}
is a \code{put} expression.

Even if a part of the binding successfully matches in \code{expr2}, substitution may be prevented because it would draw a 
free variable in \code{expr1} under a binding. Such a binding may be the retained part of the original binding or it may 
be a binding in a \code{let} subexpression which has been retained during the simplification of \code{expr2}
or it may be a binding in a \code{match} expression which is not processed by the simplification. These cases are handled
by splitting the binding for which matches are searched whenever it is drawn under another binding in a (maximal) part allowed
to draw under the binding and a rest which must be retained. The rest is still searched under the binding to determine whether
the variables in it occur at all, if that is not the case it is not required in the expression and is not retained.

A binding is split according to a set of variables not to occur free by first determining all bound variables so that the 
corresponding part of the bound expression contains a free occurrence of a variable from the set. Then the binding is reduced
to this set and to its complement, yielding the binding to retain and the binding for substitution.

If \code{expr1} is a \code{let} or \code{if} expression or a match expression the binding cannot be reduced or split directly.
In these cases Gencot constructs the reduced or split binding by recursively reducing or splitting the subexpressions (the 
let-body, the if-branches, the match-alternatives).

The substitution and binding simplification is implemented in two phases. In the first phase the matches for the pattern are 
searched in \code{expr2}, resulting in the part to be retained and for every matching part the number of successful matches
The matching parts are actually substituted in \code{expr2} in the second phase. If the retained part is not empty it is 
prefixed to the result.

\subsubsection{Banged Variables}

A binding may have ``banged'' variables, i.e., be of the form
\begin{verbatim}
  p = expr1 !v1 ... !vn
\end{verbatim}
which makes the variables \code{v1,...,vn} readonly in \code{expr1}. Banged variables are introduced by readonly processing 
(see~\ref{impl-post-readonly}). Simplification of \code{let}-expressions may be executed after readonly processing, therefore it
must deal with banged variables.

In Cogent banged variables can only appear at specific places in the code: in a \code{let} binding, in a \code{match}-expression, 
and in the condition of an \code{if}-expression. Therefore it is in general not possible to substitute (a part of) the pattern \code{p}
at arbitrary occurrences in \code{expr2} by \code{expr1} together with the banged variables. Gencot never tries, it retains those
parts of the binding in which the banged variables occur free in \code{expr1}.

The same mechanism for splitting a binding used to prevent drawing variables under a binding is used for banged variables. Whenever
a binding is split, the banged variables are added to the set of variables not to occur free.

\subsubsection{Growth Restriction}

As size metrics for an expression the number of characters appearing in its surface representation is used. It could be determined
by actually prettyprinting the expression and measuring the size of the resulting string. However, it is assumed to be more
efficient to traverse the expression and calculate the size from the number of characters in the names and literals and in
the keywords, special characters and separating blanks needed for constructing composed expressions.

After the first phase the metrics of the \code{let} expression is calculated. Since for each matching part to be substituted it 
has been determined in the first phase how often it occurs in \code{expr2} the metrics for the simplified expression can be 
calculated and it is known how much each subpattern contributes to its size. If the size is larger than for the original 
expression and its growth exceeds a fixed limit factor additional binding parts are determined which are retained. 
Beginning with the binding part with the largest contribution, parts are retained until the growth is below the limit.

Instead of only taking its contribution to the size into account, binding parts could also be selected according to the kind of
variables they contain. 
Gencot uses different kinds of variables in its generated code (see Section~\ref{impl-ccode-cexpr}): value variables, component
variables, the control and result variables, and variables corresponding to C object names. These could be prioritized
as follows: first as many value 
variables are substituted as possible in a complete expression, then the control variables, then the component variables and
finally the C object names. In this way the most ``technical'' variables are substituted before the more ``semantical''.

The reference metrics is calculated for the expression after simplifying its subexpressions. This means that the growth limit factor
applies to every subexpression simplification step separately. This has two implications. First, a subexpression simplification
may strongly reduce the size of the subexpression and that may also reduce the size of the \code{let} expression, which becomes 
the reference for its own simplification. Thus it is not possible to tolerate a larger growth after strongly reducing the size for
subexpressions. Alternatively, the reference size could be measured before simplifying the subexpressions. In the code generated
by Gencot there are typically large nestings of \code{let} expressions with unnecessary ``chain bindings''. It is assumed that it
does not yield good results when these unnecessary large expressions are used as reference, therefore Gencot uses the first approach.

Second, in the worst case each simplification step grows the expression by the limit factor which still results in an overall exponential growth
relative to the number of subexpressions. Therefore the growth limit factor should not be much larger than 1. The effect of this
factor and a good selection for it must be determined by practical tests. Alternatively the factor could be specified as an input 
parameter for Gencot so that it can be selected specifically for every translated C program.

\subsubsection{Pre-Simplifying Unused Variables}

If in an expression
\begin{verbatim}
  let p = expr1 in expr2
\end{verbatim}
a variable bound in \code{p} does not occur free in \code{expr2} it can be removed from the binding \code{p = expr1} as described above,
without substituting it in \code{expr2}. This case is much simpler than the general case described above in several aspects:
\begin{itemize}
\item it is not necessary to search for matchings in \code{expr2},
\item it is not possible to draw free variables in \code{expr1} under a binding,
\item the expression will never grow by the simplification,
\item type differences between \code{p} and \code{expr1} do not matter.
\end{itemize}

The Gencot translation produces many such cases of unused variables, because it translates expressions without regarding whether
their values are used in the context. For example, the value of an assignment expression is normally not used in the context. On the
other hand unused variables may prevent resolving a type difference by banging, if the variable has non-escapeable type (possibly
caused by the banging itself) and leaves the scope of the banging. Therefore it is crucial to remove bindings of unused variables
early during postprocessing, in particular, before trying to apply banging, whereas normal simplification of \code{let} expression
is only done after resolving type differences. Early removal of unused variables is called pre-simplification here.

An exception is made for \code{put} operations. Every \code{put} binding is always generated together with a preceding \code{take}
binding and both are usually also processed together (see Section~\ref{impl-post-takeput}). If only the component variable of a
\code{take} binding is used but not the container variable, pre-simplification would remove the \code{put} binding and would preserve
the \code{take} binding. Since the \code{put} bindings do not affect the banging possibilities, they are excluded from
pre-simplification. Since every \code{put} binding uses both the container and component variable of the corresponding \code{take}
binding, that will always be preserved as well.

Pre-simplification is facilitated by implementing the removal of unused variables in a separate postprocessing step
\begin{verbatim}
  presimp :: GenExpr -> GenExpr
\end{verbatim}
also defined in module \code{Gencot.Cogent.Post.Simplify}. Thus it can be applied independently from \code{letproc}. Note, that
\code{letproc} will still remove variables which have become unused by other postprocessing steps after applying \code{presimp}.

\subsection{Simplifying If-Expressions}
\label{impl-post-if}

The most straightforward simplification of a conditional expression is replacing it by one of the branches, if the condition can be
statically evaluated. Gencot tries this, by recursing into the condition and then using \code{evalproc} (see Section~\ref{impl-post-const})
for evaluating the condition, before it recurses into the branches. This avoids processing a branch which is removed afterwards. 
If the condition cannot be statically evaluated, both branches are processed recursively.

\subsubsection{Other Used Transformations}

Afterwards, the following additional simplification rules are applied, if possible.
\begin{itemize}
\item If both branches are the same expression, the conditional expression is replaced by this expression.
\item If both branches statically evaluate to a boolean constant, the conditional expression is replaced
by the condition or the negated condition according to the rules
\begin{verbatim}
  if c then True else False --> c
  if c then False else True --> not c
\end{verbatim}
\item The condition is substituted by \code{True} in the \code{then} branch and by \code{False} in the \code{else} branch. This 
may enable additional simplifications in subsequent iterations (see Section~\ref{impl-post-combine}).
\end{itemize}

The following rule is applied to operator expressions where the first argument is a conditional expression and the second argument
can be statically evaluated:
\begin{verbatim}
  (if c then e1 else e2) <op> e -->
  if c then e1 <op> e else e2 <op> e
\end{verbatim}
This transformation may enable the static evaluation of the resulting branches. 

All these rules have been selected, because they specifically apply to conditional expressions resulting from the Gencot translation
and postprocessing, in particular for the control variable.

Simplifying \code{if} expressions using these rules never detects and signals errors, therefore it is implemented by the function
\begin{verbatim}
  ifproc :: GenExpr -> GenExpr
\end{verbatim}
defined in module \code{Gencot.Cogent.Post.Simplify}.

\subsubsection{Unused Transformations}

Other rules would transform conditional expressions where one branch can be statically evaluated to a boolean value according to
\begin{verbatim}
  if c then True else e  --> c || e
  if c then False else e --> not c && e
  if c then e else True  --> not c || e
  if c then e else False --> c && e
\end{verbatim}
This is not used, because it removes boolean constants which may be useful for static evaluation after other processing steps.

Other rules for simplifying conditionals with boolean values are
\begin{verbatim}
  if c then e else not e --> c == e
  if c then not e else e --> c /= e
\end{verbatim}
These are not used because they turn conditional expressions into equations, which currently are not processed any further.

If a branch is again a conditional expression, the following transformation is possible:
\begin{verbatim}
  if c then (if c' then e1 else e2) else e -->
  if c' then (if c then e1 else e)
        else (if c then e2 else e)
\end{verbatim}
It is not used because it duplicates expression \code{e} and does not reduce the structure of conditional expressions,
so there is the danger of cyclic transformation.

Another rule would split conditional tuples into a tuple of conditionals according to
\begin{verbatim}
  if c then (t1,..,tn) else (e1,..,en) --> 
  (if c then t1 else e1, .., if c then tn else en)
\end{verbatim}
which would allow further simplification for all components with \code{ti = ei} and it could allow additional substitutions
by \code{letproc}, because the components can be substituted or omitted separately. However, if both are not applicable, it 
tends to enlarge the expression by copying the condition \code{c}. Therefore the effect on \code{letproc} has been implemented
there by the way how conditional expressions are split and the rule is not used here for \code{ifproc}.

The substitution of the condition in the branches could be generalized by substituting values for variables which can be
inferred from the condition, such as in
\begin{verbatim}
  if i == 0 then e1 else e2
\end{verbatim}
where it is possible to substitute \code{i} by \code{0} in \code{e1}. Even more general, the condition can be interpreted as
a set of equations for its free variables, if it can be solved for some of them they can be substituted by their solution
in the first branch. It has not yet been considered whether such substitutions would have an effect that would pay for the 
additional complexity.

If the condition is itself a conditional expression, it may be possible to derive substitutions, although the condition does
not occur as a whole in the branches. As an example, the following transformation could be applied:
\begin{verbatim}
  if (if c then x else y) 
     then (if c then (if x then e1 else e2) else e3) 
     else e4 
  -->
  if (if c then x else y) 
     then (if c then e1 else e3)
     else e4
\end{verbatim}
It has not yet been considered, whether such transformations would be useful for cases occurring during translations of C programs.

\subsection{General Type Difference Processing}
\label{impl-post-types}

Even if the translated C program is type-correct, the Gencot translation may result in type incompatibilities in the generated
Cogent code. These originate from two possible sources:
\begin{itemize}
\item Type differences in the C program which are automatically resolved by the C compiler by conversions.
\item Application of item properties which affect the item's type during the Gencot translation.
\end{itemize}

The first case only occurs for C operators. They are conceptually polymorphic, the actual function is determined by the type
of the argument(s). For binary operators the argument types may be different, then in some cases they are adapted to a common
type which then determines the function of the operator. The same holds for the ternary conditional operator for the two
branches. Operators in C are either arithmetic, relational or comparison operators or the conditional operator. The first
two kinds are only applied to numeric arguments. Since Gencot does not support floating point types only integer arguments
are relevant here. The comparison operators \code{==} and \code{!=} can also be applied to pointer arguments and the branches
of a conditional operator can be of arbitrary type. In some cases the type differences can also be resolved in Cogent by
applying conversion functions, in other cases Gencot does not support a translation and signals an error.

The second case may occur for the item properties Read-Only, Not-Null, and No-String. All three only affect items of pointer
types. Since they may be specified manually, differences may be errors which should be detected and signaled by Gencot. In some
cases it is also possible to resolve differences by inserting conversions during postprocessing.

Most type incompatibilities have the form of a sub expression having one type and its context, where the sub expression occurs,
having a different type. Such type clashes can occur in the following situations:
\begin{itemize}
\item in a binding between the type of a variable in the pattern and the type of the corresponding component of the bound
expression. This will never happen for a value variable, since for them the type is always determined by the bound expression
component. It may happen for translated C variables and parameters and for component variables,
\item in a function application between the formal type of a parameter according the the function's type and the type of
the corresponding component of the actual argument tuple,
\item in an operator application between the expected type of the arguments and the actual argument types. Since C has no operators
for struct, union, and function types, the arguments can only be of arithmetic and pointer types, which includes after
translation the type \code{Bool} and all linear and array types.
\item between the arguments of a binary operator including the branches of a conditional expression. A binary operator in C
may be polymorphic and admit several argument types, but both arguments must be of the same type (possibly after automatic
conversion).
\end{itemize}

Whenever Gencot cannot resolve a type difference it signals an error and additionally replaces sub expressions with the wrong type
by dummy expressions which specify the error reason and have the correct expected type according to the context of the expression.
Thus, after processing them no type clashes remain in the resulting Cogent code, even if there where errors.

\subsection{Detecting Readonly Modifications}
\label{impl-post-romod}

Applying the Read-Only item property changes the item's Cogent type \code{t} to the readonly type \code{t!}. The main incompatibility
for values of readonly types occurs when they are modified. Modifications can only be applied to container values, by replacing
or setting a component.

As described in Section~\ref{impl-ccode-cexpr} container modifications are translated to a pair of \code{take}- and \code{put}-bindings
with a re-binding of the component variable to a new value in between. In case of a nested component there are several \code{take}-
and \code{put}-bindings surrounding the re-binding.

If the container has readonly type every modification of a component is an error, independent of the component type. Gencot detects
such modifications as follows: for every \code{take}-binding with readonly container type all bindings of the component
variable in their scope which are not \code{put}-bindings are modifications. A \code{put}-binding without a re-binding of the
component variable puts back the original value and does not cause a modification.

Since it is not possible to convert a readonly type back to a modifyable type these modifications cannot be corrected by
applying a conversion. Hence Gencot always signals an error message and also replaces the component variable in the erroneous
binding by the error variable \code{err'}. This will remove all such modifications, the resulting code never modifies a
readonly container. Since \code{err'} is never referenced the binding will be eliminated when unused variables are eliminated
in later postprocessing steps.

Postprocessing for detecting and removing modifications of readonly containers is implemented by the monadic action
\begin{verbatim}
  romodproc :: GenExpr -> ETrav GenExpr
\end{verbatim}
defined in module \code{Gencot.Cogent.Post.MatchTypes}.

\subsection{Readonly Processing}
\label{impl-post-bang}

Another incompatibility for readonly types are type clashes with the corresponding linear type. Since values of linear type
can be converted to values of readonly type by applying the ``bang'' operation, such type clashes may be resolved by conversion
so that both types are readonly.

However, the application of the bang operator in Cogent is strongly restricted. It cannot be applied to arbitrary expressions
but only to single variables. It can only be applied at specific positions in the code (at bindings, at conditions in conditional
expressions, and at match expressions). The effect of the bang operator is restricted to a scope determined by the position of
application. No value with escape-restricted type (containing a read-only part) may leave this scope. Due to these restrictions
a systematic construction of bang applications so that a maximum of readonly type clashes are resolved, is a complex optimization
problem.

Postprocessing for readonly processing is implemented by the monadic action
\begin{verbatim}
  bangproc :: GenExpr -> ETrav GenExpr
\end{verbatim}
defined in module \code{Gencot.Cogent.Post.MatchTypes}.

\subsubsection{Determine Variables for Banging and Changing their Types}

Gencot uses a specific heuristics to find bang applications which resolve readonly type clashes. Remaining clashes are then
resolved by dummy expressions and signaling them as errors. In such cases it may be possible to remove readonly type clashes
manually with the help of the Read-Only item property.

The heuristics only bangs variables which correspond to translated C variables and parameters. If a component variable would
be banged, the scope of the banging would either include the putback binding, which would cause a type clash with the type of
the container component, or it would exclude it, then the value has to leave the scope because it is required for the putback
binding, but that is not possible, since by banging it its type has become non-escapeable. If a value variable would be banged
this makes only sense if its single use is in the scope of the banging. But then the value outside the scope is not used, it
is discarded which is not allowed for a value of linear type in Cogent. If the result variable would be banged, it must always
leave the scope of the banging, since its value must be returned by the function body, again, that is not possible because its
type is non-escapeable by the banging. The other variable kinds (control, switch, and case variables) cannot have a linear
type, therefore banging is not applicable to them.

When Gencot searches for readonly type clashes which may be resolved by banging, it maintains a map of ``source variables'' for
value and component variables. These are the C variables which, if banged, change the type of the value variable or component
variable to readonly. For a component variable the source variables are those of the container. Usually, a variable has only
one source variable, but for a variable bound to a conditional expression there may be different source variables in the branches,
so in general every variable has a set of source variables. If the set is empty the variable's type cannot be made readonly
by banging variables, this is the case for example for a variable bound to the result of a function application.

The scope of a bang application is always an expression. In the case of a conditional, it is the condition expression, in the
case of a binding it is the bound expression.

When Gencot processes an expression as possible bang scope it searches all
contained readonly type clashes. If the subexpression at the type clash is of linear type and has source variables, so that
its type can be converted to readonly by banging the source variables they are collected. In all other cases the type clash
is signaled as an error and is resolved by replacing the sub expression by a dummy expression with the same type as for the
context. If the set of collected source variables is empty all readonly type clashes have been resolved without the need to
bang variables.

Otherwise in a next step the scope is traversed and for all expressions and patterns which depend on the collected source
variables the type is changed to readonly. This may cause new inconsistencies: either modifications of readonly containers
or readonly type clashes. The former are detected and treated as error, as described above, the latter are resolved by either
collecting additional source variables for banging or by treating them as error. This step is repeated as long as it collects
additional variables for banging. Since the scope only uses a finite number of variables the repetition terminates. If the
collected source variables are banged and the scope is replaced by the processed scope and this scope has an escapeable type
all readonly type clashes in it have been resolved.

\subsubsection{Selecting Bang Positions and Scopes}

As described in Section~\ref{impl-ccode-cexpr} Gencot translates C expressions in a way that they are either trivial and cannot
contain a readonly type clash, or they contain atleast one binding and thus a bang position. The heuristics tentatively tries
bang positions in bindings and conditions. Match expressions are not tried, they are always generated by NULL pointer processing
(see Section~\ref{impl-post-null}) in a way that banging the match will make its result non-escapeable.

The heuristics starts with the outermost bang positions, i.e. those with the largest bang scopes. If it is successful without
causing errors it uses the bang position by banging all variables in the collected set (which may be empty) and does not try
inner bang positions in the scope. If it caused errors but there are no inner bang positions in the scope it uses the bang
position with the processed scope and signals the corresponding errors. If there are inner bang positions the bang position
is not used at all, discarding all errors caused by the tentative processing, and processing recurses into the scope expression.
In this way the most effective bang positions (with the largest scope) are tried first.

A bang position may fail because the banged scope has a non-escapeable type. A condition in a conditional expression always
has type \code{Bool} which is escapeable, hence a non-escapeable type can only result for a bang position in a binding. There
it is treated as follows. First, the scope result is reduced as much as possible by removing unused parts from it.
This is done by performing the pre-simplification step \code{presimp} described in Section~\ref{impl-post-let} and the step
\code{romodproc} described above before processing readonly type clashes. Moreover, containers which are banged in the scope
are also removed, because although they may be used afterwards, they cannot be modified in the scope (otherwise the banging
would cause an error), therefore their value before the scope is still valid.

Second, if the result of a single binding prevents banging because it is not escapeable, it may be possible to bang the binding
together with subsequent bindings where the result of the first binding is used. Then the bindings form a common bang scope
and the result of the first binding is only used inside this scope and need not leave it.

A sequence of bindings can be converted to a common binding scope by converting it to a single binding in a similar way as by
the function \code{cmbBinds} described in Section ~\ref{impl-ccode-cexpr}. A binding sequence \code{b1, ..., bn} is converted
to the binding
\begin{verbatim}
  (v1,...,vm) =
  let b1 and ... and bn
  in (v1,...,vm)
\end{verbatim}
where the variables \code{v1,...,vm} are all variables bound in \code{b1, ..., bn} and used after the binding sequence, either
in subsequent bindings or in the body of the surrounding \code{let} expression.

When the heuristics processes a binding sequence it tries the scopes resulting from combined bindings in a similar way as it
tries scopes in general: it starts with the largest scope which results from converting the whole sequence to a single binding.
If not successful it removes bindings from the end of the sequence and tries the resulting smaller scopes until it reaches the
single first binding in the sequence. If that also causes errors it is used as it is, then the rest of the sequence is processed
in the same way. In this way all possible subsequences are tried as bang scopes.

\subsubsection{MayNull Operations}

The Gencot operations for \code{MayNull} types defined in Section~\ref{design-operations-null} must be treated in a specific
way since they are available both for linear and readonly types. Therefore, a readonly type clash for an argument or result
of such an operation can be resolved by replacing the operation. The relevant operations are \code{mayNull}, \code{notNull},
and \code{null} with their readonly alternatives \code{roMayNull}, \code{roNotNull}, and \code{roNull}. For the first two,
either the argument and result are both linear, or both readonly. Applications are generated by the NULL pointer processing
(see Section~\ref{impl-post-null}), it always inserts the linear version, independent of the argument type. The third is only
generated after readonly processing, it is still present in the form of the value \code{cogent\_NULL}.

Occurrences of \code{NULL} in C are treated as follows. They are syntactically translated by Gencot to a reference to a
variable \code{cogent\_NULL} of type \code{MayNull CVoidPtr}. Instead of banging this variable, the type of every single
occurrence may be converted to readonly type, if necessary. This is implemented by temporarily renaming every occurrence of
\code{cogent\_NULL} to \code{cogent<n>\_NULL} where \code{<n>} is a unique number. The heuristics then adds all instances
with a readonly type clash to the source variables collected for banging as usual. Thus their types and that of all variables
with them as source are converted to readonly. For the actual banging these variables are omitted.

Applications of \code{mayNull} may occur at arbitrary places in the generated code, the result type is readonly whenever the
argument type is readonly. Thus, if the argument is affected by banging variables, it transfers to the result. This is taken
into account by transferring the source variables from argument to result. Then readonly type clashes between a linear result
and its context can be resolved as usual. If the result is readonly and the context is linear, the corresponding type clash
existed between the argument and the context before \code{mayNull} has been inserted, thus the clash is resolved as usual
by replacing the \code{mayNull} application by a dummy and signaling an error. If

Applications of \code{notNull} occur only in a match expression in the form
\begin{verbatim}
  notNull v
  | Nothing -> let v = cogent_NULL in e1
  | Some v -> e2
\end{verbatim}
where \code{v} is a C variable or component variable.

Here, whenever the type of \code{v} is readonly, the result of \code{notNull} and the two alternative patterns have readonly type,
thus there cannot be a readonly type clash for the result of \code{notNull} which could cause \code{v} to be banged. Therefore
the source variables of \code{v} need not be transferred to the result of \code{notNull}.

If the source variables of \code{v} are decided to be banged, the type of the result of \code{notNull} and the two patterns must
be converted to readonly, together with the type of the \code{v} pattern in the \code{Nothing} alternative. The type of
\code{cogent\_NULL} and for the occurrences of \code{v} in \code{e1} and \code{e1} will be converted as usual.

In all cases only the types of \code{mayNull} and \code{notNull} are converted, the operations are only replaced by their readonly
alternatives in a later processing step.

\subsection{Boolean Value Processing}
\label{impl-post-bool}

The type \code{Bool} is used in the Cogent AST although it does not result from translating a C type. As described in
Section~\ref{impl-ccode-type} it is specified by the translation for all results of applications of equational, relational,
and boolean operators. Moreover, it is implicitly expected for the arguments of boolean operators and for conditions in conditional
expressions. The use of type \code{Bool} can clash with all types which result from translating a C type which can be used to
represent a boolean value. These are all ``scalar'' types in C, which are the arithmetic types and the pointer types.

Arithmetic types are always translated to the Cogent integer types \code{U8, U16, U32,} and \code{U64}. Type clashes between
them and \code{Bool} can always be resolved by conversion. An expression \code{e} of integer type can be converted
to \code{Bool} by
\begin{verbatim}
  e /= 0
\end{verbatim}
because the type of the literal \code{0} is automatically adapted to the type of \code{e} here.

An expression \code{e} of type \code{Bool} can be converted to any arithmetic type by
\begin{verbatim}
  if e then 1 else 0
\end{verbatim}
because the literals \code{1} and \code{0} are automatically adapted to the expected arithmetic type.

Pointer types are translated to linear types and are represented by boxed record types or boxed abstract types, possibly wrapped
by \code{MayNull}. An expression \code{e} of type \code{MayNull a} can be converted to \code{Bool} by comparing it with NULL:
\begin{verbatim}
  e /= cogent_NULL
\end{verbatim}
Here \code{cogent\_NULL} denotes the Gencot translation of the C constant \code{NULL} of Cogent type \code{MayNull CVoidPtr}. This
Cogent expression resulting from the conversion is the same as the translation of the C expression \code{expr != NULL}, if
\code{e} is the translation of \code{expr}. Clashes between the type of \code{e} and \code{MayNull CVoidPtr} will be resolved
by further postprocessing for pointer types as described below.

It would be possible to convert the value \code{False} to a NULL pointer using the Gencot basic operations \code{null} and
\code{roNull} defined in Section~\ref{design-operations-null}. However, for the value \code{True} no sensible conversion exists.
More general, conversion from a numerical value to a pointer would correspond to a form of pointer arithmetics which is
deliberately not supported by Gencot. Therefore Gencot never converts from type \code{Bool} to a pointer type.

Type clashes with \code{Bool} are resolved as follows. A sub-expression with non-boolean type in a context expecting type \code{Bool}
is converted by comparing with \code{0} or \code{cogent\_NULL}. A sub-expression with type \code{Bool} in a context not expecting
type \code{Bool} is always converted to arithmetic type \code{U32} as described above. If necessary, further type clashes are resolved
in later postprocessing steps. If the type clash is between two operator arguments
or two components of the branches of a conditional expression the conversion is always to type \code{Bool}, since that is always
possible.

Postprocessing for boolean values in this way cannot cause errors, hence it is implemented by the function
\begin{verbatim}
  boolproc :: GenExpr -> GenExpr
\end{verbatim}
defined in module \code{Gencot.Cogent.Post.MatchTypes}.

\subsection{NULL Pointer Processing}
\label{impl-post-null}

Pointer values may be NULL in C. In Cogent this property is modeled in the type using the \code{MayNull} wrapper type. Type clashes
may result between \code{MayNull} types and not-null (unwrapped) types.

Values of not-null type can be converted to \code{MayNull} type using the Gencot provided operations \code{mayNull} and \code{roMayNull}
introduced in Section~\ref{design-operations-null}. Values of \code{MayNull} type can only be converted to not-null type by testing them
for being NULL using the Gencot provided functions \code{notNull} and \code{roNotNull} and then modifying the type in the corresponding
conditional branch. In the other branch the value can be substituted using the Gencot provided functions \code{null} and \code{roNull}.

Values of not-null type are needed when the pointer shall be dereferenced. It would be possible for Gencot to generate the required
NULL tests, but then it must generate a working code alternative for the case that the pointer is NULL. It is usually not possible to
do this automatically. Therefore Gencot never generates NULL test, it only uses those which are present in the C code.

A NULL test has the form \code{v op cogent\_NULL} or \code{cogent\_NULL op v} where \code{op} is either \code{==} or \code{/=}. It origins
either from translating corresponding C code or by resolving a boolean type clash by converting a value of pointer type to \code{Bool}, as
described above. If the variable \code{v} has not-null type it can be immediately substituted by \code{True} or \code{False}. Otherwise the
test result can be used to specialize occurrencies of \code{v} in conditional code which depends on the test result.

In C the test result can be stored and used later as condition to guard code parts. To detect all those code parts would require a full
data flow analysis of the test result. Gencot does not perform this analysis, it only uses the test result if the test is immediately
present in the condition of a conditional expression or statement. Conditional expressions and statements are both translated to Cogent
conditional expressions. Then the scopes affected by the test are syntactically available as the branches of the conditional expression.

\subsubsection{Splitting Conditions}

A NULL test in C may occur as part of a complex boolean expression using the operators \code{\&\&}, \code{||}, and \code{!}. In this form
the test cannot be used for specializing the tested variable, because the complex condition may have no direct consequence for the tested
variable. Therefore, in a separate pass, Gencot splits complex conditions so that contained NULL tests are isolated as condition in a
conditional subexpression.

As described in Section~\ref{impl-ccode-cexpr}, the operators \code{\&\&}, \code{||} are translated to a conditional expression. Therefore
a complex boolean condition is always translated to an expression using (possibly nested) conditional expressions and the \code{not} operator.
If such an expression occurs as condition in another conditional expression this expression can be split according to the transformation
\begin{verbatim}
  if (if x then x1 else x2) then y1 else y2
  -->
  if x then (if x1 then y1 else y2)
       else (if x2 then y1 else y2)
\end{verbatim}
When the condition results from translating a \code{\&\&}, \code{||} operator, one of \code{x1} and \code{x2} is typically \code{True}
or \code{False}, then the result of the splitting can immediately be simplified by removing one occurrence of \code{y1} or \code{y2}.
Note however, that even then the splitting will duplicate one of the branches \code{y1} and \code{y2} of the original conditional expression.

The \code{not} operators can be eliminated by swapping the branches according to
\begin{verbatim}
  if (not x) then y1 else y2
  -->
  if x then y2 else y1
\end{verbatim}

Gencot reduces and splits complex conditions according to these rules until the remaining conditions are either a single NULL test
or a (possibly complex) condition which does not contain a NULL test.

The duplication of branches caused by the splitting rule may result in an exponential growth of the code size. To mitigate this, Gencot
tries to move parts of the branches before the conditional expression, before applying the splitting rule. This is done according to the
transformation rule
\begin{verbatim}
  if y then (let b1 in y1) else (let b2 in y2)
  -->
  let b1 and b2 in (if y then y1 else y2)
\end{verbatim}
However, this is not always possible, since the variables bound in \code{b1} may not occur free in \code{let b2 in y2} and vice versa and
also not in \code{y}. Gencot extracts as much bindings from the branches as possible. If a branch binds only value variables (which may
not occur outside the branch), i.e., it has no side effects, all bindings can be extracted and the branch is reduced to a single variable
reference, then the code is minimally enlarged.

Extracting bindings from the branches prevents applying the implications of the NULL test in them, which is the main goal of the NULL
processing. Therefore bindings are only extracted from branches which are actually duplicated, because then they cannot be restricted
to a single branch of a NULL test condition and its effects cannot be applied to them, at least not to all copies.

Gencot also takes into account, that the condition \code{y} may have side effects in C. Then it will be translated to a tuple binding
\begin{verbatim}
  (v<n>',v1..) = e
\end{verbatim}
where \code{e} may be a conditional expression or a let expression and the value valiable \code{v<n>'} is used as condition \code{y}.
Then the splitting rule becomes more complex and must also deal with the side effect parts of \code{e}.

The code modifications done during condition splitting are rather complex. Banged variables in bindings would make it even more complex,
therefore Gencot performs NULL processing before performing readonly processing which may introduce banged variables, as described in
Section~\ref{impl-post-bang}.

\subsubsection{Transforming NULL Tests}

After splitting conditions Gencot uses a second pass to transform all conditional expressions with a NULL test as condition to a Cogent
match expression according to the transformation rule
\begin{verbatim}
  if v /= cogent_NULL then y1 else y2
  -->
  notNull v | Nothing -> y2
            | Some v -> y1
\end{verbatim}
Note that if the type of \code{v} is \code{MayNull T} the result of \code{notNull} has type \code{Option T} which can be discriminated
by the match expression. In the \code{Some}-branch the variable \code{v} has type \code{T}, so it is known to be not NULL. In \code{y1}
the type information in the Cogent AST is updated accordingly for every free occurrence of \code{v} and also after a re-binding to itself
and by a \code{take} or \code{put} binding which both do not change the value of \code{v}.

The transformation always inserts the operation \code{notNull}, even if \code{v} has a readonly type. The readonly processing is performed
after the NULL processing and may convert \code{v} to readonly by banging it, if it is not readonly. Therefore \code{notNull} is
only replaced by \code{roNotNull} after readonly processing.

If \code{v} is a value variable the occurrence in the condition is its single occurrence and it will not be present in \code{y1}, so the
transformation would have no effect. Therefore Gencot substitutes \code{v} by its bound expression, as long as it is a value variable.
Then it is either a C variable or a component variable, or it is some other expression, such as a function application or a conditional
expression. In the former case the variable may occur several times in \code{y1} and be affected by the NULL test implications. In the
latter case only the syntactically same expression could be affected and only, if variables used in it have not been re-bound to other
values. Even then the evaluation of the expression must be deterministic for the affecting being correct. Therefore Gencot only transforms
NULL tests where the tested expression is a C or component variable after substituting value variables.

In the \code{Nothing}-branch it is known that \code{v} has value NULL. This is exploited by replacing \code{y2} by the expression
\begin{verbatim}
  let v = cogent_NULL in y2
\end{verbatim}
However, this would be interpreted by the readonly processing as a modification of \code{v} which could prevent banging it. Therefore
this replacement is done in a separate postprocessing step which is executed after readonly processing. Then it has also been finally
decided whether \code{v} has readonly type or not and instead of \code{cogent\_NULL} the functions \code{null} or \code{roNull} can be
used.

\subsubsection{Resolving MayNull Clashes}

In a third processing step Gencot resolves type clashes between \code{MayNull} wrapped types and unwrapped types. There are two cases:
If the context expects an unwrapped type but the sub expression has a \code{MayNull} type this means that a pointer is expected to
be not NULL, but this information is not present at the position where the pointer is used. The reason may be a missing NULL test in
the C program or a too complex data flow dependency which is not detected by Gencot. This type clash is always resolved by replacing
the sub expression by a dummy expression with the unwrapped type and signaling an error.

The second case is a context which expects a \code{MayNull} type but the sub expression has an unwrapped type. This means, it is known
that the pointer is not NULL, but this information is not required in the context. This situation is always resolved by applying the
Gencot operation \code{mayNull} to the sub expression which corresponds to ``forgetting'' the information of being not NULL.

Like for \code{notNull}, this transformation always inserts \code{mayNull}, for expressions of readonly type it is only replaced by
\code{roMayNull} after readonly processing.

To preserve the restricted form of the Cogent AST described in Section~\ref{impl-post-ast} the \code{mayNull} application is always
inserted as a separate binding of the form
\begin{verbatim}
  v = mayNull[T] v
\end{verbatim}
where \code{v} is the subexpression of type \code{T} which must be converted to \code{MayNull T}. The variable \code{v} on the left side
of the binding has type \code{MayNull T}, therefore its type can be changed to \code{MayNull T} for every free occurrence in the scope
of the binding. The binding is inserted according to the rules described in Section~\ref{impl-post-ast}.

If the type clash is between an additional function result component and the side effect target variable to be modified by it the
type of the variable is changed to unwrapped in the function application binding and then corrected by a \code{mayNull} binding inserted
after the application binding.

\subsection{String Processing}
\label{impl-post-string}

\subsection{Integer Adaptation}
\label{impl-post-int}

\subsection{Pointer Adaptation}
\label{impl-post-pointer}

\subsection{Take/Put Processing}
\label{impl-post-takeput}

For struct and array accesses in C (\code{s.m}, \code{s->m}, \code{a[i]}) the translation described in Section~\ref{impl-ccode-cexpr}
creates pairs of take/put bindings of the form
\begin{verbatim}
  <v>{m=pk} = vn
  ...
  <v> = <v>{m=pk}
\end{verbatim}
(for struct access) and
\begin{verbatim}
  (<v> @{@vl=pk},ik) = (vn,vl)
  ...
  <v> = <v> @{@ik=pk}
\end{verbatim}
(for array access). Here, \code{<v>} is the variable used for the container (struct or array) and \code{pk'} is the component variable 
used to bind the component (member or element). The value variable \code{vn'} is the result of the expression denoting the container
(struct or array). If that expression is not an lvalue in C (corresponding to a C variable or component variable in Cogent) \code{<v>}
is the error variable \code{err'} in the \code{take} binding and the \code{put} bindingis replaced by the unit binding \code{() = ()}.

There are several postprocessing steps applied to take/put pairs:
\begin{itemize}
\item Simplifying \code{take} bindings,
\item eliminating take/put pairs for readonly container types,
\item enlarging take/put regions,
\item converting take/put pairs to \code{modify} applications.
\end{itemize}


Postprocessing for \code{take} and \code{put} bindings is implemented by the function
\begin{verbatim}
  tpproc :: GenExpr -> GenExpr
\end{verbatim}
defined in module \code{Gencot.Cogent.Post.Takeput}.

The take/put pairs are postprocessed in two major steps. In the first step single take or put bindings are eliminated, because the component
has nonlinear type. In the second step, some of the remaining take/put pairs are converted to applications of the \code{modify} operation
(see section~\ref{design-operations-modify}). The steps are implemented by the functions
\begin{verbatim}
  tpelimproc :: GenExpr -> GenExpr
  tpmodifproc :: GenExpr -> GenExpr
\end{verbatim}
defined in module \code{Gencot.Cogent.Post.Takeput}.

\subsubsection{Banging \code{take} Bindings}

A component of nonlinear type can freely by copied from a container without the need for a \code{take} operation. The same holds, if the 
component has linear type, but is only used in readonly form. Then the container can be ``banged'' before the component access and a readonly
access can be used instead of a \code{take} operation.

As a preparation step all \code{take} bindings are banged for which that is possible, i.e. the container is banged in the binding by appending
\code{!vn'} to it:
\begin{verbatim}
  <v>{m=pk} = vn
  ->
  <v>{m=pk} = vn !vn'

  (<v> @{@vl=pk},ik) = (vn,vl)
  ->
  (<v> @{@vl=pk},ik) = (vn,vl) !vn'
\end{verbatim}

Whether a \code{take} binding can be banged depends on the taken component \code{pk'}. If it has a declared nonlinear type (according to the C 
type and the item properties), the \code{take} binding can always be banged. Otherwise, if it has a linear type, it depends on how the 
component \code{pk'} is used, i.e. the free occurrences of the \code{pk'} bound in the \code{take} binding. First, it must be used in 
the corresponding \code{put} binding, i.e., it must not be rebound before. This means the component is not modified in the container, 
which would prevent making the container readonly. Second, all other free occurrencies of \code{pk'} must be in a bang specification, 
possibly as a container in a banged \code{take} binding. To evaluate that, all following \code{take} bindings must be processed 
recursively before. 

The only possible other uses of \code{pk'} are:
\begin{itemize}
\item Actual parameter of an invoked function. If the formal parameter has a readonly type, \code{pk'} must be banged before,
otherwise it is used unbanged.
\item Assignment to a variable or container component, or return value of the surrounding function. That must be unbanged, 
otherwise it would escape the banged context.
\item Dereferencing it using \code{*} or \code{->} in C. This is translated like a component access to a take/put pair and is
handled by the recursive processing of the \code{take} bindings.
\item Comparison with another pointer in C. There it will always be banged by the comparison postprocessing.
\end{itemize}
Together, it is sufficient to check whether all free occurrencies of \code{pk'} have been explicitly banged by previous 
postprocessings or the recursive \code{take} processing.

The component variable \code{pk'} may also be used indirectly, by binding it to another variable. In that case the free 
occurrencies of that variable must be checked in the same way. Usually, however, such ``chain bindings'' should have been 
removed by the simplification of \code{let} expressions in~\ref{impl-post-let}.

The banging of \code{take} bindings is implemented by the function
\begin{verbatim}
  tpbangproc :: GenExpr -> GenExpr
\end{verbatim}
defined in module \code{Gencot.Cogent.Post.Takeput}.

If a \code{take} binding is banged, the explicit bangings of the \code{pk'} are redundant. However, they are only removed after
\code{tpelimproc} because they allow to check locally whether the container in a \code{take} binding is readonly.

\subsubsection{Eliminating \code{put} Bindings}

A \code{put} binding can be completely removed, if the put value \code{pk'} has only been bound in the corresponding \code{take}
binding. In this case the taken component is put back unmodified, which is redundant. 

If the \code{take} binding has been banged, the component and the container are readonly and the container's type will not be 
changed by accessing the component. Moreover, the put would be illegal in Cogent, since it is applied to a readonly container,
so in this case the \code{put} binding must be removed.

If the \code{take} binding has not been banged, the \code{take} binding changes the type of the container to that where the component
has been taken. The \code{put} binding is usually required to change the type back to the untaken form. However, if it was not possible
to bang the \code{take} binding, there must be another use of component \code{pk'} in linear form. Therefore the \code{put} would
be illegal in Cogent because the linear component is used twice. Therefore in this case the \code{put} binding is removed as well.

It may be that there is another take/put pair for the same component later, where the taken component is not used at all, so that 
the \code{take} binding is eliminated as described below. Then the remaining \code{put} binding changes the type back. Note, that
all cases in C where a pointer component in a container is accessed once and then overwritten by an assignment before it is 
accessed again is translated to a corresponding sequence of take/put pairs. The postprocessing turns it into valid Cogent code
which respects the linear use of the pointers.

Since the elimination of \code{put} bindings depends on insecting the corresponding \code{take} binding, it must be done before 
eliminating \code{take} bindings.

\subsubsection{Eliminating \code{take} Bindings}

A \code{take} binding can be replaced by a normal binding, if the taken component is not linear. After executing \code{tpbangproc}
this can be detected by checking whether the \code{take} binding is banged. If that is the case, it can be replaced by a binding
which binds the container and the component separately. A banged \code{take} binding is replaced according to
\begin{verbatim}
  <v>{m=pk} = vn !vn'
  ->
  (<v>,pk') = (vn',vn'.m) !vn'

  (<v> @{@vl=pk},ik) = (vn,vl) !vn'
  ->
  (<v>,pk',ik') = (vn',getArr(vn',vl'),vl') !vn'
\end{verbatim}
In case of a struct the Cogent member access \code{vn'.m} is used, in case of an array the Gencot array operation \code{getArr(vn',vl')}
is used.

Note, that banging and elimination also works for \code{take} bindings where \code{<v>} is the wildcard \code{\_}. In this case the 
\code{vn'} is simply discarded which is no problem, since it has been banged. The unnecessary wildcard binding will be removed by
\code{let} simplification. Only if a wildcard \code{take} binding cannot be banged and thus not eliminated, it may result in illegal
Cogent code, because the remaining container may still be linear after taking \code{pk'}, but it is discarded.

After eliminating all \code{take} bindings where possible, the redundant bangings are removed: Whenever a binding is banged, 
the bangings of all free occurrences of the bound variables (and possible chain bindings) are removed. 

\subsubsection{Repeated Access of the Same Component}

If a \code{take} binding is followed by another \code{take} binding for the same container and the same component before the 
corresponding \code{put} binding, this may cause illegal code in Cogent, because a component is taken twice. If one or both 
\code{take} bindings can be eliminated as described above, there is no problem because the component is accessed in a readonly 
way which can be done arbitrarily often.

If both \code{take} bindings cannot be eliminated this means that the linear component is used in linear form in both cases
which results in an illegal double use in Cogent. Nevertheless the case is still postprocessed as follows.

Since every \code{take} binding uses a new component variable \code{pk'} the double uses are related to two different variables 
\code{pi'} and \code{pj'}. To make the double use more apparent and reduce the
number of \code{take} bindings, the second \code{take} is replaced by a rebinding of \code{pj'} to the value of \code{pi'}. Since 
the \code{pi'} may have been rebound between the first and the second \code{take} binding, this rebinding is inserted immediately
after the first \code{take}. Together, a sequence of two repeated \code{take} bindings which cannot be eliminated is processed 
according to
\begin{verbatim}
  <v>{m=pi} = vn
  ...
  <v>{m=pj'} = <v>
  ->
  <v>{m=pi} = vn
  pj' = pi'
  ...
\end{verbatim}
for a struct. Note that for a struct it is easy to detect that two \code{take} bindings access the same component, because the coponent
names must be the same. 

In case of an array the components are the same, if the same index value is used for access, this cannot be 
statically decided in general. The postprocessing uses a heuristics to test whether two index expressions evaluate to the same
value. First, \code{evalproc} is applied to both so that constant subexpressions are evaluated. Then, simple integer operator
expressions are matched, so that, e.g., the expressions \code{i+5} and \code{i+5} are detected as having the same value, 
if \code{i} is not rebound in between. That should cover simple typical cases of indexing the same elements in C.

Then the transformation for arrays is
\begin{verbatim}
  <v> @{@vl=pi} = vn
  ...
  <v> @{@vm=pj} = <v>
  ->
  <v> @{@vl=pi} = vn
  pj' = pi'
  ...
\end{verbatim}
if the index expressions \code{vl'} and \code{vm'} can be shown to evaluate to the same value.

If a \code{put} binding is followed by a \code{take} binding for the same container and the same component, and both bindings cannot
be eliminated, they can be replaced by a single binding of the component variable used in the \code{take} binding to the value 
put in the \code{put} binding. Neither the container nor its type is modified by putting a value into a component of linear type and then
taking the component out again. The corresponding transformation is
\begin{verbatim}
  <v> = <v>{m=pi}
  ...
  <v>{m=pj'} = <v>
  ->
  pj' = pi'
  ...
\end{verbatim}
for structs and
\begin{verbatim}
  <v> = <v> @{@vl=pi}
  ...
  <v> @{@vm=pj} = <v>
  ->
  pj' = pi'
  ...
\end{verbatim}
if the index expressions \code{vl'} and \code{vm'} can be shown to evaluate to the same value.

Note that the original translation in Section~\ref{impl-ccode-cexpr} never creates a \code{take} binding after a \code{put} binding,
but postprocessing of Cogent expressions resulting from a sequence of C statements may result in such a sequence. The processing
described above results in a pattern which is similar to a ``\code{do-with}'' construct where a component is selected once and then
processed several times.

Both transformations for repeated access of the same component are applied in \code{tpelimproc} after eliminating single \code{take}
and \code{put} bindings.

\subsubsection{Converting take/put Pairs to \code{modify} Expressions}

\subsection{Introducing \code{getref}/\code{modref}}
\label{impl-post-ref}


\subsection{Combining the Steps}
\label{impl-post-combine}

Generally, the postprocessing steps recurse into the structure of the processed expression. Thus it would be possible to combine them
on every recursion level by combining the non-recursive steps to a common postprocessing function which recurses into the expression
structure. Alternatively each step recurses on its own and the overall simplification applies the steps sequentially to the toplevel
expressions.

Some steps depend on each other in a cyclic way. These are in particular the functions \code{evalproc}, \code{letproc}, and \code{ifproc}.
After \code{letproc} substitutes variables it may be possible to evaluate more expressions by \code{evalproc} than before. This may
allow additional simplifications by \code{ifproc} since conditions may evaluate to a constant. These simplifications may remove code parts 
with occurrences of free variables which in turn may allow additional simplification by \code{letproc}. Therefore these steps must 
be applied in a loop until the expression does not change any more.

The \code{letproc} step works bottom up and is applied to subexpressions before it is applied to an expression. The \code{ifproc} step 
for a subexpression will only benefit if variables are substituted from the context. Thus it does not help to iterate these steps for
the same subexpression. Instead, both steps recurse on their own and are iterated on the toplevel expressions.

The \code{evalproc} step is only used as auxiliary step in other postprocessing steps. Since the other steps recurse into the control
structures like \code{if} and \code{let}, it is not necessary for \code{evalproc} to do this. Therefore \code{evalproc} only recurses
into operator subexpressions.

The \code{opproc} step recurses into arbitrary subexpressions. It processes cases which are typically created by \code{ifproc}.
Therefore it is executed after every toplevel execution of \code{ifproc}.

The \code{tpproc} step depends on the explicit banging of variables of linear type which are used in a readonly way. That is done 
in the \code{funproc} step, therefore \code{tpproc} must be executed after \code{funproc}.
