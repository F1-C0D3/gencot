
Parsing and processing C code in Gencot is always implemented in Haskell, to be able to use an existing
C parser. There are at least two choices for a C parser in Haskell:
\begin{itemize}
\item the package ``language-c'' by Benedikt Huber and others,
\item the package ``language-c-quote'' by Geoffrey Mainland and others.
\end{itemize}

The Cogent compiler uses the package language-c-quote for outputting the generated C code and for parsing the antiquoted
C source files. The reason is its support for quasiquotation (embedding C code in Haskell code) and antiquotation
(embedding Haskell code in the embedded C code). The antiquotation support is used for parsing the antiquoted C sources.

Gencot performs three tasks related to C code:
\begin{itemize}
\item read the original C code to be translated,
\item generate antiquoted C code for the function wrapper implementations,
\item output normal C code for the C function bodies as placeholder in the generated Cogent function definitions.
\end{itemize}

The first task is supported by both packages: a C parser reads the source text and creates an internal abstract syntax tree (AST).
Every package uses its own data structures for representing the AST. However, the language-c package provides an additional
``analysis'' module which processes the rather complicated syntax of C declarations and returns a ``symbol map'' mapping
every globally declared identifier to its declaration or definition. Since Gencot generates a single Cogent definition for
every single globally declared identifier, this is the ideal starting point for Gencot. For this reason Gencot uses
the language-c parser for the first task.

The second task is only supported by the package language-c-quote, therefore it is used by Gencot. 

The third task is supported by both packages, since both have a prettyprint function for outputting their AST. Since the 
function bodies have been read from the input and are output with only minor modifications, it is easiest to use
the language-c prettyprinter, since language-c has been used for parsing and the body is already represented by its 
AST data structures. However, the language-c prettyprinter cannot be extended to generate the ORIGIN markers, therefore
the AST is translated to the language-c-quote AST and the corresponding prettyprinter is used for the third task (see 
Section~\ref{impl-ccode-expr}).

Note that in both packages the main module is named \code{Language.C}. If both packages are exposed to the ghc Haskell
compiler, a package-qualified import must be used in the Haskell program, which must be enabled by a language pragma:
\begin{verbatim}
  {-# LANGUAGE PackageImports #-}
  ...
  import "language-c" Language.C
\end{verbatim}

\subsection{Including Files}
\label{impl-ccode-include}

The filter \code{gencot-include <dirlist> [<filename>]} processes all quoted include directives and replaces them (transitively) by the 
content of the included file. Line directives are inserted at the begin and end of an included file, so that
for all code in the output the original source file name and line number can be determined. The \code{<dirlist>}
specifies the directories to search for included files. The optional \code{<filename>}, if present, must be the name of
a file with a list of names of files which should be omitted from being included.

\subsubsection{Filter \code{gencot-include}}

The filter for expanding the include directives is implemented as an awk script, heavily inspired by the ``igawk''
example program in the gawk infofile, edition 4.2, in Section 11.3.9.

As argument it expects a directory list specified with ``:'' as separator. The list corresponds
to directories specified with the \code{-I} cpp option, it is used for searching included files.
All directories for searching included files must be specified in the arguments, there are no defaults.

Similar to cpp, a file included by a quoted directive is first searched in the directory of the including file. 
If not found there, the argument directory list is searched.

Since the input of \code{gencot-include} is read from standard input it is not associated with a directory. Hence
if files are included from the same directory, that directory must also be specified explicitly in an argument directory
list.

\subsubsection{Generating Line Directives}

Line directives are inserted into the output as follows.

If the first line of the input is a line directive, it is copied to the output. Otherwise 
the line directive
\begin{verbatim}
  # 1 "<stdin>"
\end{verbatim}
is prepended to the output.

If after a generated line directive with file name \code{"fff"} the input line \code{NNN} contains the 
directive 
\begin{verbatim}
  #include "filepath"
\end{verbatim}
the directive is replaced in the output by the lines 
\begin{verbatim}
  # 1 "dir/filepath" 1
  <content of file filepath>
  # NNN+1 "fff" 2
\end{verbatim}

The \code{"dir/"} prefix in the line directives for included files is determined as follows. 
If the included file has been found in the 
directory of its includer, the directory pathname is constructed from \code{"fff"} by taking the pathname 
up to and including the last ``/'' (if present, otherwise the prefix is empty).
If the included file has been found in a directory from the argument directory list
the directory pathname is used as specified in the list.

\subsubsection{Multiple Includes}

The C preprocessor does not prevent a file from being included multiple times. Usually, C include files use
an ifdef directive around all content to prevent multiple includes. The \code{gencot-include} filter does
not interprete ifdef directives, instead, it simply prevents multiple includes for all files independent 
from their contents, only based on their full file pathnames. To mimic the behavior of cpp, if a file is 
not include due to repeated include, the corresponding line directives are nevertheless generated in the form
\begin{verbatim}
  # 1 "dir/filepath" 1
  # NNN+1 "fff" 2
\end{verbatim}

\subsubsection{Omitted Includes}

A special case of multiple include is the recursive include of the main input file. However, since it is read from standard
input, its name is not known to \code{gencot-include}. If it may happen that it is recursively included, the corresponding
pathname, as it appears in an include directive, must be added to the list of includes to be omitted.

There are other reasons, why some include files should be omitted. One case is that an include file may or may not exists
which is configured through a preprocessor flag. Since \code{gencot-include} ignores all conditional directives,
this would not be detected and an error message would be caused if the file does not exist.

The list of files to be omitted from inclusion is specified in the optional file passed as second argument to 
\code{gencot-include}. Every file must be specified on a separate line by its pathname exactly in the form it occurs 
in a quoted include directive (without quotes). Since system includes and includes where the included file is specified 
as a macro call are not processed by \code{gencot-include} they need not be added to the list.

Includes for files listed to be omitted are simply ignored. No line
directives are generated for them.

\subsection{Preprocessing}
\label{impl-ccode-preproc}

The language-c parser supports an integrated invocation of an external preprocessor, the default is to use
the gcc preprocessor. However, the integrated invocation always reads the C code from a file (and checks
its file name extension) and not from standard input.

To implement C code processing as a filter, Gencot does not use the integrated preprocessor,
it invokes the preprocessor as an additional separate step. For consistency reasons it is wrapped in
the minimal filter script \code{gencot-cpp}. 

The preprocessor step only has the following purpose:
\begin{itemize}
\item process all system include directives by including the file contents,
\item process retained conditional directives to prevent conflicts in the C code.
\end{itemize}
All other preprocessing has already been done by previous steps.

\subsection{Reading the Input}
\label{impl-ccode-read}

\subsubsection{Parsing}

To apply the language-c parser to the standard input we invoke it using function \code{parseC}. It needs an \code{InputStream}
and an initial \code{Position} as arguments. 

The language-c parser defines \code{InputStream} to be the standard type \code{Data.ByteString}. To get the 
standard input as a \code{ByteString} the function \code{ByteString.getContents} can be used. 

The language-c parser uses type \code{Position} to describe a character position in a named file. It provides
the function \code{initPos} to create an initial position at the beginning of a file, taking a \code{FilePath}
as argument, which is a \code{String} containing the file name. Since Gencot and the C preprocessor create
line directives with the file name \code{<stdin>} for the standard input, this string is the correct argument
for \code{initPos}. 

The result of \code{parseC} is of type \code{(Either ParseError CTranslUnit)}. Hence it should be checked whether
an error occurred during parsing. If not, the value of type \code{CTranslUnit} is the abstract syntax tree for
the parsed C code.

Both \code{parseC} and \code{initPos} are exported by module \code{Language.C}. The function \code{ByteString.getContents}
is exported by the module \code{Data.Bytestring}. Hence to use the parser we need the following imports:
\begin{verbatim}
  import Data.ByteString (getContents)
  import "language-c" Language.C (parseC,initPos)
\end{verbatim}

Then the abstract syntax tree can be bound to variable \code{ast} using
\begin{verbatim}
  do
    input_stream <- Data.ByteString.getContents
    ast <- either (error . show) return $ parseC input_stream (initPos "<stdin>")
\end{verbatim}

\subsubsection{Analysis}

Although it is not complete and only processes toplevel declarations (including typedefs), and object definitions, the
language-c analysis module is very
useful for implementing Gencot translation. Function definition bodies are not covered by analysis, but they are
not covered by Gencot either.

The main result of the analysis module is the symbol table. Since at the end of traversing a correct C AST the toplevel
scope is reached, the symbol table only contains all globally defined identifiers. From this symbol table 
a map is created containing all toplevel declarations and object definitions, mapping the identifiers
to their semantics, which is mainly its declared type. Whereas in the abstract syntax tree there may be several declarators
in a declaration, declaring identifiers with different types derived from a common type, the map maps every identifier
to its fully derived type. 

Also, tags for structs, unions and enums are contained in the map. In C their definitions can be embedded in other declarations.
The analysis module collects all these possibly embedded declarations in the symbol table. The map also gives for
every defined type name its definition.

Together, the information in the map is much more appropriate for creating Cogent code, where all type definitions are on
toplevel. Therefore, Gencot uses the map resulting from the analysis step as starting point for its translation. 
Additionally, Gencot uses the symbol table built by the analysis module during its own processing to access the
types of globally defined identifiers and for managing local declarations when traversing function bodies, as described in
Section~\ref{impl-ccode-trav}.

Additionally, the analysis module provides a callback handler which is invoked for every declaration entered into the symbol 
table (with the exception of tag forward declarations and enumerator declarations). The callback handler can accumulate results 
in a user state which can be retrieved after analysis together with the
semantics map. Since the callback handler is also invoked for all local declarations it is useful when all declarations
shall be processed in some form.

To use the analysis module, the following import is needed:
\begin{verbatim}
  import Language.C.Analysis
\end{verbatim}

Then, if the abstract syntax tree has been bound to variable \code{ast}, it can be analysed by
\begin{verbatim}
  (table,state) <- either (error . show) return $ 
    runTrav uinit (withExtDeclHandler
                   (analyseAST ast >> getDefTable) uhandler)
\end{verbatim}
which binds the resulting symbol table to variable \code{table} and the resulting state to \code{ustate}. \code{runTrav}
returns a result of type \code{Either [CError] (DefTable, TravState s)}, where \code{DefTable}
is the type of the symbol table and \code{s} is the type of the user state. The error list in the first alternative contains 
fatal errors which made the analysis fail. The state in the second alternative contains warnings about semantic inconsistencies, 
such as unknown identifiers, and it contains the user state. \code{uinit} is the initial user state and \code{uhandler}
is the callback handler of type
\begin{verbatim}
  DeclEvent -> Trav s ()
\end{verbatim}
It returns a monadic action without result.

The semantics map is created from the symbol table by the function \code{globalDefs}, its type is \code{GlobalDecls}.

On this basis, Gencot implements the following functions in the module \code{Gencot.Input} as utility for parsing and analysis:
\begin{verbatim}
  readFromInput :: String -> s ->
      (String -> DeclEvent -> Trav s ()) -> IO (DefTable, s)
  readFromFile :: s -> (String -> DeclEvent -> Trav s ()) ->
      FilePath -> IO (DefTable, s)
\end{verbatim}
The first one takes as arguments the original C source file name, an initial user state and a callback handler.
It reads C code from standard input, parses and analyses it and returns the symbol table and the user state
accumulated by the callback handler. The second function takes a file name as additional argument instead of
the original C source file name and does the same reading from the file. Both functions pass the file name
as first argument to the callback handler.

All Gencot filters which read C code use one of these two functions.

The callback handler is used by Gencot whenever it has to process information in a different order than in the source file.
Then the callback handler collects all relevant information during the analysis phase and returns it in the user state.
It is used for the second AST traversal for the processing by Gencot (see Section~\ref{impl-ccode-trav}) by either
transferring it to the user state for that traversal, or by using it as the traversed AST elements.
There are two callback handlers used by Gencot this way:
\begin{itemize}
\item \code{collectGlobalStateIds}, defined in module \code{Gencot.Items.Types}. It collects a mapping from item ids to
item definitions or declarations for all global variables, which is added to the user state of the second traversal.
It is needed because a function with a Global-State parameter may be defined before the corresponding global variable.
The variables type is required for processing the parameter, it must be retrieved from the definition or declaration.
\item \code{collectTypeCarriers}, defined in module \code{Gencot.Util.Types}. It collects typed AST elements occurring in the
Cogent compilation unit as starting points for transitively determining all used types in the second traversal.
\end{itemize}

\subsubsection{Source Code Origin}

The language-c parser adds information about the source code origin to the AST. For every syntactic construct represented
in the AST it includes the start origin of the first input token and the start origin and length of the last input token.
The start origin of a token is represented by the type \code{Position} and includes the original source file name and 
line number, affected by line directives if present in the input. It also includes the absolute character offset in the 
input stream. The latter can be used to determine the ordering of constructs which have been placed in the same line.
The type \code{Position} is declared as instance of class \code{ORD} by comparing the character offset, hence it can 
easily be used for comparing and sorting.

The origin information about the first and last token is contained in the type \code{NodeInfo}. All types for representing
a syntactic construct in the AST are parameterized with a type parameter. In the actual AST types this parameter is always 
substituted by the type \code{NodeInfo}. 

The analysis module carries the origin information over to its results, by including a \code{NodeInfo} in most of its
result structures. This information can be used to
\begin{itemize}
\item determine the origin file for a declared identifier,
\item filter declarations according to the source file containing them,
\item sort declarations according to the position of their first token in the source,
\item translate identifiers to file specific names to avoid conflicts.
\end{itemize}

For the last case the true name of the processed file is required, however, the parsed input is read from a pipe where
the name is always given as \code{<stdin>}. The true name is passed to the Haskell program as an additional 
argument, as described in Section~\ref{impl-ccomps-filters}. Since there is no easy way to replace the file name in
all \code{NodeInfo} values in the semantic map, Gencot adds the name to the monadic state used for processing
(see Section~\ref{impl-ccode-trav}).

\subsubsection{Preparing for Processing}

The main task for Gencot is to translate all declarations or definitions which are contained in a single source file, where
nested declarations are translated to a sequence of toplevel Cogent definitions. This is achieved by parsing and analysing
the content of the file and all included files, filtering the resulting set of declarations according to the source file name
\code{<stdin>}, removing all declarations which are not translated to Cogent, and sorting the remaining ones in a list. 
Translating every list entry to Cogent yields the resulting Cogent definitions in the correct ordering.

For syntactically nested constructs in C the analysis phase creates separate declarations. This corresponds to the 
Cogent form where every declaration becomes a seperate toplevel construct. However, for generating the origin information 
a seperate processing of these declarations would yield repeated origin ranges which may result in repeated comment units in
the target code. Therefore Gencot processes nested 
constructs as part of the containing constructs. Sorting the declarations according to their positions always puts the
nested declarations after their containing declarations. Processing them as part of the containing declaration will
always be done before the nested declaration occurs in the main list of declarations. By maintaining a list of declarations
already processed as nested, Gencot skips these declarations when it finds them in the main list.

The only C constructs which can be nested are tag definitions for struct, union, and enum types (all other cases of nesting
occurs only in C function bodies where the nested parts are not contained as seperate entries in the main list). Tag definitions
can occur as part of every type specification, the most important case is the occurrence in a typedef as in
\begin{verbatim}
  typedef struct s { ... } t
\end{verbatim}
Other relevant cases are the occurrence in the declaration of a global variable, in the result or parameter types of a 
function declaration and in the declaration of a struct or union member (which may result in arbitrarily deep nesting).

For these cases, if the type references a tag definition, Gencot inspects the position information of the tag definition.
If it is syntactically embedded, it processes it and marks it as processed so that it is skipped when it finds it in the
main list.

The type \code{GlobalDecls} consists of three separate maps, one for tag definitions, one for type definitions,
and one for all other declarations and definitions. Every map uses its own type for its range values, however, 
there is the wrapper type \code{DeclEvent} which has a variant for each of them. 

The language-c analysis module provides a filtering function for its resulting map of type \code{GlobalDecls}. The filter 
predicate is defined for values of type \code{DeclEvent}. If the map has been bound to the variable \code{gmap}
it can be filtered by
\begin{verbatim}
  filterGlobalDecls globalsFilter gmap
\end{verbatim}
where \code{globalsFilter} is the filter predicate.

Gencot uses a filter which reduces the declarations to those contained directly in the input file, removing all
content from included files. Since the input file is always associated with the name \code{<stdin>} in the \code{NodeInfo}
values, a corresponding filter function is
\begin{verbatim}
  (maybe False ((==) "<stdin>") . fileOfNode)
\end{verbatim}
Additionally, for a specific Gencot component, the declarations are reduced to those which are processed by the component. 

Every map range value, and hence every \code{DeclEvent} value contains the identifier which is mapped to it, 
hence the full information required for translating the definitions is contained in the range values. 
Gencot wraps every range value as a \code{DeclEvent}, and puts them in a common list for all three maps. This
is done by the function
\begin{verbatim}
  listGlobals :: GlobalDecls -> [DeclEvent]
\end{verbatim}

Finally, the declarations in the list are sorted according to the offset position of their first tokens, using the
compare function
\begin{verbatim}
  compEvent :: DeclEvent -> DeclEvent -> Ordering
  compEvent ci1 ci2 = compare (posOf ci1) (posOf ci2)
\end{verbatim}

Together, the list for processing the code is prepared from the symbol table \code{table} by
\begin{verbatim}
  sortBy compEvent $ listGlobals $ filterGlobalDecls globalsFilter $ globalDefs table
\end{verbatim}

All this preprocessing is implemented in module \code{Gencot.Input}. It provides the functions
\begin{verbatim}
  getOwnDeclEvents :: GlobalDecls -> (DeclEvent -> Bool) -> [DeclEvent]
  getDeclEvents :: GlobalDecls -> (DeclEvent -> Bool) -> [DeclEvent]
\end{verbatim}
The first one reduces the declarations to those directly in the input file, the second also returns
declarations from included files. 
Both perform the preprocessing and return the list of \code{DeclEvent}s to be processed.
As its second argument they expect a filter predicate for restricting the declarations to the
\code{DeclEvent}s to be processed by the specific Gencot component.

\subsection{Reading Packages}
\label{impl-ccode-package}

In some cases several source files of the <package> must be processed together. The typical case is when the main
files for the Cogent compilation unit are generated (see Section~\ref{design-files}). For this it is necessary 
to determine and process the external name references in a set of
C source files. This set is the subset of C sources in the <package> which is translated to Cogent and together yields
the Cogent compilation unit. 

\subsubsection{General Approach}

There are different possible approaches how to read and process this set of source files.

The first approach is to use a single file which includes all files in the set. This file is processed as usual by
\code{gencot-include}, \code{gencot-remcomments}, and \code{gencot-rempp} which yields the union of all definitions
and declarations in all files in the set as input to the language-c parser. However, this input may contain conflicting
definitions. For an identifier with internal linkage different definitions may be present in different source files.
Also for identifiers with no linkage different definitions may be present, if, e.g., different \code{.c} files define
a type with the same name. The language-c parser ignores duplicate definitions for identifiers with internal linkage,
however, it treats duplicate definitions for identifiers without linkage as a fatal error. Hence Gencot does not use
this approach.

The second approach ist to process every file in the set separately and merge the generated target code. However, for
identifiers with external linkage (function definitions) the external references cannot be determined from the content
of a single file. A non-local reference is only external if it is not defined in any of the files in the set. It would
be possible to determine these external references in a separate processing step and using the result as additional input
for the main processing step. Since this means to additionally implement reading and writing a list of external references,
Gencot does not use this approach.

The third approach is to parse and analyse the content of every file separately, then merge the resulting semantic maps
discarding any duplicate definitions. This approach assumes that the external name references, which are relevant for
processing, are uniquely defined in all source files. If this is not the case, because conflicting definitions are used
inside the <package>, which are external to the processed file subset, this must be handled manually. 
This approach is used by Gencot.

\subsubsection{Specifying Input Files}

Due to the approach used, the Gencot filters for generating the files common to the Cogent compilation unit expect
as input a list of names of the files which comprise the Cogent compilation unit. The file names must be pathnames which are either 
absolute or relative to the current directory. Every file name must occur on a single line.

Like all other input to the language-c parser their content must have been processed by \code{gencot-include}, 
\code{gencot-remcomments}, and \code{gencot-rempp}. This implies that all included content is already present
and need not be specified separately, usually only \code{.c} files need to be specified as input, after they have
been processed as usual.

If a processor only processes items which are external to all input files, the original file name is not required 
for the files input to a Gencot processor. However, the processor \code{gencot-dvdtypes} also processes derived 
types which are not external. In a derived type the original file name is only used for constructing the Cogent name
and item identifier for tagless compound types. Currently the only case where tagless types are processed by 
\code{gencot-dvdtypes} is when they occur in a derived function type. If it occurs as parameter type, it is mostly
useless, because then the type has only prototype scope and is not available when the function is invoked. If, however,
it is used as result type, a typedef name can be defined for it in another declarator of the same declaration and
used anywhere in the program. Since this is a very unusual construction in a C program Gencot does not handle it.
This will possibly result in wrong type names in the result of \code{gencot-dvdtypes} which must be manually corrected.

It would be possible to provide a list of the original file names together with the list of files to be processed and
use them as described in Section~\ref{impl-ccode-trav}. However, then it is only available in the userstate during 
analysis for a single input file. After merging the semantic maps the content of the resulting map cannot be associated
with the original file name any more. It would be necessary to preserve this association as a separate data structure.

The utility function
\begin{verbatim}
  readPackageFromInput :: IO [DefTable]
\end{verbatim}
in module \code{Gencot.Package} reads the file name list from input and parses and analyses all files using 
\code{readFromFile}. It returns the list of resulting symbol tables.

\subsubsection{Combining Parser Results}

When the parser results are combined it is relevant, how they are structured, in particular, if the same file
is included by several of the \code{.c} files. Most of the information only depends on the parsed text.
However, the language-c parser also uses unique identifiers, which are counted integers starting at 1 for every
parsed file. This implies, that these identifiers are not unique anymore, if several files are parsed separately
and then the results are combined.

The unique identifiers are associated with most of the AST nodes and are part of the \code{NodeInfo} values.
In the analysis phase they are used to cache the relation between defining and referencing occurrences of C identifiers,
and the relation between C expressions and their types. The corresponding caches are part of the symbol table structure.
However, the first relation cache seems to be built but not used, the second relation cache is only used during 
type analysis for expressions. In both cases, after the analysis phase the caches are still present, but are not 
relevant for the further processing by Gencot.

As a consequence, it is not possible to combine the raw AST structures and then perform the language-c analysis
on the combined AST, since then the non-unique identifiers may cause problems. Instead, Gencot parses and analyses
every file separately and the combines the resulting symbol tables.

However, the unique identifiers are additionally used for identifying tagless struct/union/enum types in the symbol table.
Language-c uses the alternative type \code{SUERef} to identify struct/union/enum types, with the alternatives 
\code{NamedRef} and \code{AnonymousRef}, where the latter specifies the unique integer identifier of the AST node
of the type definition. The symbol table maps \code{SUERef} values to their type definitions. This implies, that
tagless types may be entered in different symbol tables under different keys. This must be detected and handled
when combining the symbol tables.

As described in Section~\ref{impl-ccode-read}, Gencot uses for its processing the list of \code{DeclEvent}s which is
derived from the \code{GlobalDecls} map. This means, the combination could be implemented on the \code{GlobalDecls}
maps or even on the \code{DeclEvent} lists. However, as described in Section~\ref{impl-ccode-trav}, Gencot also
uses the symbol table during processing, for looking up identifiers. For this reason the combination is implemented
on the symbol tables.

A language-c symbol table is implemented by the type 
\begin{verbatim}
  data DefTable = DefTable {
    identDecls   :: NameSpaceMap Ident IdentEntry,
    tagDecls   :: NameSpaceMap SUERef TagEntry,
    labelDefs  :: NameSpaceMap Ident Ident,
    memberDecls :: NameSpaceMap Ident MemberDecl,
    refTable   :: IntMap Name,
    typeTable  :: IntMap Type
  }
\end{verbatim}
where a \code{NameSpaceMap k v} is a mapping from \code{k} to \code{v} with nested scopes. The last two components are the 
relation caches as described above, they are ignored and combined to be empty. After the analysis phase, on the toplevel, 
the maps \code{labelDefs} and \code{memberDecls} are empty, since in C there are no global labels and \code{memberDecls}
contains the struct/union members only while processing the corresponding declaration. So only the first two maps must
be combined.

The map \code{identDecls} contains all identifiers with file scope. For them, the linkage is relevant. If an identifier has 
internal linkage, it is only valid in its symbol table and may denote a different object in another symbol table. These
identifiers are not relevant for Gencot when processing several source files together, thus they are omitted when the
symbol tables are combined. Only identifiers with external or no linkage are retained in the combined symbol table. Note
that this implies that identifiers with internal linkage cannot be looked up in the combined table anymore.

If an identifier has external linkage, it is assumed to denote the same object in every symbol table. However, it may be
declared in one symbol table and defined in another one. In this case, always the definition is used for the combined
table, the declaration is ignored. Only if it is declared in both symbol tables one of the declarations is put into the
combined table. Note that if the C program is correct, the identifier may be defined in at most one C compilation unit
and thus a definition for it occurs in at most one of the symbol tables. 

If both symbol tables contain a definition for the same identifier with external linkage Gencot compares their source 
file positions. If both positions are the same, the definition is in a file included by both sources and it is correct to
discard one of them. If the positions are not the same, Gencot signals an error. The typical case for such included 
definitions are object declarations where the \code{extern} specifier is omitted. This is interpreted as a ``tentative''
definition in C and is classified as definition by the language-c analysis step, if it is not followed by a definition.

The dummy declarations generated by Gencot for parameterless macro definitions (see Section~\ref{impl-ccode-dummydecl})
have the form of such tentative definitions. Since they are generated separately for every C source file, they cannot
be recognized by comparing their source file positions. To prevent them from being signaled as duplicate definitions they
are explicitly specified as \code{extern}, then they are classified as declarations by language-c (instead as tentative 
definitions) and no error is signaled by Gencot. Alternatively they could be generated with internal linkage (specified 
as \code{static}), then they are removed before combining the symbol tables. However, then their names are mapped differently,
as described in Section~\ref{design-names}. Note that (manually created) dummy declarations for
macros with parameters are never classified as definitions, since they have the form of a C function declaration without
a body. 

The typical cases for toplevel identifiers with no linkage are typedef names and struct/union/enum tags. Such an identifier
may occur in two symbol tables, if it is
defined in a file included by both corresponding \code{.c} files. In this case it names the same type and one of both
entries is put in the combined table. However, it may also be the case that the identifier is defined in both \code{.c}
files and used for different types. In this case the combination approach does not work. Gencot assumes that this case
does not occur and tests whether the identifier is mapped to the same semantics (determined from the position information
of the corresponding definition). If not, an error is signaled, this must be handled manually by the developer.

The map \code{tagDecls} contains all tags of struct/union/enum types, mapped to the type definition. For tagless types
the unique identifier is used as key, as described above. If a tag is present, it is treated in the same way as other 
identifiers with no linkage.

A tagless struct/union/enum type in C can be referenced only from a single place, since it must be syntactically embedded
there. This means, when the same tagless type occurs in two symbol tables using a different key, every symbol table
contains at most one reference to the key. When the symbol tables are combined, at most one of these references are transferred
to the combined table. Thus it is possible to use the same key for the transferred definition to yield a consistent
combined table. The simples way to do so would be to always use the entry of the same symbol table for the combination 
when an object occurs in both. However, this is not possible, since for identifiers with external linkage the definition
must be preferred over a declaration, independent where it occurs. Therefore Gencot first transfers both definitions to the 
combined table and afterwards removes all definitions which are not referenced there.

Finally, it may happen that the same unique identifier is used in different symbol tables to reference different types, 
as described for type names above. This is not a problem in the C sources, it is an internal collision of the parser-generated 
unique identifiers. The easiest way to solve this is to introduce a tag for at least one of both tagless types.

The combination is implemented by the function
\begin{verbatim}
  combineTables :: DefTable -> DefTable -> DefTable
\end{verbatim}
in module \code{Gencot.Package}. It should be applied to the tables built by \code{readFromFile} for two different
\code{.c} files of the same package. It can be iterated to combine the result of \code{readPackageFromInput}.
The result can then be processed mainly in the same way as described in 
Section~\ref{impl-ccode-read} for a table built from a single input file.

\subsection{Dummy Declarations for Preprocessor Macros}
\label{impl-ccode-dummydecl}

As described in Section~\ref{design-preprocessor-macros} macro calls in C code must either be syntactically correct
C code or they must be converted to syntactically correct C code. Due to the language-c analysis step this is not 
sufficient. The analysis step checks for additional properties. In particular, it requires that every identifier 
is either declared or defined.

Thus for every identifier which is part of a converted macro call a corresponding declaration must be added to the 
C code. They are called ``dummy declarations'' since they are only used for making the analysis step happy. 

For all preprocessor defined constants Gencot automatically generates the required dummy declarations. The corresponding
macro calls always have the form of a single identifier occurring at positions where a C expression is expected. The type
of the identifier is irrelevant, hence Gencot always uses type \code{int} for the dummy declarations. For every preprocessor
constant definition of the form 
\begin{verbatim}
  #define NNN XXX
\end{verbatim}
a dummy declaration of the form
\begin{verbatim}
  extern int NNN;
\end{verbatim}
is generated. This is implemented by the additional filter \code{gencot-gendummydecls}. It is applied to the result of 
\code{gencot-selppconst}. The resulting dummy declarations are prepended to the input of the language-c preprocessor
since this prevents the lines from being counted for the \code{<stdin>} part.

Dummy declarations are generated with explicit external linkage. This causes them to be classified by language-c as 
declarations instead as (tentative) definitions, hence they are not signaled as repeated definitions when they occur 
in several symbol tables (see Section~\ref{impl-ccode-package}).

Flag macro calls do not occur in C code, hence no dummy declarations are required for them.

For all other macros the required dummy declarations must be created manually and added to the Gencot macro call conversion.
Even if no macro call conversion is needed because the macro calls are already in C syntax, it may be necessary to
add dummy declarations to satisfy the requirements of the language-c analysis step.

\subsection{Generating Cogent Code}
\label{impl-ccode-gencog}

When Gencot generates its Cogent target code it uses the data structures defined by the Cogent compiler for representing
its AST after parsing Cogent code. The motivation to do so is twofold. First, the AST omits details such as using code layout
and parentheses for correct code structure and the Cogent compiler provides a prettyprint function for its AST which cares
about these details. Hence, it is much easier to generate the AST and use the prettyprinter for output, instead of generating
the final Cogent program text. Second, by using the Cogent AST the generated Cogent code is guaranteed to be syntactically correct and
current for the Cogent language version of the used compiler version. Whenever the Cogent language syntax is changed
in a newer version, this will be detected when Gencot is linked to the newer compiler version.

\subsubsection{Cogent Surface Syntax Tree}

The data structures for the Cogent surface syntax AST are defined in the module Cogent.Surface. It defines parameterized types
for the main Cogent syntax constructs (\code{TopLevel}, \code{Alt}, \code{Type}, \code{Polytype}, \code{Pattern}, 
\code{IrrefutablePattern}, \code{Expr}, and \code{Binding}), where the type parameters determine the types of the 
sub-structures. Hence the AST types
can easily be extended by wrapping the existing types in own extensions which are then also used as actual type parameters.

Cogent itself defines two such wrapper type families: The basic unextended types \code{RawXXX} and the types \code{LocXXX}
where every construct is extended by a representation of its source location. 

All parameterized types for syntax constructs and the \code{RawXXX} and \code{LocXXX} types are defined as instances of 
class \code{Pretty} from
module \code{Text.PrettyPrint.ANSI.Leijen}. This prettyprinter functionality is used by the Cogent compiler for outputting
the parsed Cogent source code after some processing steps, if requested by the user.

As source location representation in the \code{LocXXX} types Cogent uses the type \code{SourcePos} from Module 
\code{Text.Parsec.Pos} in package \code{parsec}.
It contains a file name and a row and column number. This information is ignored by the prettyprinter.

\subsubsection{Translations for C Statements and Expressions}

C statements and expressions are first translated to intermediate Cogent bindings, which are then further processed
and finally converted to Cogent expressions. Gencot directly uses the datastructure for representing bindings
in the Cogent AST for the intermediate form. Although it would be possible to define a specific data structure
which is more adequate for the intermediate processing, this approach has the advantage of higher flexibility,
the possibility of using the Cogent prettyprinter for debugging output and no need to transform between representations.

However, only a subset of the AST for bindings is used. Of the datatype \code{Binding} only the variant
\code{Binding} is used, the variant \code{BindingAlts} is not used since it is intended for refutable patterns
to distinguish cases. The optional type in the \code{Binding} variant is not used.

The irrefutable patterns in the bindings are usually nested tuples of variables, built from the constructors
\code{PTuple} and \code{PVar}. Related to struct and array accesses also \code{take} patterns are used constructed
by \code{PTake} and \code{PArrayTake}.

\subsubsection{Extending the Cogent Surface Syntax}

Gencot needs to extend the Cogent surface syntax for its generated code in three ways:
\begin{itemize}
\item origin markers must be supported, as described in Section~\ref{impl-origin},
\item additional C code must be supported in Cogent dummy expressions, as described in Section~\ref{design-cstats}.
\item type information must be supported for some of the postprocessing steps, described in Section~\ref{impl-post}.
\end{itemize}

\paragraph{Origin Markers}

The origin markers are used to optionally surround the generated target code parts, which may be arbitrary syntactic constructs
or groups of them. Hence it would be necessary to massively extend the Cogent surface syntax, if they are added as explicit 
syntactic constructs. Instead, Gencot optionally adds the information about the range of source lines to the syntactic
constructs in the AST and generates the actual origin markers when the AST is output. 

Although the \code{LocXXX} types already support a source position in every syntactic construct, it cannot be used by Gencot,
since it represents only a single position instead of a line range. Gencot uses the \code{NodeInfo} values, since they represent
a line range and they are already present in the C source code AST, as described in Section~\ref{impl-ccode-read}. Hence, they
can simply be transferred from the source code part to the corresponding target code part. For the case that there is no
source code part in the input file (such as for code generated for external name references), or there is no position 
information available for the source code part, the \code{NodeInfo} is optional.

It may be the case that a target AST node is generated from a source code part which is not a single source AST node. Then
there is no single \code{NodeInfo} to represent the origin markers for the target AST node. Instead, Gencot uses the 
\code{NodeInfo} values of the first and last AST nodes in the source code part.

It may also be the case that a structured source code part is translated to a sequence of sub-part translations without target
code for the main part. In this case the \code{\#ORIGIN} marker for the main part must be added before the \code{\#ORIGIN} 
marker of the first target code part and the \code{\#ENDORIG} marker for the main part must be added after the \code{\#ENDORIG} 
marker of the last target code part. 

To represent all these cases, the origin information for a construct in the target AST consists of two lists of \code{NodeInfo}
values. The first list represents the sequence of \code{\#ORIGIN} markers to be inserted before the construct, here only the
start line numbers in the \code{NodeInfo} values are used. The second list represents the sequence of \code{\#ENDORIG} markers 
to be inserted after the construct, here only the end line numbers in the \code{NodeInfo} values are used. If no marker of
one of the kinds shall be present, the corresponding list is empty.

Additional information must be added to represent the marker extensions for placing the comments (the trailing ``+'' signs).
Therefore, a boolean value is added to all list elements.

Together, Gencot defines the type \code{Origin} for representing the origin information, with the value \code{noOrigin}
for the case that no markers will be generated:
\begin{verbatim}
  data Origin = Origin { 
    sOfOrig :: [(NodeInfo,Bool)], 
    eOfOrig :: [(NodeInfo,Bool)] } 
  noOrigin = Origin [] []
\end{verbatim}
Gencot adds an \code{Origin} value to every Cogent AST element. The type \code{Origin} is defined in the module 
\code{Gencot.Origin}

\paragraph{Embedded C Code}

Gencot embeds C code in the Cogent AST when it cannot translate it. This may happen for C statements and expressions, as
described in Section~\ref{design-cstats}. The C code is output in the form of a comment to inform the programmer for 
manual action.

In this case the corresponding Cogent code is a dummy expression which has the form of an invocation of the function
\code{gencotDummy} (see Section~\ref{design-operations-dummy}). So it would be sufficient to support embedded C code
only for such expressions. However, the Cogent AST implementation supports extensions only for all expressions, types, 
irrefutable patterns or toplevel constructs. Therefore Gencot extends all expressions to support embedded C code.

The embedded code origins from the C AST resulting from parsing the C source. It could either be embedded in the Cogent 
AST as a text string or as an AST structure. Embedding it as text is more flexible, however, it involves executing the 
C prettyprinter during translation, where the prettyprinting context (such as line length) is not available. Therefore 
it is embedded as an AST structure and prettyprinted together with the Cogent code. The embedded code may either be a 
C statement or a C expression. Since every C expression can be wrapped as a simple statement, Gencot always embeds C
code in the form of a statement AST.

\paragraph{Type Information}

The translation of function bodies to the Cogent AST described in Section~\ref{impl-ccode-cstats} uses nearly no type 
information from the C program and only interpretes some of the item properties. As described in Section~\ref{impl-post}, the
rest of the translation is done in postprocessing steps which work exclusively on the Cogent AST and have no access to
the parsed C program any more. However, some of the postprocessing steps need information about the expression types and
some item properties, in particular the readonly processing described in Section~\ref{impl-post-readonly}. Therefore
this information must be added to the extended Cogent AST.

It would be possible to add the item associated types (see Section~\ref{impl-itemprops-types}) to the Cogent AST. However, 
some of the type properties, such as determining whether a type is linear or readonly, requires to expand typedef names
using the symbol table, and it requires to access the item properties. The symbol table and item properties are only 
available for monadic actions during C AST traversal (see Section~\ref{impl-ccode-trav}). Thus, it would be necessary to
implement all postprocessing by monadic actions. This could be avoided by pre-calculating all required type properties
and adding that information to the Cogent AST together with the C types. However, that would be inflexible and result in
a rather complex extended Cogent AST.

Therefore Gencot uses another approach by adding the Cogent type, determined according to Section~\ref{design-types}, to
the Cogent AST. The mapping from C types to Cogent types respects all relevant item properties, so that their effects are
present in the Cogent types.

However, typedef names are usually mapped to Cogent type names which hides the structure of the type associated with the
typedef name. To make this information available, a global table of all generated Cogent type definitions would be needed
to resolve used type names, which makes it necessary to implement the postprocessing steps as monadic actions using the
type definition table as state. Alternatively, the Cogent types could be constructed by resolving all type names, so that
their full structure is directly available and no global state is necessary for the postprocessing steps.

Using the second alternative would require to translate C types twice: once with type names resolved, for using the full type
information during postprocessing, and once with type names preserved, for using a type as part of the generated Cogent
code, where it should be as compact and similar to the C code as possible. There are even cases where types in the generated
Cogent code must be constructed from the additional type information of expressions (explicit type arguments specified for
polymorphic functions like \code{repeat}, see Section~\ref{impl-ccode-cstats}), therefore both forms must be added to the
Cogent AST.

To reduce this complexity Gencot implements types in the Cogent AST in a way that combines both forms. Basically, type names
are always fully resolved so that the type structure is available in a standalone way. Moreover, if the type or a part of
it has been determined by resolvong a type name, this type name is additionally specified in the type or its part, so that
it is available for the prettyprinter. When such a type is output to the Cogent code, the prettyprinter uses type names
instead of outputting the full type structure whenever available.

This form of types is directly used to implement the types as part of the Cogent AST and it is added to the following
other nodes in the Cogent AST: \code{Pattern}, \code{IrrefutablePattern}, and \code{Expr}. It cannot be added to
\code{Binding} and \code{Alt}, because these nodes cannot be extended. The remaining node \code{TopLevel} represents
toplevel definitions of types, functions, and constants, where enough type information is already available in the
normal Cogent AST structure.

\paragraph{Extended Cogent Surface Syntax AST}

Although the Cogent code generated by Gencot is only a restricted subset of the full Cogent syntax, Gencot extends all parts 
of the Cogent AST which can be extended (i.e. are parameterized in the type definitions). This is more systematic and 
allows arbitrary extending the subset of the generated Cogent syntax.

Together, Gencot uses types equivalent to the following definitions to represent its extended Cogent surface AST:
\begin{verbatim}
  data GenToplv =
    GenToplv (TopLevel GenType GenIrrefPatn GenExpr) Origin
  data GenExpr =
    GenExpr (Expr GenType GenPatn GenIrrefPatn () GenExpr)
            Origin GenType (Maybe Stm)
  data GenPatn =
    GenPatn (Pattern GenIrrefPatn)
            Origin GenType
  data GenIrrefPatn = 
    GenIrrefPatn (IrrefutablePattern VarName GenIrrefPatn GenExpr)
            Origin GenType
  data GenType = 
    GenType (Type GenExpr () GenType)
            Origin (Maybe String)
  type GenBnd = Binding GenType GenPatn GenIrrefPatn GenExpr
  type GenAlt = Alt GenPatn GenExpr
\end{verbatim}
The second parameter of \code{Type} and the fourth parameter of \code{Expr} have been added in 2020 for representing 
Dargent layout information. Gencot does not generate that and uses the unit type instead.

The third components in \code{GenExpr}, \code{GenPatn}, and \code{GenIrrefPatn} are the additional Cogent type information
mainly intended for postprocessing, as described above. The optional \code{String} in \code{GenType} is the alternative
representation by a type name to be used by the prettyprinter whenever available.

Type \code{Stm} is the type for C statements as defined by the language-c-quote AST 
(see Section~\ref{impl-ccode-expr}), used to optionally embed C code in the Cogent AST.

The types \code{GenBnd} and \code{GenAlt} are defined as abbreviations, the types of the corresponding nodes cannot be extended,
because they are not parameterized for \code{Expr} nodes in the Cogent AST. Type \code{GenBnd} is used as intermediate
representation for translating C statements and expressions (see Section~\ref{impl-ccode-cstats}).

All five wrapper types are defined as instances of class \code{Pretty}, basically by applying the Cogent prettyprint
functionality to the wrapped Cogent AST type.

\subsection{Mapping Names}
\label{impl-ccode-names}

Names used in the target code are either mapped from a C identifier or introduced, as described in 
Section~\ref{design-names}. Different schemas are used depending on the kind of name to be generated.
The schemas require different information as input.

\subsubsection{Name Mapping Configuration}

As described in Section~\ref{design-names} the general mapping schema is based on the replacement of 
name prefixes and can be configured. The configuration is specified in a ``name prefix map'' file.
It consists of a sequence of line, each line describes the mapping of a prefix in the form
\begin{verbatim}
  <prefix> <upper>|<lower>
\end{verbatim}
where \code{<prefix>} is the prefix to be replaced, \code{<upper>} is the replacement if the resulting 
name must begin with an uppercase letter, and \code{<lower>} is the replacement if the resulting name 
must begin with a lowercase letter. The prefix is separated by whitespace from the replacements, any remaining content 
in the line is ignored. If the replacement specification does not contain a \code{"|"} it is used for
both cases, converting the first letter to upper- or lowercase, as needed. If \code{<prefix>} is omitted
the empty prefix is replaced, i.e., the replacement is prepended to the name. 

If several lines are specified the prefixes are matched in the order of the lines and the first matching
prefix is applied. Note that the empty prefix always matches, hence lines following it are ignored.
Empty lines are always ignored, they do not prevent the use of subsequent lines.
At the end Gencot automatically appends a line of the form
\begin{verbatim}
  cogent_
\end{verbatim}
which results in the default mapping described in Section~\ref{design-names} if no other line matches.

The file content is read and converted to an internal representation of the form 
\begin{verbatim}
  type NamePrefixMap = [(String, (String, String))]
\end{verbatim}
which maps from the original prefix to the pair of replacements for uppercase and lowercase names.
This representation is added to the monadic user state so that it is available during the monadic AST traversal
(see Section~\ref{impl-ccode-trav}). A list is used instead a map so that the order of the map entries
is preserved.

\subsubsection{General Name Mapping}

The general mapping scheme is applied whenever a Cogent name is generated from an existing C identifier.
Its purpose is to adjust the case, if necessary and to avoid conflicts between the Cogent name and
the C identifier.

As input this scheme only needs the C identifier and the required case for the Cogent name.
It is implemented by the monadic action
\begin{verbatim}
  mapName :: Bool -> Ident -> f String
\end{verbatim}
where \code{f} is a \code{MapNamesTrav} and \code{MonadTrav} 
(see Section~\ref{impl-ccode-trav}). The first argument specifies whether the name must be uppercase. 
It uses the configuration from the user state to match and replace a prefix.

\subsubsection{Cogent Type Names}

A Cogent type name (including the names of primitive types) may be generated as translation of a C 
primitive type, a C typedef name, or a C struct/union/enum type reference. 

A C primitive type is translated according to the description in Section~\ref{design-types}. Only the
type specifiers for the C type are required for that.

A C typedef name is translated by simply mapping it with the help of \code{mapName} to an uppercase name.
Only the C typedef name is required for that.

A C struct/union/enum type reference may be tagged or tagless. If it is tagged, the Cogent type name is
constructed from the tag as described in Section~\ref{design-names}: the tag is mapped with the help of
\code{mapName} to an uppercase name, then a prefix \code{Struct\_}, \code{Union\_} or \code{Enum\_} is 
prepended. For this mapping the tag and the kind (struct/union/enum) are required. Both are contained
in the language-c type \code{TypeName} which is used to represent a reference to a struct/union/enum.

If the reference is untagged, Gencot nevertheless generates a type name, as motivated and described 
in Section~\ref{design-names}. As input it needs the kind and the position of the struct/union/enum 
definition. The latter is not contained in the \code{TypeName}, it contains the position of the reference
itself. To access the position of the definition, the definition must be retrieved from the symbol table
in the monadic state. To access the real name of the input file it must be retrieved from the user
state (see Section~\ref{impl-ccode-trav}). Hence, the mapping function is defined as a monadic action. 

Together the function for translating struct/union/enum type references is
\begin{verbatim}
  transTagName :: TypeName -> f String
\end{verbatim}
where \code{f} is the same as for \code{mapName}.

If the definition itself is translated, it is already available and need not be retrieved from the map. 
However, the user state is still needed to map the generic name \code{<stdin>} to the true source file 
name. Therefore Gencot uses function \code{transTagName} also when translating the definition.

\subsubsection{Cogent Function Names}

Cogent function names are generated from C function names. A C function may have external or internal
linkage, according to the linkage the Cogent name is constructed either as a global name or as a name specific
to the file where the function is defined. For deciding which variant to use for a function name reference,
its linkage must be determined. It is available in the definition or in a declaration for the function name,
either of which must be present in the symbol table. The language-c analysis module replaces all 
declarations in the tyble by the
definition, if that is present in the parsed input, otherwise it retains a declaration. 

A global function name is generated by mapping the C function name with the help of \code{mapName} to
a lowercase Cogent name. No additional information is required for that.

For generating a file specific function name, the file name of the definition is required. Note that 
this is only done for a function with internal linkage, where the definitions must be present in
the input whenever the function is referenced. The definition contains the position information
which includes the file name. Hence, the symbol table together with the real name of the input file 
is sufficient for translating the name. To make both available the translation function is defined as 
a monadic action.

In C bodies function names cannot be syntactically distinguished from variable names. Therefore, Gencot
uses a common function for translating function and variable names. For a description how variable
names are translated see Section~\ref{impl-ccode-expr}.
\begin{verbatim}
  transObjName :: Ident -> f String
\end{verbatim}
where \code{f} is the same as for \code{mapName}.

Similar as for tags, the function is also used when translating a function definition, although the 
definition is already available.

\subsubsection{Cogent Constant Names}

Cogent constant names are only generated from C enum constant names. They are simply translated
with the help of \code{mapName} to a lowercase Cogent name. No additional information is required.

\subsubsection{Cogent Field Names}

C member names and parameter names are translated to Cogent field names. Only if the C name is
uppercase, the name is mapped to a lowercase Cogent name with the help of \code{mapName}, 
otherwise it is used without change. Only the C name is required for that, in both cases it is
available as a value of type \code{Ident}. The translation is implemented by the function
\begin{verbatim}
  mapIfUpper :: Ident -> f String
\end{verbatim}
where \code{f} is the same as for \code{mapName}.

\subsubsection{Replacing Names of Global Variables}

As described in Section~\ref{design-fundefs-body}, accesses to global variables in a function body may 
be replaced by an access to a parameter introduced by a Global-State parameter or by an invocation of an 
access function, in case of a Const-Val property. To retrieve the properties of the global variable, its item
identifier must be constructed. To do this, Gencot must determine whether the identifier of an object 
used in a function body has local or global scope, since the item identifiers for the same C identifier
are different in both cases (see Section~\ref{impl-itemprops-ids}).

For variables the scope can be determined from the identifier's linkage.
If it has global scope it must have either internal or external linkage. If it has local scope it must have no
linkage. A locally declared variable with keyword \code{extern} has external linkage and only references a 
definition outside the function body, thus it has global scope. A locally declared variable 
with keyword \code{static} has no linkage, the keyword only specifies its storage class. Thus it has local scope
and is never replaced by Gencot.

For every name occurring in a C function body, which syntactically may be a global variable, Gencot looks up 
its definition in the symbol table. If it has external or internal linkage Gencot constructs its item identifier
and retrieves its declared properties. If a Global-State property has been declared, Gencot accesses the 
function definition in the monadic user state (see Section~\ref{impl-ccode-trav}) and determines its virtual
parameter items with Global-State properties. If one of them has the same Global-State property as the global
variable its name is mapped, the C dereference operator \code{*} is applied to it, and the resulting expression
is used instead of the variable name.

Otherwise, if the Const-Val property has been declared for the variable, it is replaced by an invocation of the 
parameterless access function. The function name is determined by mapping the variable name. Otherwise the 
variable name is not replaced and only mapped to the Cogent naming scheme.

\subsection{Generating Origin Markers}
\label{impl-ccode-origin}

For outputting origin markers in the target code, the AST prettyprint functionality must be extended.

The class \code{Pretty} used by the Cogent prettyprinter defines the methods
\begin{verbatim}
  pretty :: a -> Doc
  prettyList :: [a] -> Doc
\end{verbatim}
but the method \code{prettyList} is not used by Cogent. Hence, only the method \code{pretty} needs to be defined
for instances. The type \code{Doc} is that from module \code{Text.PrettyPrint.ANSI.Leijen}.

The basic approach is to wrap every syntactic construct in a sequence of \code{\#ORIGIN} markers and 
a sequence of \code{\#ENDORIG} markers according to the origin information for the construct in the extended AST. 
This is done by an instance definition of the form
\begin{verbatim}
  instance Pretty GenToplv where
    pretty (GenToplv org t) = addOrig org $ pretty t
\end{verbatim}
for \code{GenToplv} and analogous for the other types. The function \code{addOrig} has the type
\begin{verbatim}
  addOrig :: Origin -> Doc -> Doc
\end{verbatim}
and wraps its second argument in the origin markers according to its first argument.

The Cogent prettyprinter uses indentation for subexpressions. Indentation is implemented by the \code{Doc} type, 
where it is called ``nesting''. The prettyprinter maintains a
current nesting level and inserts that amount of spaces whenever a new line starts. 

The origin markers must be positioned in a separate line, hence \code{addOrig} outputs a newline before and after
each marker. This is done even at the beginning of a line, since due to indentation it cannot safely be determined
whether the current position is at the beginning of a line. Cogent may change the nesting of the next line after \code{addOrig}
has output a marker (typically after an \code{\#ENDORIG} marker). The newline at the end of the previous marker 
still inserts spaces according to the old nesting level, which determines the current position at the begin of
the following marker. This is not related to the new nesting level. 

This way many additional newlines are generated, in
particular an empty line is inserted between all consecutive origin markers. The additional newlines are later removed
together with the markers, when the markers are processed. Note that, if a syntactic construct
is nested, the indentation also applies to the origin markers and the line after it. To completely remove an
origin marker from the target code it must be removed together with the newline before it and with the newline 
after it and the following indentation. The following indentation can be determined since it is the same as that 
for the marker itself (a sequence of blanks of the same length). 

\subsubsection{Repeated Origin Markers}

Normally, target code is positioned in the same order as the corresponding source code. This implies, that
origin markers are monotonic. A repeated origin marker is a marker with the same line number as its previous marker.
Repeated origin markers of the same kind must be avoided, since they would result in duplicated comments or 
misplaced directives.
Repeated origin markers of the same kind occur, if a subpart of a structured source code part begins or ends 
in the same line as its main part. In this case only the outermost markers must be retained.

An \code{\#ENDORIG} marker repeating an \code{\#ORIGIN} marker means that the source code
part occupies only one single line (or a part of it), this is a valid case. 
An \code{\#ORIGIN} marker repeating an \code{\#ENDORIG} marker means that the previous source code
part ends in the same line where the following source code part begins. In this case the markers are
irrelevant, since no comments or directives can be associated with them. However, if they are
present they introduce unwanted line breaks, hence they also are avoided by removing both of them.

Together, the following rules result. In a sequence of repeated \code{\#ORIGIN} markers, only the first one 
is generated. In a sequence of repeated \code{\#ENDORIG} markers only the last one is generated.
If an \code{\#ORIGIN} marker repeats an \code{\#ENDORIG} marker, both are omitted.

There are several possible approaches for omitting repeated origin markers:
\begin{itemize}
\item omit repeated markers when building the Cogent AST
\item traverse the Cogent AST and remove markers to be omitted
\item output repeated markers and remove them in a postprocessing step
\end{itemize}
Note, that it is not possible to remove repeated markers already in the language-c AST, since there a \code{NodeInfo}
value always corresponds to two combined markers.

Handling repeated markers in the Cogent AST is difficult, because for an \code{\#ORIGIN} marker the context
before it is relevant whereas for an \code{\#ENDORIG} marker the context after it is relevant. An additional
AST traversal would be required to determine the context information. The first approach is even more complex
since the context information must be determined from the source code AST where the origin markers are not
yet present. 

For this reason Gencot uses the third approach and processes repeated markers in the generated target code text,
independent from the syntactical structure.

\subsubsection{Filter for Repeated Origin Marker Elimination}

The filter \code{gencot-reporigs} is used for removing repeated origin markers. It is implemented as an awk script.

It uses five string buffers: two for the previous two origin markers read, and three for the code before,
between, and after both markers. Whenever all buffers are filled (the buffer after both markers with a 
single text line; this line exists, since consecutive markers are always separated by an empty line),
the markers are processed as follows, if they have the same line number: in the case of two 
\code{\#ORIGIN} markers the second is deleted, in the
case of two \code{\#ENDORIG} markers the first is deleted, and in the case of an \code{\#ORIGIN}
marker after an \code{\#ENDORIG} marker both are deleted. In the latter case the line number of the
\code{\#ORIGIN} marker is remembered and subsequent \code{\#ORIGIN} markers with the same line number
are also deleted.

When both markers have different line numbers or if an \code{\#ENDORIG} marker follows an \code{\#ORIGIN}
marker the first marker and the code before it are output and the buffers are filled until the next marker
has been read.

\subsection{Generating C Expressions}
\label{impl-ccode-expr}

For outputting the Cogent AST the prettyprint functionality must be extended to 
output the embedded C code. In that C code origin markers must be generated to be able to re-insert comments and 
preprocessor directives. Finally, all names
occurring free in the embedded C code must be mapped to Cogent names.

The language-c prettyprinter is defined in module \code{Language.C.Pretty}. It defines an own class \code{Pretty} with 
method \code{pretty} to convert the AST types to a \code{Doc}. However, other than the Cogent prettyprinter, it uses 
the type \code{Doc} from module \code{Text.PrettyPrint.HughesPJ} instead of module \code{Text.PrettyPrint.ANSI.Leijen}.
This could be adapted by rendering the \code{Doc} as a string and then prettyprinting this string to a \code{Doc}
from the latter module. This way, a prettyprinted embedded C code could be inserted in the document created by the
Cogent prettyprinter.

\subsubsection{Origin Markers}

For generating origin markers, a similar approach is not possible, since they must be inserted between single statements,
hence, the function \code{pretty} must be extended. Although it does not use the \code{NodeInfo}, it is only defined for
the AST type instances with a \code{NodeInfo} parameter and has no genericity which could be exploited for extending it.
Therefore, Gencot has to fully reimplement it. 

In the prettyprint reimplementation the target code parts must be wrapped by origin markers
in the same way as for the Cogent AST. However, for the type \code{Doc} from module \code{Text.PrettyPrint.HughesPJ} 
this is not possible, since newlines are only
available as separators between documents and cannot be inserted before or after a document. An alternative choice
would be to use the type \code{Doc} from \code{Text.PrettyPrint.ANSI.Leijen}, as the Cogent prettyprinter does.
However, the approach of both modules is quite different so that it would be necessary to write a new C 
prettyprint implementation nearly from scratch. 

It has been decided to use another approach which is expected to be simpler. The alternative C parser language-c-quote 
also has a prettyprinter. It generates a type \code{Doc} defined by a third module \code{Text.PrettyPrint.Mainland}.
It is similar to \code{Text.PrettyPrint.ANSI.Leijen} and also supports adding newlines before and after a document.
The language-c-quote prettyprinter is defined in the module \code{Language.C.Pretty} of language-c-quote and consists
of the method \code{ppr} of the class \code{Pretty} defined in module \code{Text.PrettyPrint.Mainland.Class.Pretty}.
This method is not generic at all, hence it must be completely reimplemented to extend it for generating origin 
markers. However, this reimplementation is straightforward and can be done by copying the original implementation
and only adding the origin marker wrappings. The resulting Gencot module is \code{Gencot.C.Output}.

Whereas the type \code{Doc} from \code{Text.PrettyPrint.ANSI.Leijen} provides a \code{hardline} document which always
causes a newline in the output, the type \code{Doc} from \code{Text.PrettyPrint.Mainland} does not. Normal line breaks
are ignored in certain contexts, if there is enough room. Using normal line breaks around origin markers could result
in origin markers with other code in the same line before or after the marker.

For the reimplemented language-c-quote prettyprinter Gencot defines its own \code{hardline} by using a newline 
which is hidden for type \code{Doc}. This could be implemented without nesting the marker and the subsequent line.
However, if at the marker position a comment is inserted, the subsequent line should be correctly indented.
To achieve this, the \code{hardline} implementation also adds the current nesting after the newline.

Hiding the newline from \code{Doc} implies that the ``current column'' maintained by \code{Doc} is not
correct anymore, since it is not reset by the \code{hardline}. Every \code{hardline} will instead advance the current
column by the width of the marker and twice the current nesting. This has two consequences.

First, in some places the language-c-quote prettyprinter uses ``alignment'' which means an indentation of subsequent lines
to the current column. This indentation will be too large after inserted markers. Gencot handles this by replacing 
alignment everywhere in the prettyprint implementation by a nesting of two additional columns. 

Second, the language-c-quote prettyprinter is parameterized by a ``document width''. It automatically breaks lines 
when the current column exceeds the document width. The incorrect column calculation causes many additional such
line breaks, since the current column increases much faster than normal. Gencot handles this by setting the document
width to a very large value (such as 2000 instead of 80) to compensate for the fast column increase.

\subsubsection{Using the language-c-quote AST}

Language-c-quote uses a different C AST implementation than language-c. To use its reimplemented prettyprinter, the 
language-c AST must be translated to a language-c-quote AST. This is not trivial, since the structures are somewhat
different, but it seems to be simpler than implementing a new C prettyprinter. The translation is implemented in
the module \code{Gencot.C.Translate}. 

Additionally the language-c-quote AST must be extended by \code{Origin} values. The language-c-quote AST already 
contains \code{SrcLoc} values which are similar to the \code{NodeInfo} values in language-c. Like these they cannot
be used as origin marker information since they cannot represent begin and end markers independently. Therefore
Gencot also reimplements the language-c-quote AST by copying its data types and replacing the \code{SrcLoc}
values by \code{Origin} values. This is implemented in module \code{Gencot.C.Ast}.

As described in Section~\ref{impl-ccode-gencog}, the extended Cogent AST uses only statements from
this C AST for embedding C code. However, the wrapper functions are also generated using the C AST and they 
need complete C function definitions and embedded antiquoted Cogent types. Therefore the complete 
language-c-quote AST is reimplemented in \code{Gencot.C.Ast}.

Together, this approach yields a similar structure as for the translation to Cogent: The Cogent AST is extended 
by the structures in \code{Gencot.C.Ast} to represent embedded C code. The function for
translating from language-c AST to the Cogent AST is extended by the functions in \code{Gencot.C.Translate} to
translate code from the language-c AST to the reimplemented language-c-quote 
AST, and the Cogent prettyprinter is extended by the prettyprinter
in \code{Gencot.C.Output} to print embedded C code with origin markers.

In addition to translating the C AST structures from language-c to those of language-c-quote, the translation
function in \code{Gencot.C.Translate} implements the following functionality:
\begin{itemize}
\item generate \code{Origin} values from \code{NodeInfo} values,
\item map C names to Cogent names.
\end{itemize}

\subsubsection{Name Mapping}

Name mapping depends on the kind of name and may additionally depend on its type. Both information is
available in the symbol table (see Section~\ref{impl-ccode-trav}). However, the scope cannot be queried
from the symbol table. Hence it is not possible to map names depending on whether they are locally defined
or globally.

The following kinds of names may occur in a function body: primitive types, typedefs, tags, members, 
functions, global variables, enum constants, preprocessor constants, parameters and local variables.

Primitive type names and typedef names can only occur as name of a base type in a declaration. Primitive
type names are mapped to Cogent primitive type names as described in Section~\ref{design-types-prim}.

A typedef name may also occur in a declarator of a local typedef which defines the name. 
In both cases, as described in Section~\ref{design-fundefs-body}, Gencot
only maps the plain typedef names, not the derived types. The typedef names are mapped according to
Section~\ref{design-types-typedef}: If they ultimately resolve to a struct, union, or array type they
are mapped with an unbox operator applied, otherwise they are mapped without.

A tag name can only occur as base type in a declaration. It is always mapped to a name with a prefix 
of \code{Struct\_}, \code{Union\_}, or \code{Enum\_}. Tagless structs/unions/enums are not mapped at all.
Tag names are mapped according to Sections~\ref{design-types-enum} and~\ref{design-types-struct}: struct
and union tags are mapped with an unbox operator applied, enum tags are mapped without.

Gencot also maps defining tag occurrences. Thus an occurrence of the form 
\begin{verbatim}
  struct s { ... }
\end{verbatim}
is translated to
\begin{verbatim}
  struct #Struct_s { ... }
\end{verbatim}

Every occurrence of a field name can be syntactically distinguished. It is mapped according to 
Section~\ref{design-names} to a lowercase Cogent name if it is uppercase, otherwise it is unchanged.
Field names are also mapped in member declarations in locally defined structures and unions.

All other names syntactically occur as a primary expression. They are mapped depending on their semantic
information retrieved from the symbol table. In a first step it distinguishes objects, functions, 
and enumerators.

An object identifier may be a global variable, parameter, or local variable. It may also be a preprocessor 
constant since for them dummy declarations have been introduced which makes them appear as a global variable
for the C analysis. For the mapping the linkage is relevant, this is also available from the symbol table.

Identifiers for global variables may have external or internal linkage and are mapped depending on the
linkage. Identifiers for parameters always have no linkage and are always mapped like field names. Identifiers
for local variables either have no linkage or external linkage. In the first case they are mapped like
field names. In the second case they cannot be distinguished from global variables with external linkage,
and are mapped to lowercase. The dummy declarations introduced for preprocessor constants
always have external linkage, the identifiers are mapped to lowercase. Together, object identifiers with 
internal linkage are mapped as described in Section~\ref{design-names}, object identifiers with external
linkage are mapped to lowercase, and object identifiers with no linkage are mapped to lowercase if they are
uppercase and remain unchanged otherwise.

An identifier for a function has either internal or external linkage and is mapped depending on its linkage.
An identifier for an enumerator is always mapped to lowercase, like preprocessor constants.

Identifiers for local variables may also occur in a declarator of a local object definition which defines 
the name. They are also mapped depending on their linkage, as described above.

\subsection{Translating C Expressions}
\label{impl-ccode-cexpr}

The translation produces Cogent code in a simple and straightforward manner. The resulting code is highly inefficient
and large, it is intended for being improved in postprocessing steps.

\subsubsection{General Translation of C Expressions}

In C an expression can not only have side effects, side effects can even be sequenced, i.e., the result of a side
effect can be observed and used for another side effect, for example by using the comma operator. To cover sequenced 
side effects, Gencot uses binding lists as intermediate representation for expressions. The meaning is that the 
rest of a list is evaluated in the context established by the first binding. 

Related to accessing components of struct and array values Gencot uses \code{take} and \code{put} operations in Cogent.
Components accessed by a \code{take} operation must usually be put back after use. To make the component value accessible
as result value of an expression it is bound to a variable in between. Therefore Gencot represents a translated expression
by a binding list together with a variable for accessing the result value.

In C an expression may also denote an ``lvalue'' which can be modified. Gencot represents modifications by binding a
new value to specific variables. Therefore the representation of a translated expression also includes an optional
``lvalue'' variable for this case.

The type \code{ExprBinds} is used as intermediate representation for a translated C expression. Gencot uses a common
monadic action
\begin{verbatim}
  bindExpr :: CExpr -> FTrav ExprBinds
\end{verbatim}
to translate every expression to the intermediate representation, irrespective of the expression kind.

As variable for the expression value Gencot uses variables named \code{v<n>'}, where \code{v0'} is abbreviated to 
\code{v'}. Due to the prime character this is
a valid identifier in Cogent but not in C, so it cannot collide with any other variable taken and mapped from the C
code. The \code{<n>} is a natural number increased for each (sub)expression so that the variables for all expression 
values are distinct. Note that, since expression values can only be used once at the position where the expression 
is syntactically placed, every value variable will also be used only once (in translations of assignments and
increment/decrement operators it is used twice, but immediately together in a tuple expression) and could be reused afterwards for 
other expressions. However, the value of an expression is not always used before another expression is evaluated,
therefore the value variables are constructed so that they are unique. Only if in the construction of an expression
one or more value variables are used one of them (usually that with the lowest number) is reused for binding the expression value.

The binding which binds the expression result to a variable has the general form
\begin{verbatim}
  (v<n>',v1..) = expr
\end{verbatim}
with value variable \code{v<n>'}. The term \code{v1..} abbreviates
the sequence \code{v1},...,\code{vn} of the mapped names of all C identifiers affected by side effects of the expression, their values
are specified in the corresponding components of the tuple value of \code{expr}. Often, \code{expr} will be a tuple 
expression of the same size as the pattern, but in some cases not (e.g., for function calls or dummy expressions). 
The variables \code{v1}, ..., \code{vn} are called ``side effect targets'' and occur in the pattern in arbitrary order.
If there are no side effect targets, the lhs pattern is the single variable \code{v<n>'} and the rhs is the expression for
the value bound to it.

If Gencot cannot translate an expression it translates it to a single binding where the rhs is a dummy expression as described in 
Section~\ref{design-cstats-dummy}. The lhs may still contain side effect targets, if Gencot detects that the expression
modifies these C objects.

The binding list can be combined to a single binding by the function
\begin{verbatim}
  cmbBinds :: ExprBinds -> GenBnd
\end{verbatim}
If the value variable of the \code{ExprBinds} is \code{v<n>'} the resulting binding has the form
\begin{verbatim}
  (v<n>',v1..) = 
  let b1 and ... and bk
  in (v<n>',v1..)
\end{verbatim}
where \code{b1}, ... , \code{bk} are the bindings in the list and the \code{v1..} are all side
effect targets which occur in the list. Binding lists are usually only combined when their code is evaluated conditionally.

\subsubsection{Dealing with Subexpressions}

An expression with subexpressions is translated to a binding list which first binds the subexpressions to value
variables and then uses these variables in the final binding as replacement for the subexpressions. The subexpressions
are translated to binding lists using \code{bindExpr}.

The C standard defines ``sequence points'' for subexpression groups in some expressions. This means that side effects 
occurring in subexpressions before the sequence point are observable in subexpressions after the sequence point. Otherwise
subexpressions are ``unsequenced'', then the semantics is undefined if their side effects overlap (either the target of 
one can be observed in another subexpression or side effects in two subexpressions have common targets). 

Gencot does not translate expressions where side effects of unsequenced subexpressions overlap for an object determined 
by the same identifier in C. Otherwise it translates every group of unsequenced subexpressions to a binding list
and concatenates these lists according to the sequencing of the groups.

The binding lists of unsequenced subexpressions are concatenated in arbitrary order. Because the subexpressions have no
overlapping side effect targets, the side effect targets are all distinct. As described above, the value variables are 
constructed so that they are distinct for all subexpressions. Together, no variable will be rebound by concatenating the lists. 

Note that it is not sufficient to use value variables numbered from 1 to \code{n} for \code{n} subexpressions. The same variables
could be used for subexpressions of the subexpressions and would be rebound when the lists are concatenated.

Note also that there can be overlapping side effects for struct components, array elements, and objects accessed through
shared pointers. These overlapping side effects are not determined by Gencot, the resulting translation corresponds to
one possible semantics of the C program resulting from the specific sequencing used for the unsequenced subexpressions. 
If unwanted, such situations must be detected and corrected manually.

\subsubsection{Expressions for Values with Pointers}

In C even an expression which is not an ``lvalue expression'' can cause side effects, if the expression evaluates to a 
value which is a pointer or contains a pointer and occurs in a context where it is possible to use the pointer to access 
and modify the referenced data. In the translation the possible side effect must be respected by binding a variable to the 
value with the pointer referencing the modified data. In general it is not clear which variable to use here.

In C a value containing a pointer is either the pointer itself, or it is a container with a component containing a pointer,
i.e., a struct with a member containing a pointer, or an array where the elements contain a pointer. In C an expression
for a pointer or container is either an identifier, a component accessed in another container, an application of the derefence
operator \code{*}, or a function invocation which 
returns the pointer or container as its result. A container can also be designated by a compound literal. A pointer can also
be designated by an application of the \code{\&} operator, or by ``pointer arithmetics'', i.e., by arithmetic operations 
involving pointers.

If a pointer or container is used in a context, the subexpression for the pointer or container is translated by Gencot as 
described above, resulting in a binding list which binds the pointer or container to a value
variable \code{v<n>'}. The use in the context results in another binding which uses \code{v<n>'}.
This binding must be extended by a side effect target for the pointer or container after possible modification. 

If the pointer or container is specified in C by an identifier, the identifier is mapped to a Cogent variable 
which is bound to \code{v<n>'}. This mapped identifier is then used as side effect target. If there is no sharing, all 
subsequent uses of the pointer or container must be through the same identifier, therefore the modifications will be
respected by the re-binding.

If the pointer or container is specified in C by access to a component of another container, the value variable 
\code{v<n>'} is bound to the corresponding component variable, as described in the following subsection about 
accessing struct members and array elements. This component variable is used as side effect target to bind the pointer
or container value after modification. Since the component variable is also used in the putback operation, the surrounding
container will be affected by the modification. As described below, if the pointer or container is specified by dereferencing
another pointer, Gencot treats this in the same way as for a component access, using a component variable.

If the pointer or container is specified in C by any other expression, it can only be accessed afterwards if it is shared 
by another C object. Usually, Gencot cannot automatically translate such cases to valid Cogent code. Therefore Gencot 
does not bind the pointer or container after modification to a variable, it uses the error variable \code{err'} instead. Since
the error variable is never referenced this
means the pointer or container is ``discarded'' in Cogent. Depending on the further processing in following translation 
stages this may cause a corresponding error message by the Cogent compiler.

\subsubsection{Accessing Struct Members and Array Elements}

The most general way of accessing struct members and array elements in Cogent is the \code{take} operation. It separates
the member or element from its container data structure and binds both to variables. Since the \code{take} operation 
syntactically is a pattern, the access expressions can be represented by a binding list, like all other expressions.

In general the \code{take} operation modifies the type of the container value. To restore it the component must 
be re-inserted after being used or replaced which is done by a \code{put} operation. A \code{put} operation is a Cogent
expression which returns the reassembled container. Gencot binds it to the same variable which has been used 
to bind the remaining container in the \code{take} operation. The resulting binding always consists of the single
variable bound to the \code{put} expression.

The variable to which the component is bound by the \code{take} operation is used by the \code{put} operation for the 
reassembling. Therefore it cannot be a value variable since it may be used more than once. Gencot uses variable names 
of the form \code{p<n>'} for this purpose, called component variables. They are distinct from all value variables and, 
due to the prime character, from all mapped C identifiers. The \code{<n>} is a natural number increased for each \code{take}
operation so that the variables for all taken components are distinct.

The variable to which the remaining container is bound in the \code{take} operation is determined as described for values 
with pointers. Cases where there are no pointers in the container or where no modifications can occur are handled in later
translation stages.

If the container is an array, the \code{put} operation needs to use the same element index as the \code{take} operation. 
In the \code{take} operation it is available as a value variable which could be reused before the \code{put} operation.
Therefore the index is bound to an additional variable of the form \code{i<n>'} where \code{<n>} is the same number as for 
the component variable. These variables are called index variables.

Between the \code{take} and \code{put} bindings the component variable may be rebound. This way it is possible to translate
side effects modifying the component and thus its container. In such a rebinding the component variable occurs as a normal side
effect target.

If it has been rebound the component must be put back before it is accessed again in the same expression and before the container
has been modified in other ways. Therefore Gencot always
puts it back as soon as possible, i.e., as soon as it has been bound to a value variable or has been rebound. However, a component
may also be used by accessing a nested component using a nested take and put. Nested component access can be arbitrarily deep,
therefore it may be translated to an arbitrarily long sequence of take bindings, followed by a component binding or rebinding,
followed by a list of put bindings in the opposite order of the take bindings, so that components which are taken
first are put back last.

A struct member access \code{e.m} has only one subexpression \code{e} for denoting the struct. A read access is translated to the
following binding sequence:
\begin{verbatim}
  <v>{m=p<k>'} = v<n>'
  v<n>' = p<k>'
  <v> = <v>{m=p<k>'}
\end{verbatim}
where \code{v<n>'} is the value variable bound in the translation of \code{e}, \code{<v>} is a variable
depending on the expression bound to \code{v<n>'} in translation of \code{e} as described above, and \code{p<k>'}
is a new component variable.

If the struct component is used as an lvalue the component variable \code{p<k>'} is re-bound to the new value by additional
bindings inserted between the second and third binding.

A Cogent \code{take} operation can be applied to boxed and to unboxed record types. In the member access \code{e.m} the expression
\code{e} corresponds to an unboxed record, in the member access \code{e->m} it corresponds to a boxed record. Therefore the
member access \code{e->m} is translated by Gencot in the same way as \code{e.m}, the difference can be detected by looking at
the type of \code{v<n>'}.

An array element access \code{e1[e2]} has two unsequenced subexpressions \code{e1}, \code{e2} for denoting the array and the index value.
The array access is translated by first concatenating the binding list for \code{e1} after \code{e2}. Then a read access is translated
to the following binding sequence:
\begin{verbatim}
  (<v> @{@v<l>'=p<k>'},i<k>') = (v<n>',v<l>')
  v<n>' = p<k>'
  <v> = <v> @{@i<k>'=p<k>'}
\end{verbatim}
where \code{v<n>'} is the value variable bound in the translation of \code{e1}, \code{v<l>'} is the value variable bound in the translation
of \code{e2}, \code{i<k>'} is the index variable corresponding to \code{p<k>'}, and \code{<v>} and \code{p<k>'}
are as above.

If the array element is used as an lvalue the component variable \code{p<k>'} is re-bound to the new value by additional
bindings inserted between the second and third binding.

Here the specific Cogent array \code{take} and \code{put} operations are used. In Cogent they can only be applied if \code{v<n>'}
has a builtin array type. This is never the case for the code generated by Gencot, the mapped array types use builtin array types,
but they are wrapped in record types (see Section~\ref{design-types-array}). Moreover, in C an array element access can be applied
to any pointer which is not a function pointer, therefore the type of \code{v<n>'} can result from mapping any C array or pointer
type to Cogent, as described in Sections~\ref{design-types-array} and~\ref{design-types-pointer}. The array \code{take} and \code{put}
operations are only used as intermediate representations here, they will be completely replaced by other code constructs in the
postprocessing steps, depending on the type of \code{v<n>'}.

\subsubsection{Translating Pointer Dereferences}

A pointer dereference is denoted in C by an application of the unary operator \code{*} to a subexpression \code{e} which evaluates to
a pointer value. Depending on the type of the referenced value (container, function, other) and whether they can be \code{NULL},
pointers are treated differently by Gencot (see Section~\ref{design-types-pointer}).

In the first translation step Gencot only differentiates between function pointers and all other pointers. Function pointers
can only be dereferenced for invoking the function, this is always implemented by Gencot using the abstract function
\code{fromFunPtr} (see Section~\ref{design-operations-function}). The following binding is appended to the translation of \code{e}:
\begin{verbatim}
  v<n>' = fromFunPtr[ft,fpt] v<n>'
\end{verbatim}
where \code{v<n>'} is the value variable bound in the translation of \code{e}. The types \code{ft} and \code{fpt} are
the types of the function and the function pointer, they must be explicitly specified because \code{fromFunPtr} is polymorphic.

For all other pointers Gencot translates pointer dereferences as if the
pointer type would be translated to a type \code{(CPtr T)} by accessing the \code{cont} component. That is, an expression
\code{*e} is translated by \code{bindExpr} like \code{e.cont} to a binding list involving a \code{take} and a \code{put}
operation as described for struct member accesses. A read access is translated to the following binding sequence:
\begin{verbatim}
  <v>{cont=p<k>'} = v<n>'
  v<n>' = p<k>'
  <v> = <v>{cont=p<k>'}
\end{verbatim}
where \code{v<n>'} is the value variable bound by the translation of \code{e}, \code{<v>} is a variable
depending on the expression bound to \code{v<n>'} in the translation of \code{e} as described above, and \code{p<k>'}
is a new component variable.

Semantically this means that the referenced content is separated from the pointer in a \code{take} binding and is bound
to \code{p<k>'} and then both are recombined by the \code{put} binding.

If the dereferenced pointer is used as an lvalue the component variable \code{p<k>'} is re-bound to the new value by additional
bindings inserted between the second and third binding.

Note that a member access \code{e->m} is equivalent to \code{(*e).m} but the latter is translated in two steps using two
nested \code{take} and \code{put} pairs. This form will be simplified by postprocessing steps.

Note also that, similar as for array element accesses, there are cases where the \code{take} and a \code{put} operations cannot
actually be applied, because the mapped type of \code{e} is no record with a \code{cont} component. It may even be a mapped
array type, because in C pointer dereference can be applied to arrays, which accesses the first array element. In these cases
the \code{take} and a \code{put} are only intermediate representations which will be replaced by postprocessing steps.

\subsubsection{Acessing Global Objects}

An identifier referenced in a function body may denote a global object. This can only be translated in three possible cases: if
the global object has a Const-Val or a Global-State property (see Section~\ref{design-types-itemprops}) or if it is a
preprocessor constant (see Section~\ref{design-const}). In the following, let \code{<id>} be the mapped name of the identifier
referencing the global object.

If the global object has a Const-Val property, it is translated by Gencot as a parameterless access function which returns
the value of the global object. In this case the object reference is translated to an invocation of the access function. The
name of the access function is the mapped name of the C object. The resulting binding is
\begin{verbatim}
  v<n>' = <id> ()
\end{verbatim}

If the global object has a Global-State property it can be accessed if the surrounding function has a parameter with the same
property. If no such parameter exists a dummy expression with an error message is generated. Since the parameter is used to
pass a pointer to the global object an additional pointer dereference is generated by Gencot.
A read access is translated to the following binding sequence:
\begin{verbatim}
  gsp{cont=p<k>'} = v<n>'
  v<n>' = p<k>'
  gsp = gsp{cont=p<k>'}
\end{verbatim}
where \code{gsp} is the name of the parameter with the Global-State property and \code{v<n>'} is the value variable bound
to it and \code{p<k>'} is a new component variable.

If the global object is used as an lvalue the component variable \code{p<k>'} is re-bound to the new value by additional
bindings inserted between the second and third binding.

The global object may also be a preprocessor constant, because for them dummy declarations have been created by Gencot, as
described in Section~\ref{impl-ccode-dummydecl}. These dummy declarations cause them to appear like global C objects. Since
preprocessor constants are translated to Cogent value definitions they can be directly accessed in the Cogent code. Therefore
they are translated to a reference to a Cogent variable of the mapped name of the preprocessor constant. The resulting binding is
\begin{verbatim}
  v<n>' = <id>
\end{verbatim}
Note, that such
a Cogent variable is never bound in the context of this code, it always references the toplevel Cogent value definition.

The remaining case is a true global C object with neither of the two properties. This case cannot be translated to Cogent.
Since it is not possible to distinguish this case from the preprocessor constant, Gencot always assumes that global objects
which have neither property are preprocessor constants and translates them accordingly. If that assumption is wrong, no
Cogent definition or binding will exist for the generated variable reference and the Cogent compiler will signal an error.
It us up to the user to add the properties to all global C objects which are accessed in translated function bodies.

\subsubsection{Translating the Address Operator}

The address operator \code{\&} is used in C to determine a pointer to an object. If applied to a function, Gencot
translates it using the abstract function \code{toFunPtr} (see Section~\ref{design-operations-function}).

Gencot does not translate other expressions which
apply the address operator to a subexpression, this must be done manually (see Section~\ref{app-transfunction-addrop}).

\subsubsection{Translating Function Calls}

A function call \code{f(e1,..,em)} has the function \code{f} to be applied and all actual arguments as subexpressions,
these are treated as usual. Then the application is translated to the following binding sequence:
\begin{verbatim}
  v<n>' = v<n>' (v<n1>',..,v<nm>')
\end{verbatim}
where \code{v<n>'} is the value variable bound in the translation of the function subexpression \code{f}. It can
always be reused because it is always present, in contrast to the value variables for binding the parameter values in case
the function has no parameters. If the function has result type
\code{void} in C the result has unit type in Cogent, then the unit value will become bound to \code{v<n>'}.

Depending on its type and on item properties for the function and its arguments, the function may take additional arguments and
it may return a tuple with additional results. Also, the function may be variadic or incomplete. The following item properties
must be directly processed here, since they cause the introduction of additional function arguments or result components:
Heap-Use, Add-Result, and Global-State. The other item properties only affect the translation of types and are thus implicitly
included in the translated types added to the expressions and patterns, so they can be handled in later translation stages.

The item properties Heap-Use and Global-State introduce additional function arguments, for them actual values must be determined
to pass to the function invocation. In both cases the additional arguments must also be present for the surrounding function
definition for which the body contains the invocation. The corresponding variable names are used as actual arguments for the
invocation. In the case of Heap-Use it is a fixed name as described in Section~\ref{design-types-itemprops}, in the case of
Global-State it is the name of the corresponding virtual parameter.

The item properties Add-Result, Heap-Use, and Global-State introduce additional result components. In that case the binding has 
the form
\begin{verbatim}
  (v<n>',v1..) = f(v<n1>',..,v<nm>')
\end{verbatim}
with a tuple pattern. The variables \code{v1..} correspond to the properties Add-Result, Global-State, and Heap-Use in that order.
The variable for a component added by an Add-Result property is determined as described for expressions for values with pointers,
i.e., it is either a mapped C variable name, or a component variable, or the error variable \code{err'}. The variable for a component
added by a Global-State or Heap-Use property is the same which is used as actual argument for the corresponding parameter, i.e.,
it is the name of the corresponding parameter of the surrounding function.

\subsubsection{Translating lvalue Expressions}

In C the targets of side effects are denoted by ``lvalue expressions'' which occur as subexpressions in assignment expressions and
in increment/decrement expressions. An lvalue expression has the same form as any other expression and is only determined by its 
position as subexpression in the surrounding expression. However, expressions which may occur as valid lvalue expressions are 
restricted mainly to variables, container component accesses, and pointer dereferences.

Gencot translates lvalue subexpressions in the same way as other subexpressions to a binding lists using \code{bindExpr}.
As described above, for all cases where the subexpression is a valid lvalue expression, the resulting \code{ExprBinds} also
specifies a variable \code{v} which can be used to modify the lvalue by re-binding it to the new value. This variable is always
either a mapped C object identifier, or a component variable.

The binding list of the translated lvalue expression always contains a binding
\begin{verbatim}
  v<n>' = v
\end{verbatim}
which makes the value of \code{v} available for read accesses using the value variable \code{v<n>'}. If the expression is used
as an lvalue, the additional binding
\begin{verbatim}
  (v<n>',v) = (v<k>',v<k>')
\end{verbatim}
is inserted immediately afterwards into the binding list.
Here \code{v<k>'} is the value variable bound by the translated expression corresponding to the new value assigned as side effect.
It is also the result of the assignment expression, therefore it is additionally bound to the (reused) value variable \code{v<n>'}.
Note that this is the only case where a value variable can be used twice, however, it is always used in the same binding.

Of course, appending this binding makes the binding for the read access obsolete, because \code{v<n>'} is re-bound without being
used. However, such unused bindings are removed in later processing steps anyways, so Gencot does not care about it here.

As an example, for the assignment expression \code{x = 5} the concatenated binding lists for the subexpressions yield the
list 
\begin{verbatim}
  v1' = 5
  v' = x
\end{verbatim}
which is extended for the translated assignment expression by appending the binding
\begin{verbatim}
  (v',x) = (v1',v1')
\end{verbatim}
so that \code{v'} represents the result value of the assignment expression and \code{x} is the modified side effect target.

The translation of \code{a[i].m = 0} yields the binding list
\begin{verbatim}
  v2' = 0
  v1' = i
  (a @{@v1'=p1'},i1') = (a,v1')
  v' = p1'
  p1'{m=p2'} = v'
  v' = p2'
  (v',p2') = (v2',v2')
  p1' = p1'{m=p2'}
  a = a @{@i1'=p1'}
\end{verbatim}
with the putback bindings immediately after the binding for the assignment.

\subsubsection{Translating Expressions with Side Effects}

C Expressions with side effects are assignments and application of increment/decrement operators. The lvalue subexpression is always 
translated as described in the previous section. The cases differ in how the value variable \code{v<k>'} for the new value is 
determined.

For an assignment expression there are two subexpressions, the subexpression \code{e1} for the lvalue and the subexpression \code{e2}
for the rhs. Let \code{v<n>'} be the value variable bound in the translation of \code{e1} and \code{v<k>'} be that for \code{e2}.
The binding list for the assignment expression is constructed by appending the list for \code{e1} after that for \code{e2}.
Then an additional binding is appended which is
\begin{verbatim}
  v<n>' = v<k>'
\end{verbatim}
for a plain assignment \code{e1 = e2} and has the form
\begin{verbatim}
  v<n>' = v<n>' + v<k>'
\end{verbatim}
for an assignment with an operator, such as \code{e1 += e2}. After that the binding for the lvalue modification
\begin{verbatim}
  (v<n>',v) = (v<n>',v<n>')
\end{verbatim}
is appended to the main list, where \code{v} is the variable to be set by the lvalue, as described in the previous section.

For an increment/decrement operator such as \code{e++} there is only one subexpression \code{e}. Let \code{v<n>'} be the value
variable bound in the translation of \code{e}. An additional binding list for the literal \code{1} is constructed and
prepended to that for \code{e}. If it binds the value variable \code{v<k>'} the additinal binding appended to the main
list of \code{e} is
\begin{verbatim}
  v<n>' = v<n>' + v<k>'
\end{verbatim}
Then for a postfix increment/decrement operator, such as \code{e++} the binding for the lvalue modification is
\begin{verbatim}
  (v<n>',v) = (v,v<n>')
\end{verbatim}
and for a prefix increment/decrement operator, such as \code{++e} it is
\begin{verbatim}
  (v<n>',v) = (v<n>',v<n>')
\end{verbatim}

\subsubsection{Conditional Evaluation}

In C there are cases where subexpressions are only evaluated conditionally. These cases are the logical operators \code{\&\&} and \code{||}
where the evaluation of the second operand depends on the value of the first operand and the conditional operator where the evaluation
of the second and third operands depend on the value of the first operand. 

The side effects of a conditionally evaluated subexpression occur only if it is evaluated. In the translation Gencot uses a binding for 
all side effect targets to a common conditional expression which either returns the tuple of modified values or the tuple of the original 
side effect targets. 

The logical operators are conceptially rewritten as conditional expressions:
\begin{verbatim}
  e1 && e2 -> e1 ? e2 : False
  e1 || e2 -> e1 ? True : e2
\end{verbatim}

A conditional expression \code{e0 ? e1 : e2} is translated to a binding lists as follows. First the three subexpressions are translated
to binding lists by \code{bindExpr}. Then the lists for \code{e2} and \code{e3} are combined by \code{cmbBinds} to single bindings
\code{(v<m>',x1..) = expr1} and \code{(v<k>',y1..) = expr2}. Let \code{v<n>'} be the value variable bound in the translation
of \code{e0}. Let \code{z1..} be the union of the side effect targets \code{x1..}, and \code{y1..} in some order. The binding list
of the translated expression is the list of \code{e0} to which the binding
\begin{verbatim}
  (v<n>',z1..) = 
  if v<n>' 
  then let (v<m>',x1..) = expr1 in (v<m>',z1..)
  else let (v<k>',y1..) = expr2 in (v<k>',z1..)
\end{verbatim}
is appended. According to the type of \code{v<n>'} the condition in the conditional expression is adjusted in later stages.

In most realistic cases the conditionally evaluated subexpressions have no side effects. Then it is irrelevant whether they are 
evaluated or not. Gencot tests for these cases and provides a simpler translation if one or both have no side effects (i.e. the set 
of side effect targets is empty). For such a subexpression
its binding list is not combined by \code{cmbBinds}, instead its list is appended to the list of \code{e0} and the \code{let}
expression in the corresponding condition branch is replaced by the tuple \code{(v<m>',z1..)} or \code{(v<k>',z1..)}, respectively.

As an example, the expression \code{x \&\& (v = i)} is translated to
\begin{verbatim}
  v' = x
  v3' = False
  (v',v) = 
    if v' then 
      let (v1',v) = 
        let v2' = i 
        and (v1',v) = (v2',v2') 
        in (v1',v) 
      in (v1',v)
    else (v3',v)
\end{verbatim}
which will be simplified to \code{(v',v) = if x then (i/=0,i) else (False,v)} in later stages,
whereas the expression \code{(v = i) \&\& x} is translated to
\begin{verbatim}
  v1' = i
  (v',v) = (v1',v1')
  v2' = x
  v3' = False
  v' = 
    if v' then v2' else v3'
\end{verbatim}
which will be simplified to \code{(v = i) and (v' = if i/=0 then x else False)} in later stages.

\subsection{Additional Type Information}
\label{impl-ccode-type}

Although the translation described in Section~\ref{impl-ccode-cexpr} is mostly independent of any type
information, additional type information must be provided in the resulting Cogent AST to be used during
postprocessing (see Section~\ref{impl-ccode-gencog}). This is done by constructing a Cogent type for every
expression and pattern in the bindings of the Cogent AST and also for all subexpressions and subpatterns.
These types are inserted into the AST elements for expressions and patterns.

The type information is either taken from the C program or it is constructed according to the structure of an
expression or pattern from the types of sub components. Additionally, the item properties have to be taken
into account, which affect the type translation.

The analysis module of the language-c parser provides type information in two ways: either from the symbol map
using the monadic action \code{lookupObject} (see Section\ref{impl-ccode-trav}), where type information is
provided for all defined or declared identifiers, or from a monadic action \code{tExpr} which is used to
typecheck expressions during the analysis phase.

The action \code{tExpr} is defined by language-c as
\begin{verbatim}
tExpr :: [StmtCtx] -> ExprSide -> CExpr -> m Type
\end{verbatim}
where \code{m} is a \code{MonadTrav} (see Section\ref{impl-ccode-trav}). The \code{StmtCtx} is only used for
``statement expressions'' which are a GNU extension of C which is not supported by Gencot, therefore an arbitrary
value can be used for it. The \code{ExprSide} specifies whether the expression occurs as lvalue or rvalue and
only affects the admissible types. Here the value for rvalue is used since no restrictions apply if expressions
are used as rvalue. If the typecheck is successful, \code{tExpr} returns the C type of the checked expression
in the same form as used in the symbol map. Since Gencot assumes a correct C program the typecheck functionality
is irrelevant, only the resulting type is used.

\subsubsection{Expressions for Constants and Operator Application}

For constants and the results of operator applications the type information is always directly determined from the
C program. Item properties are not relevant, because constants and operators are no items, so no properties can be
specified for them. The type of operator results may depend on the type of the parameters, however, C operators
only exist for arithmetic types, which are not affected by item properties.

For constants language-c distinguishes in the C AST between Integer, Char, Float, and String constants. Float
constants are not supported by Gencot. Char constants in C have type \code{int}, which is mapped to Cogent type
\code{U32} (see Section~\ref{design-types-prim}). For String constants Cogent type \code{String} is used.
For Integer constants and operator applications the C type is determined using \code{tExpr}, then it is mapped to a
Cogent type as described in Section~\ref{design-types-prim} which results in one of the types \code{U8}, \code{U16},
\code{U32}, or \code{U64}.

In C there is no specific type for boolean values, they are represented by values of integer or pointer type with
\code{False} being represented by \code{0} and \code{True} by arbitrary other values. In Cogent there is type \code{Bool}
which is used for the result of equational, relational, and boolean operators and as expected type for boolean operators
and the condition in conditional expressions.

Since the expected types for operators and conditional expressions are not made explicit in the Cogent AST, type \code{Bool}
is only used for the result of equational, relational, and boolean operators. Cases of expected type \code{Bool}
are handled in postprocessing steps.

\subsubsection{Expressions for Variables}

For an identifier first the C type is determined using \code{tExpr} (which internally looks it up in the symbol map).
Since every identifier may denote an ``item'' with declared item properties on which its Cogent type may depend
(see Section~\ref{impl-itemprops}), next its associated item id must be determined, then both are combined to an
\code{ItemAssocType} (see Section~\ref{impl-itemprops-types}) and mapped to a Cogent type by \code{transType}
(see Section~\ref{impl-ccomps-main}).

This way, the type of a preprocessor constant is determined according to the dummy declaration generated for it. This
will always be \code{int} because the dummy declarations are generated in this form (see Section~\ref{impl-ccode-dummydecl}).
A special case is the constant \code{NULL}. It is detected by its name, then its type is set to \code{MayNull CVoidPtr}.
This is necessary to determine the correct type for a conditional expression, as described below, if one branch is
the \code{NULL} value.

The item id of an identifier depends on whether the identifier denotes a toplevel object or function, a parameter
of the surrounding function definition, or a local variable declared in the function body. However, this information is
no more available after the analysis by language-c. Looking the identifier up in the symbol map only allows to
distinguish toplevel definitions from local declarations, but neither parameters from local variables, nor different
local variables with the same name.

Therefore Gencot implements its own ``item id table'' for this purpose: it maintains a stack of local contexts
where each context maps identifiers to their item id. Only local identifiers in function definitions are managed here,
the function parameters are in the outermost context and at the end of a function definition all contexts are removed.
See Section~\ref{impl-ccode-trav} for the corresponding monadic actions.

\subsubsection{Component Access}

As described in Section~\ref{impl-ccode-cexpr}, accesses to container components (struct members, array elements, pointer
dereferences) are translated to pairs of \code{take} and \code{put} operations. In Cogent both operations modify the
container type, reflecting the fact that the component has been removed or inserted.

During translation Gencot does not apply these type modifications in the additional type information, the same type is always
associated to a container. The reason is that the additional type information is not exposed in the final Cogent program,
it is only used by Gencot for postprocessing. There it is not needed, because \code{take} and \code{put} operations are always
generated in pairs with no other \code{take} and \code{put} operations for the same container in between. During postprocessing
a \code{take} operation may be converted to a readonly component access (which does not
modify the container type) and a \code{put} operation may be removed, because the component has not been modified, in these
cases the type modifications would have to be reverted.

The Cogent type of the component can always be determined from the Cogent type of the container, because it is a syntactic
part of the container type.

In C, if the component is an (embedded) array, component access does not result in a copy of the array, instead, it results
in a pointer to the first array element. In Cogent this corresponds to a value of the boxed mapped array type. Since
embedded array components are always represented by the unboxed array type (see Section~\ref{design-types-array}), the
type of the component variable is adjusted to the boxed component type, whenever the component is of an unboxed array type.
This is not correct for Cogent \code{take} and \code{put} operations, they will be replaced during postprocessing usually
by \code{getref} and \code{modref} applications (see Section~\ref{design-operations-parts}).

The boxed component type is not wrapped as \code{MayNull} because the access of an array as component always yields a valid
pointer, if the pointer to the container is valid. It may only be readonly if the container has a readonly type. An array
which is embedded in a container of linear type is always itself linear. If a Read-Only property has been declared for the
component it will only affect the types of sub-components, because an embedded component is translated to have unboxed type.

\subsubsection{Function Pointers}

When function pointers are used to invoke the referenced function they must be dereferenced. This may be done explicitly,
using the indirection operator \code{*}, or implicitly by simply applying the function pointer to arguments. In Cogent
the dereferencing must always be explicit using the abstract function \code{fromFunPtr} (see
Section~\ref{design-operations-function}). For the corresponding expression the function type must be associated.

However, since Gencot currently represents function pointer types as abstract types with encoded type names (see
Section~\ref{design-types-pointer}), it is not possible to determine the function type from the function pointer
type in Cogent. As solution, Gencot first determines the C type from the function pointer expression using \code{tExpr},
then determines the C function type from it, and finally translates that to Cogent using \code{transType}.

For this translation Gencot needs the item id of the function pointer. However, the function pointer need not be specified
by an identifier in C, it may be an arbitrary expression like a struct member access or the result of a function application.
Therefore the item id is constructed according to the expression structure from the item id of a subexpression which is
an identifier (and which must always be present for a function pointer expression).

When Gencot is modified to use structured Cogent types for function pointers this approach is not needed anymore, then
the Cogent function type can be directly constructed from the Cogent function pointer type.

\subsubsection{Function Application}

In a function application the Cogent type of the function is determined by translating its C type using \code{tExpr} and
\code{transType}. If the function is specified by a function pointer the function type is determined as above, otherwise
the function is specified by its name, so that the item id can be determined immediately. Since all relevant item properties
are respected by the translation, the Cogent type includes all additional arguments (for Global-State and Heap-Use properties)
and all additional result components (for Global-State, Heap-Use, and Add-Result properties).

The type of the function application expression in Cogent is simply taken from the function type. The type of the function
argument (which is a tuple type of the argument types or a single argument type) is instead constructed from the types
of the actual argument expressions. This may result in type differences between the actual argument type and the formal
argument type specified as part of the function type. These differences may origin from similar differences in the C program,
which are resolved in C by automatic type conversion, or they may origin from item properties which are applied to the
arguments and/or the function in different ways. These type differences are resolved by Gencot in postprocessing stages.

\subsubsection{Conditional Expressions}

A conditional C expression is translated to a conditional expression in Cogent. The type of the conditional expression
must be the same as the type for both branches. However, the branch types may differ, due to differences in the C program
or to differences in item property applications.

The C type of the conditional expression includes the resolved differences in C, but does not resolve the differences
caused by item properties, therefore it cannot be used to determine the Cogent type of the conditional expression. Instead,
it is constructed from the Cogent types of the branches. This is based on the fact that type differences caused by item
property application are always resolved to one of both types in a deterministic manner. For example, a readonly type and
a linear type are always resolved to the readonly type, because a value of linear type can be converted to readonly by
banging it, but not vice versa. This makes it possible to pre-calculate during translation the type which will later result
from postprocessing the type differences for both branches. This type is used for the conditional expression.

\subsubsection{Patterns}

The patterns used in the generated bindings to bind expression results always consist of single variables, \code{take}
patterns, or (flat) tuples of these. For variables which result from translating a C identifier, the type is determined
as described above. For component variables the type is determined by the component type, which is determined by the
container type, as described above. For value variables the associated type is always the type of the expression bound
to it. Since value variables are reused, their associated type may change as soon as they are re-bound to another expression.
For a \code{take} pattern the type is the same as the container type, it is not modified to a ``taken'' type, as described
above.

The type of a tuple pattern is simply constructed as the tuple type of the types of the sub patterns.

\subsection{Translating C Statements}
\label{impl-ccode-cstats}

Like C expressions, C statements are mainly translated to Cogent bindings.

\subsubsection{General Translation of C Statements}

The translation of C statements differs from that of C expressions in two major ways. A C statement has no result 
value, therefore its translation never binds a value variable. But a C statement may cause jumps, these are translated
to conditional evaluation with the help of an additional ``control variable'' \code{c} as described in 
Section~\ref{design-cstats-stat}.

However, the concept described there is modified with respect to the control variable and the return value. Instead of using type \code{(Bool, 
Bool, Option T)} for the control variable the implementation uses an integer type and encodes nonlocal jumps by the 
values \code{3} (\code{return}), \code{2} (\code{break}), \code{1} (\code{continue}), and \code{0} (no jump). In case 
of a \code{return} jump the third component only represents the fact that a jump has been caused. The return value is represented 
separately by binding a value of type \code{T} to a special ``result variable''. Gencot uses the name \code{r'} for the 
result variable, it is automatically distinct from the names of all other variables used in the translation. It is
normally treated like an additional side effect target.

The reason for this modification is as follows. If a value of the option type is maintained, code for the \code{None}-case
must be generated, although this case never occurs if the C program is syntactically correct. If the result type \code{T} 
is linear, the code for the \code{None}-case will always violate the Cogent type constraints, because it either uses
a default value (which does not exist for linear types) or it discards the value (which is not allowed). When using the 
result variable the \code{None}-case may correspond to the situation where the result variable occurs free in the function 
body. This would also be an error for the Cogent compiler, however, if the C program is syntactically correct all these
occurrences can be eliminated from the Cogent code. In its initial translation stage Gencot generates these free occurrences
of the result variable, they are eliminated in later stages.

Instead of using a tripel of boolean values Gencot encodes the possible nonlocal jumps in an integer value, since that is more
compact and simplifies the later stages.

Values of expressions which are syntactically a part of a statement can never be used in other statements. Therefore
all value variables can be reused in every statement. Gencot supports this by resetting the value variable counter \code{<n>}
whenever it starts translating a statement.

C Statements are always evaluated in a sequenced manner or conditionally. The value of the control variable is used exactly
once, immediately after evaluating the translated statement. Therefore a single control variable is sufficient for 
all statements. Gencot uses the name \code{c'} for the control variable, it is automatically distinct from the names of
all other variables used in the translation.

The approach described in Section~\ref{design-cstats-stat} always converts the bindings which result from expression 
translation to Cogent expressions before they are used as part of a translated statement. This means that taken
container components are put back locally in every translated expression. In later postprocessing steps Gencot may
try to reuse taken components over several expressions in a statement and even over several sequential statements.
To prepare for reusing taken components, Gencot never reuses component variables in different statements of the same
function body.

All this implies that a translated statement can always be represented by a single binding, no additional information
about a value variable and an lvalue variable is required, in contrast to translated expressions.

Gencot uses a common monadic action 
\begin{verbatim}
  bindStat :: CStat -> FTrav GenBnd
\end{verbatim}
to translate every statement to a binding of the form
\begin{verbatim}
  (c',v1..) = expr
\end{verbatim}
with side effect targets \code{v1..}. The expression \code{expr} covers the effect on the control variable and 
all side effects of the translated statement. The side effect targets may include the result variable \code{r'}.

If Gencot cannot translate a statement it translates it to a binding where the rhs is a dummy expression as described in 
Section~\ref{design-cstats-dummy}. The lhs contains the control variable and may still contain side effect targets, if 
Gencot detects that the statement modifies these C objects.

\subsubsection{Expression Statements and Null Statements}

An expression statement has the form \code{e;}. It is translated by translating \code{e} to an \code{ExprBinds} and
combining it by \code{cmbBinds} to a binding \code{(v<n>',v1..) = expr}. Then the translation of the expression statement
is the binding
\begin{verbatim}
  (c',v1..) = let (v<n>',v1..) = expr
  in (0,v1..)
\end{verbatim}
which discards the value \code{v<n>'} of \code{e}.

A null statement has the form of a single semicolon \code{;} and is translated to the
binding
\begin{verbatim}
  c' = 0
\end{verbatim}

\subsubsection{Jump Statements}

A jump statement is a \code{return} statement, \code{break} statement, \code{continue} statement, or \code{goto} statement.
Gencot does not translate \code{goto} statements.

For a \code{return} statement with an expression the expression is translated to an \code{ExprBinds} by \code{bindExpr} and
combined by \code{cmbBinds} to a binding \code{(v<n>',v1..) = expr}. Then the translation of the return statement
is the binding
\begin{verbatim}
  (c',r',v1..) = let (v<n>',v1..) = expr
  in (3, v<n>',v1..)
\end{verbatim}
which explicitly binds the result variable \code{r'} as additional side effect target. The type of \code{r'} is always
taken from the formal function result type. It may differ from the type of \code{v<n>'} due to automatically resolved
type differences in C or due to item property applications. Such type differences are resolved during postprocessing.

For a \code{return} statement without an expression only the control variable is bound, the statement is translated to the 
binding
\begin{verbatim}
  c' = 3
\end{verbatim}
This implies that for a C function with result type \code{void} the result variable will never be bound in
the Cogent code. The result value of the Cogent function will be generated in later stages.

A \code{break} statement is translated to the binding
\begin{verbatim}
  c' = 2
\end{verbatim}

A C \code{continue} statement is translated to the binding
\begin{verbatim}
  c' = 1
\end{verbatim}

\subsubsection{Local Declarations}

Local declarations are declarations which occur as an item in a compound statement. Gencot only translates local object declarations, 
it does not translate local type definitions and static assertions. 

A local object declaration consists of a sequence of declarators. Every declarator declares a single object identifier and may 
specify an initializer for the object's initial value. An initializer is either an expression or an initializer for an aggregate or
union type. Gencot translates every initializer in the same way as an expression to an \code{ExprBinds}.

A declarator is translated to a pair consisting of a variable name and a binding. The variable name is the declared identifier
mapped to a Cogent name, as described in Section~\ref{impl-ccode-names}. If the declarator has an initializer the binding
results from combining its \code{ExprBinds} by \code{cmbBinds}. Otherwise the binding \code{v' = defaultVal ()} is used.

A local object declaration is translated to the sequence of the translations of all declarators.

\subsubsection{Compound Statements}

Compound statements are blocks which contain a sequence of block items which are statements or (local) declarations. Block items 
are conceptionally grouped right-associatively. Thus a block item sequence is either empty, or a single block item
(at the end), or it is a block item followed by a block item sequence.

A declaration declares identifiers which have the rest of the block as their scope. Thus the scope is always the block item sequence
which begins with the declaration and ends at the end of the block. The declared object identifiers can occur as side
effect targets in their scope, but the side effects can only be observed in the scope and must not be propagated outside it.

A declaration may consist of several declarators. Every declarator declares a single identifier which has the following declarators
and the block after the declaration as its scope. Thus, conceptually, the declarators can be considered to be the block items instead
of the declarations. 

If a declarator has an initializer, the initializer is not part of the scope of the declared identifier. A declarator may redeclare 
an identifier which has been declared outside of the block associated with the declarator, in this case the identifier is shadowed
in the scope of the redeclared identifier. 

Gencot translates every block item sequence to a Cogent binding of the same form as that for a statement. It covers the effect to 
the control variable and it covers all side effects to variables not declared in the sequence. 

The translation of a compound statement is the translation of its block item sequence.

An empty block item sequence is translated like a sequence with a single null statement to the
binding
\begin{verbatim}
  c' = 0
\end{verbatim}

For a block item sequence consisting of a single statement the translation of the sequence is identical to that of the statement.

A block item sequence consisting of a statement \code{s} followed by a nonempty sequence \code{bis} is translated as follows. First
\code{s} and \code{bis} are translated 
to bindings \code{(c',x1..) = expr1} and \code{(c',y1..) = expr2}. Let \code{z1..} be the union of the side effect targets 
\code{x1..} and \code{y1..} in some order. The block item sequence is translated to the binding
\begin{verbatim}
  (c',z1..) = let (c',x1..) = expr1
  in if c' > 0
     then (c',z1..)
     else let (c',y1..) = expr2 in (c',z1..)
\end{verbatim}

A block item sequence consisting of a single declaration is translated by appending a null statement.

A block item sequence consisting of a declaration \code{d} followed by a nonempty sequence \code{bis} is translated by translating 
the declaration to a sequence of pairs of a variable and a binding. The sequence \code{bis} is translated to a binding. Then 
these parts are combined starting with the last pair and the binding.

As described above a pair consists of a variable \code{v} which corresponds to the declared identifier and a binding 
\code{(v<n>',v1..) = expr1} which corresponds to the initializer. It is combined with a binding \code{(c',y1..) = expr2} as follows. 
Let \code{u1..} be \code{y1..} without \code{v}. Let \code{z1..} be the union of \code{v1..} and \code{u1..}. Then the
combined binding is
\begin{verbatim}
  (c',z1..) = 
    let (v<n>',v1..) = expr1
    and (c',u1..) = 
      let v = v<n>'
      and (c',y1..) = expr2
      in (c',u1..)
    in (c',z1..)
\end{verbatim}
This translation also accounts for the case that \code{v} is a side effect target of its own initializer so that the side effect is
correctly applied to a shadowed instance of \code{v}.

\subsubsection{Function Bodies}

A C function body is always a compound statement. It is translated by \code{bindStat} to a 
binding of the form
\begin{verbatim}
  (c',v1..) = expr
\end{verbatim}

From this binding the Cogent expression
\begin{verbatim}
  let (c',v1..) = expr
  in <result expression>
\end{verbatim}
is constructed as body expression of the translated Cogent function. The \code{<result expression>} depends on the item properties 
Add-Result, Global-State, and Heap-Use.

If no additional result components are caused by the item properties, the \code{<result expression>} is
\begin{verbatim}
  ()
\end{verbatim}
if the C function result type is \code{void}, and
\begin{verbatim}
  r'
\end{verbatim}
otherwise.

If the item properties cause additional result components the \code{<result expression>} is
\begin{verbatim}
  (r', v1..)
\end{verbatim}
where the variables \code{v1..} correspond to the properties Add-Result, Global-State, and Heap-Use in that order.

The control variable \code{c'} is never used in the \code{<result expression>}, it may only be used in sub-statement.
Its binding in the function body will be removed during postprocessing.

\subsubsection{Selection Statements}

A selection statement is a conditional statement or a switch statement.

A conditional statement of the form \code{if (e) s1 else s2} is translated similar to a conditional expression.
First the subexpression \code{e} is translated to an \code{ExprBinds} and combined by \code{cmbBinds} to a binding
\code{(v<n>',v1..) = expr}. The substatements are translated to bindings \code{(c',x1..) = expr1} and \code{(c',y1..) = expr2}. 
Let \code{z1..} be the union of the side effect targets \code{v1..}, \code{x1..}, and \code{y1..} in some order. The conditional
statement is translated to the binding
\begin{verbatim}
  (c',z1..) = let (v<n>',v1..) = expr
  in if v<n>' 
     then let (c',x1..) = expr1 in (c',z1..)
     else let (c',y1..) = expr2 in (c',z1..)
\end{verbatim}

For a conditional statement of the form \code{if (e) s1} the expression \code{e} and statement \code{s1} are translated as
above. Let \code{z1..} be the union of the side effect targets \code{v1..} and \code{x1..} in some order. The conditional
statement is translated to the binding
\begin{verbatim}
  (c',z1..) = let (v<n>',v1..) = expr
  in if v<n>' 
     then let (c',x1..) = expr1 in (c',z1..)
     else let c' = 0 in (c',z1..)
\end{verbatim}

A switch statement of the form \code{switch (e) s} is only translated if it has the restricted form described in 
Section~\ref{design-cstats-stat}: The statement \code{s} must be a compound statement \code{\{s1 ... sn\}} where no \code{si}
is a declaration and all \code{case} and \code{default} statements associated with the \code {switch} statement occur among the 
\code{si}. 

The translation has the form described in Section~\ref{design-cstats-stat}, however, the C code is not rewritten but translated
directly. This is done by processing the body \code{s} in a specific way which handles the \code{case} and \code{default}
statements among the \code{si}. At all other positions \code{case} and \code{default} statements are translated to dummy expressions.
Declarations among the \code{si} are also translated to dummy expressions. Statements before the first \code{case} or \code{default}
statement in the \code{si} are silently omitted.

The value of \code{e} must be assigned to a specific ``switch variable''. Nested switch statements are translated encapsulated 
in subexpressions where the switch variable shadows that from all surrounding switch statements, therefore a single switch variable 
is sufficient for all statements. Gencot uses the name \code{s'} for the switch variable, it is automatically distinct from the names of
all other variables used in the translation. 

The case labels are in real programs mostly literals, however, syntactically they are 
expressions. In the Cogent code a case label may be used in several places, therefore Gencot evaluates them once at the beginning 
of the switch statement. This is possible because the case labels must be constant 
expressions which implies that they can be evaluated independent of their context. After evaluation Gencot immediately compares the result
to the value of the switch variable and binds the result to specific ``case variables''. For a default statement the case variable is
bound to \code{True}. Gencot uses the names \code{s1'}, ... for the 
case variables, which are automatically distinct from the names of all other variables used in the translation. Like the switch variable
they can be reused for nested switch statements where they shadow the case variables from surrounding switch statements.

Every \code{case} or \code{default} statement \code{sk} of the form \code{lbl: sk0} in the \code{si} is grouped together with all 
following statements \code{sk1 ... skmk} which are no \code{case} or \code{default} statement to the compound statement \code{\{sk0 sk1 ... skmk\}}.
Let \code{g1 ... gp} be the sequence of these compound statements and let \code{lbl1 ... lblp} be the corresponding labels in the \code{case}
or \code{default} statements. For each \code{case} statement let the label \code{lblk} be \code{case ck}, i.e., \code{ck} is the constant
used in it.

Every compound statement \code{gk} is translated to a binding \code{(c',x1..) = exprk} by applying \code{bindStat} to it. 
Then this binding is extended to a binding \code{bk} of the form
\begin{verbatim}
  (c',x1..) = 
    if condk
    then exprk
    else (0,x1..)
\end{verbatim}
which corresponds to the C statement \code{if (condk) then \{sk0 sk1 ... skmk\}}. The condition \code{condk} is determined as follows.
If there is no \code{default} statement before \code{sk} the condition is
\begin{verbatim}
  s1' || ... || s<k>'
\end{verbatim}
Otherwise the condition is
\begin{verbatim}
  not (s<k+1>' || ... || s<p>')
\end{verbatim}
For \code{k = p} this condition is equivalent to \code{True} and the binding \code{(c',x1..) = exprp} is used directly. Note that if
\code{sk} is the default statement the case variable \code{s<k>'} (which has been bound to \code{True}) is never used.

The resulting sequence of bindings \code{b1 ... bp} is combined to a binding \code{(c',x1..) = exprb} by processing it as described 
for a compound statement, as if the bindings resulted from translating statements which are the block items in the compound 
statement. The controlling expression \code{e} is translated to an \code{ExprBinds} and combined by \code{cmbBinds} to a binding
\code{(v<n>',v1..) = expr}. The case label expressions \code{e1}, ..., \code{ep} are translated to \code{ExprBinds} and combined by
\code{cmbBinds} to bindings \code{v<n>' = exprk} (there are no side effect targets because the \code{ei} are constant expressions). 
Let \code{z1..} be the union of the side effect 
targets \code{v1..} and \code{x1..} in some order. Then the translation of the \code{switch} statement is the binding
\begin{verbatim}
  (c',z1..) = let (s',v1..) = expr
    and (s1',...,s<p>') = (s' == expr1,...,s' == exprp)
    and (c',x1..) = exprb
    in (if c'=2 then 0 else c',z1..)
\end{verbatim}
where the new control value reflects that a switch statement consumes a \code{break} jump (represented as \code{2}) but passes a
\code{continue} or \code{return} jump to its context.

\subsubsection{Iteration Statements}

An iteration statement is a \code{for} loop or a \code{while} loop.

Gencot only translates specific \code{for} loops. These loops are translated using the abstract function \code{repeat} as described
in Section~\ref{design-cstats-stat}. A \code{for} loop is only translated for some cases where an upper limit for the number of 
iterations can be determined automatically from the loop structure.

In a \code{for} loop the initialization part can be a declaration or a subexpression. If it is a declaration, the \code{for} loop
is the scope of the declared variable(s).

The general translation of a loop \code{for (c1; e2; e3) s} with a clause \code{c1} which is either a declaration or an expression
and where \code{e2} has no side effects
is as follows. The statement \code{s} is translated to a binding \code{(c',x1..) = expr} by applying \code{bindStat} to it. The expression
\code{e3} is translated to a binding \code{(v<n>',v1..) = expr3} by applying \code{bindExpr} to it and combining the resulting
\code{ExprBinds} by \code{cmbBinds}. Conceptually, \code{e3} is appended as an expression statement to \code{s}, by combining
the two bindings to the binding \code{(c',z1..) = exprstep} defined by
\begin{verbatim}
  (c',y1..) = let (c',x1..) = expr
  in if c' > 1
     then (c',y1..)
     else let (v<n>',v1..) = expr3
          in (0,y1..)
\end{verbatim}
where \code{y1..} is the union of \code{v1..} and \code{x1..}. Note that the condition uses \code{c' > 1} (\code{break} or \code{return}) 
instead of \code{c' > 0} (\code{break}, \code{return}, or \code{continue}) to correctly translate the semantics of \code{continue} 
statements in the body. A \code{continue} statement causes the body to abort, but still executes \code{e3}, whereas \code{break} 
or \code{return} statements end the loop without executing \code{e3}.

The expression \code{e2} is translated to a binding \code{(v<n>',t1..) = expr2} by applying \code{bindExpr} to it and combining 
the resulting \code{ExprBinds} by \code{cmbBinds}. (Although for the general translation \code{e2} must not have side effects, there
may be side effect targets \code{t1..} created by the translation which are only removed in later stages.)
Then the binding \code{(c',y1..) = exprloop} is constructed defined by
\begin{verbatim}
  (c',y1..) =
  let (c',y1..) = repeat #{
    n = exprmax,
    stop = \#{acc = (c',y1..), obsv = (w1..)} 
           => let (v<n>',t1..) = expr2 in (c' > 1) || not v<n>',
    step = \#{acc = (_,y1..), obsv = (w1..)} 
           => exprstep
    acc = (0,y1..), obsv = (w1..)
    }
  in (if c'=2 then 0 else c',y1..)
\end{verbatim}
where \code{w1..} are all variables occurring free in \code{exprstep} or \code{expr2} which are not part of \code{y1..}, in some order.
The expression \code{exprmax} for the upper limit of number of iterations is constructed as described below.

Here the new control value is determined like for a switch statement, by consuming the effect of a \code{break} statement. Note that
\code{continue} statements are already handled in \code{exprstep} above, where in the \code{else} case the control
value is set to \code{0} which consumes the effect of a \code{continue} statement. As a consequence the control value returned by
\code{repeat} can never be \code{1} so that it is not necessary to handle this case here.

Finally, if \code{c1} is not empty its translation is prepended to the binding \code{(c',y1..) = exprloop} in the way as described 
above for a block item sequence. If \code{c1} is an expression it is translated to a binding \code{(v<n>',u1..) = expr1} by 
applying \code{bindExpr} to it and 
combining the resulting \code{ExprBinds} by \code{cmbBinds}. Then the translation of the \code{for} statement is the binding
\begin{verbatim}
  (c',z1..) = 
  let (v<n>',u1..) = expr1
  and (c',y1..) = exprloop in (c',z1..)
\end{verbatim}
where \code{z1..} is the union of \code{u1..} and \code{y1} in some order. This corresponds to a simplified sequence of the two 
bindings exploiting the fact that the first results from an expression and can therefore not contain a jump.

If \code{c1} is a declaration it is translated to a sequence of pairs of a variable and a binding. Then this sequence is combined
with the binding \code{(c',y1..) = exprloop} beginning with the last pair, as described above for a declaration in a block item
sequence.

Gencot translates a loop \code{for (c1; e2; e3) s} in this way only if it can construct an expression \code{exprmax} for the upper limit of
number of iterations. For this, the loop must have the following properties:
\begin{itemize}
\item The expression \code{e2} must be a relation \code{v rel evl} where \code{v} is a variable not occurring free in \code{evl}
and \code{rel} is one of the relation operators \code{<}, \code{<=}, \code{>}, \code{>=}, \code{!=}, or \code{e2} must be a 
conjunction which contains such a relation. The body statement \code{s} must not modify \code{v} or \code{evl} and the expression 
\code{e3} may only modify \code{v} but not \code{evl}.
\item The expression \code{e3} must be an assignment expression for the same variable \code{v} or it must be a sequence of 
comma expressions which contains exactly one such assignment.
\item If \code{rel} is \code{<} or \code{<=} the assignment in \code{e3} must have one of the forms \code{v++}, \code{v+=stp},
\code{v=v+stp}, or \code{v=stp+v} where \code{stp} is an integer literal. In this case let \code{emax} be the expression \code{evl},
if \code{rel} is \code{<=} let \code{emax} be \code{evl+1}.
\item If \code{rel} is \code{>} or \code{>=} the assignment in \code{e3} must have one of the forms \code{v-{}-}, \code{v-=stp},
or \code{v=v-stp} where \code{stp} is an integer literal. The clause \code{c1} must be an assignment expression of the form 
\code{v=ini} or a sequence of comma expressions which contains such an assignment, or it must be a declaration with a declarator 
for the variable \code{v} and initialization expression \code{ini}. In this case let \code{emax} be the expression \code{ini},
if \code{rel} is \code{>=} let \code{emax} be \code{ini+1}.
\item If \code{rel} is \code{!=} the expression \code{evl} must be an integer literal and the clause \code{c1} must be an 
assignment expression of the form \code{v=ini} or a sequence of comma expressions which contains such an assignment, or it 
must be a declaration with a declarator for the variable \code{v} and initialization expression \code{ini}. In both cases 
\code{ini} must be an integer literal. If \code{ini} is lower than \code{evl} the assignment in \code{e3} must have one of 
the forms \code{v++}, \code{v+=1}, \code{v=v+1}, or \code{v=1+v}, then let \code{emax} be the expression \code{evl}. If \code{ini}
is greater than \code{evl} the assignment in \code{e3} must have one of the forms \code{v-{}-}, \code{v-=1}, or \code{v=v-1}, 
then let \code{emax} be the expression \code{ini}.
\end{itemize}

If the loop satisfies these properties the resulting C expression \code{emax} is translated to a binding \code{(v<n>',v1..) = expr} 
by applying \code{bindExpr} to it and combining the resulting \code{ExprBinds} by \code{cmbBinds}. Then the expression
\code{exprmax} is
\begin{verbatim}
  let (v<n>',v1..) = expr in v<n>'
\end{verbatim}
Note that side effect targets \code{v1..} could only occur if \code{emax} is \code{ini}. In this case the side effects are already
handled by the translation of the loop and can be ignored here.

The motivation for this approach is as follows. To determine an upper limit for the number of iterations a ``counting'' variable
\code{v} must be present. In \code{e2} it must be compared to a value \code{evl} which is constant for all iterations, therefore neither 
\code{v} nor a variable modified by the body may occur free in it. To safely determine the counting direction, \code{stp} must 
be a literal, otherwise its evaluation could result in a negative number which would reverse the counting direction. Also,
\code{v} must only be modified by \code{e3} and not by the body \code{s}.

If the variable counts up and the comparison in \code{e2} uses \code{<} or \code{<=} the comparison value \code{evl} yields 
an upper limit for the number of iterations, independent of the step size and the initial value of \code{v}. Therefore \code{c1}
may even be omitted. If the variable counts down and the comparison in \code{e2} uses \code{>} or \code{>=} the initial value 
\code{ini} yields an upper limit for the number of iterations, independent of the step size and the comparison value \code{evl}.

If the comparison uses relation \code{!=} the situation is similar, however \code{v} must be counted in steps of 1 to safely
hit the comparison value and it may not wrap around zero during the iterations so that the upper limit is valid.

To decide the first property the side effects of the body statement \code{s} must be known. However, the side effect targets
\code{x1..} which result from translating \code{s} are in general neither correct nor complete. Due to translating struct and array 
accesses using \code{take} and \code{put} operations all structs and arrays where a member or element is accessed occur as side
effect targets. Read-only accesses are only detected and removed in later stages. It may also be the case that \code{s} modifies 
only a part of a struct and another part is accessed in the comparison value \code{evl}.

To check whether a counting variable \code{v} is modified in the body \code{s} Gencot checks whether \code{v} occurs on the lhs
of an assignment in \code{s}. The only way how \code{v} can be modified in \code{s} without being detected in this way is if it
is modified through a pointer retrieved with
the help of the address operator \code{\&} (either in \code{s} or before the loop) which must be handled manually anyways.

To check whether \code{s} or \code{e3} can modify the comparison value \code{evl} Gencot checks whether any non-literal operand 
occurring in \code{evl} occurs on the lhs of an assignment in \code{s} or \code{e3}. In particular, if a struct member occurs 
in \code{evl}, assignments to other members of the same struct in \code{s} or \code{e3} will not prevent the translation of the loop.

The variables \code{w1..} which occur free in \code{exprstep} or \code{expr2} can either be determined from the C source (variables
free in \code{e2}, \code{e3}, or \code{s}) or from the translated Cogent source. Since Cogent does not support accessing defined
constants in a lambda expression these must be included. This is automatically done, because in Cogent constants are syntactically
referenced in the same way as variables. In C, as described in Section~\ref{impl-ccode-dummydecl}, Gencot generates dummy declarations
for preprocessor constants, so syntactically they are variables as well. Since all other information used here for translating 
\code{for} statements is taken from the C source, Gencot also determines the variables \code{w1..} from the C source. This implies
that they must be explicitly mapped to Cogent names. This mapping must be done at a place where all declarations in the context
of the loop and also a declaration which occurs as clause \code{c1} in the loop are visible, since the mapping depends on the 
linkage of the name which must be looked up in the symbol table.

As an example, the loop \code{for (int i=0;i<b;i++) a*=2;} is translated according to these rules to the (simplified) binding
\begin{verbatim}
  (c',i,a) = 
    let v' = 0
    and (c',a) = 
      let i = v'
      and (c',i,a) =
        let (c',i,a) = repeat #{
          n = b,
          stop = \#{acc = (c',i,a), obsv = b} 
           => let v' = i<b in (c' > 1) || not v',
          step = \#{acc = (_,i,a), obsv = b} 
           => let (c',a) = (0,2*a)
              in if c' > 1 
                 then (c',i,a)
                 else let (v',i) = (i,i+1)
                      in (0,i,a)
          acc = (0,i,a), obsv = b
          }
        in (if c' = 2 then 0 else c',i,a)
      in (c',a)
    in (c',i,a)
\end{verbatim}
which can be further simplified to
\begin{verbatim}
  (c',i,a) = 
  let (i,a) = repeat #{
    n = b,
    stop = \#{acc = (i,_), obsv = b} => not (i < b),
    step = \#{acc = (i,a)} => (i+1,2*a)
    acc = (0,a), obsv = b
    }
  in (0,i,a)
\end{verbatim}

\subsection{Generating Antiquoted C Code}
\label{impl-ccode-anti}

In addition to the Cogent code Gencot also generates antiquoted C code. This is implemented by generating 
a C AST and then prettyprinting it. For this the reimplemented language-c-quote AST described in 
Section~\ref{impl-ccode-expr} from module \code{Gencot.C.Ast} is used together with the reimplemented 
prettyprinter from module Gencot.C.Output.

\subsubsection{Embedding Cogent Code}

The antiquotation feature from language-c-quote is originally intended to embed Haskell code in a C source.
However, the Cogent compiler uses it to allow embedded Cogent code in some specific places.

Antiquoted parts are represented in the language-c-quote AST (and its reimplementation) by alternative syntactic
entities consisting of a single string containing the literate embedded code. The prettyprinter (and its 
reimplementation) adds the antiquotation marker such as \code{\$ty:} and wraps it in parentheses, if necessary.

To embed Cogent code which exists as a Cogent AST fragment, it must be prettyprinted with the Cogent prettyprinter
and the resulting string must be added as an antiquoted entity to the C AST. Usually, the embedded Cogent code 
is rather small, such as a single type. Therefore Gencot prettyprints it in a compact form without formatting or
indentation. For a Cogent AST fragment \code{<cogent>} this is done by
\begin{verbatim}
  (displayS $ renderCompact $ pretty <cogent>) ""
\end{verbatim}
where all three functions are used from module \code{Text.PrettyPrint.ANSI.Leijen}. Function \code{pretty} is 
the prettyprint function, \code{renderCompact} does the rendering in compact form, and \code{displayS} converts
the result to the standard Haskell type \code{ShowS} which is \code{String -> String} and must be applied to
the empty string to get the Cogent code rendered as a string.

This functionality is provided by function 
\begin{verbatim}
  showCogent :: Pretty a => a -> String
\end{verbatim}
defined in module \code{Gencot.Cogent.Output}.

\subsubsection{Origin Markers}

Since the reimplemented language-c-quote AST is used, every syntactic entity has an associated origin information.

Since the antiquoted C code is generated, normally no origin information is available and must be specified as
empty. However, if there is a corresponding entity in a processed C source file it may be useful to specify 
its origin and use it for inserting conditional preprocessor directives from the processed source file.

\subsubsection{Outputting the Generated Code}

The generated C AST is output using function \code{ppr} from module \code{Text.PrettyPrint.Mainland}. In case of 
a list of C AST entities the function \code{pprList} is used instead. The resulting
\code{Doc} must be rendered to a string with function \code{pretty} from the same module, then it can be 
output with the standard Haskell function \code{putStrLn}. 

As described in 
Section~\ref{impl-ccode-expr} a large value must be specified as the document width to compensate for the 
fast column increase caused by the hidden newlines. Therefore the standard rendering output actions defined
by \code{Text.PrettyPrint.Mainland} such as \code{putDoc} cannot be used since they always set the document
width to 80.

Gencot defines in \code{Gencot.C.Output} the function
\begin{verbatim}
  showTopLevels :: [Definition] -> String
  showTopLevels defs = pretty 2000 $ pprList defs
\end{verbatim}
which can be used to output a list \code{<antis>} of antiquoted C AST definitions by
\begin{verbatim}
  putStrLn $ showTopLevels <antis>
\end{verbatim}

\subsection{Traversing the C AST}
\label{impl-ccode-trav}

The package language-c uses a monad \code{MonadTrav} for traversing and analysing the C AST. The monad is defined in module
\code{Language.C.Analysis.TravMonad} and mainly provides the symbol table, error messages, and user state during the traversal.
The traversal itself is implemented by a recursive descent according to the C AST using a separate function
for analysing every syntactic construct.

The package language-c provides the function
\begin{verbatim}
  runTrav :: forall s a. s -> Trav s a -> Either [CError] (a, TravState s)
\end{verbatim}
for running a monadic action of type \code{Trav s a} where \code{s} is the type of the user state and \code{a} is
the type of the result. The function either returns a list of errors, or it returns the result together with the
modified monadic state of type \code{TravState s}.

When processing the semantic map resulting from the language-c analysis Gencot implements similar recursive 
descents using a processing function for every syntactic construct. For this it uses the same monad with a
different type of user state for two reasons.
\begin{itemize}
\item the definitions and declarations of the global identifiers are needed for accessing their types and for
mapping the identifiers to Cogent names,
\item additionally, the definitions and declarations of locally defined identifiers are needed in C function
bodies for the same purpose.
\end{itemize}

\subsubsection{Symbol Table}

The global definitions and declarations in the symbol table correspond to the semantics map which is the result
of the language-c analysis step. It is created from the symbol table after the initial traversal of the C AST. Although Gencot 
processes the content of the semantics map, it is not available as a whole in the processing functions. Instead
of passing the semantics map as an explicit parameter to all processing functions, Gencot uses monadic traversals
through the relevant parts of the semantics map, which implicitly make the symbol table available to all 
processing functions. This is achieved by reusing the symbol table after the analysis phase for the traversals
of the semantics map.

Additionally, when processing the C function bodies, the symbol table is used for managing the local declarations. 
This is possible because although the analysis phase translates global declarations and definitions to a 
semantic representation, it does not modify function bodies and returns them as the original C AST. Since
the information about local declarations is discarded at the end of its scope, the information is not 
present anymore in the symbol table after the analysis phase. Gencot uses the symbol table functionality
to rebuild this information during its own traversals.

In the monadic actions the symbol table can be accessed by actions defined in the modules
\code{Language.C.Analysis.TravMonad} and \code{Language.C.Analysis.DefTable}. An identifier can be
resolved using the actions
\begin{verbatim}
  lookupTypeDef :: Ident -> FTrav Type
  lookupObject :: Ident -> FTrav (Maybe IdentDecl)
\end{verbatim}
For resolving tag definitions the symbol table must be retrieved by
\begin{verbatim}
  getDefTable :: FTrav DefTable
\end{verbatim}
then the struct/union/enum reference can be resolved by
\begin{verbatim}
  lookupTag :: SUERef -> DefTable -> Maybe TagEntry
\end{verbatim}
Additionally, there are actions to enter and leave a scope and actions for inserting definitions.

\subsubsection{Error Messages}

The monad supports nonlocal jumps by throwing and catching errors, however, this feature is not used by Gencot.
Gencot is implemented so that it always can proceed if it encounters an erroneous situation, if the processed
C program is correct. Gencot only registers error messages in the monad and outputs the list of all error messages
at the end of execution.

An error can be recorded in the monad using the action
\begin{verbatim}
  recordError :: Language.C.Data.Error.Error e => e -> m ()
\end{verbatim}
The class \code{Error} covers all specific error types, it provides for every error a level (warning, error, fatal),
a source code position and a sequence of error message line strings. Predefined members of the class are the types
\code{UnsupportedFeature} with position information and \code{UserError} with error message only, both have level error.
Also predefined is the member type \code{CError} which is a wrapper for all other member types of \code{Error}. When
an error is displayed, the information is shown together with the error class name as short message.

The function \code{runTrav} distinguishes between errors of level error or fatal and errors of level warning. If there
is atleast one error of the former case it only returns the error list and no result or modified state. If there are
only errors of level warning, they are returned as part of the modified monadic state and may be retrieved using the
function
\begin{verbatim}
  travErrors :: TravState s -> [CError]
\end{verbatim}

Since Gencot always proceeds upon errors and produces a result, it uses only errors of level warning.

Gencot defines its own error types with names of the form \code{XError} with level warning and a constructor function
\begin{verbatim}
  xError :: (Pos a) => String -> a -> XError
\end{verbatim}
Class \code{Pos} includes all elements of the C AST, the second argument is used to determine the position.

\subsubsection{User State}

The user state is used by Gencot to provide additional information, depending on the purpose of the traversal.
A common case is to make the actual name of the processed file available during processing. In the \code{NodeInfo}
values in the AST it is always specified as \code{<stdin>} since the input is read from a pipe. All C processing 
filters take the name of the original C source file as an additional argument. It is added to the user state 
of traversal monads so that it can be used during traversal.

This is supported by defining in module \code{Gencot.Name} the class \code{FileNameTrav} as
\begin{verbatim}
  class (Monad m) => FileNameTrav m where
    getFileName :: m String
\end{verbatim}
so that the method \code{getFileName} can be used to retrieve the source file name from all traversal monads of 
this class. 

A second information is the name mapping configuration, as described in Section~\ref{impl-ccode-names}.
It is used by all filters and processors which translate to Cogent. It is supported by the class 
\begin{verbatim}
  class (FileNameTrav m) => MapNamesTrav m where
    matchPrefix :: String -> m (String, (String,String))
\end{verbatim}
The method \code{matchPrefix} returns for a name the first matching prefix together with the replacements. It 
applies the default matching rule, so it always returns a result. The class is defined as subclass of 
\code{FileNameTrav}, although the method does not use \code{getFileName}, because all clients of \code{matchPrefix}
also use \code{getFileName}.

Another information is the set of external type names directly used in the Cogent compilation unit. All other 
external type names are resolved during translation, as described in Section~\ref{design-modular}.

This is supported by defining in module \code{Gencot.Traversal} the class \code{TypeNamesTrav} as
\begin{verbatim}
  class (Monad m) => TypeNamesTrav m where
    stopResolvTypeName :: Ident -> m Bool
\end{verbatim}
so that the method \code{stopResolvTypeName} can be used to test a type name whether it should be resolved or not.
The list can be deactivated using a flag in the user state. This is useful, if only code is processed which belongs
to the Cogent compilation unit. Then all referenced external type names are directly used and no additional information about
the external type names is required, the list can be deactivated and be empty.

Other information needed during C AST traversal are:
\begin{itemize}
\item The item property map (see Section~\ref{impl-itemprops-internal}).
It is used for translating all types, as described in Section~\ref{design-types-itemprops}.
\item A list of tag definitions which are processed in advance as nested, as described in 
Section~\ref{impl-ccode-read}. This list is implemented as a list of elements of type \code{SUERef} which is used
by language-c to identify both tagged and untagged struct/union/enum types.
\item The current function definition when traversing a function body. This is not available in the symbol table.
\item A table for looking up the item ids of local variables and parameters, as described in Section~\ref{impl-ccode-type}.
\item Counters for generated Cogent variable names, as described in Section~\ref{impl-ccode-cexpr}.
\item A string with configuration settings for the Cogent translation.
\end{itemize}

The utilities for the monadic traversal of the semantics map are defined in module \code{Gencot.Traversal}. 
The main monadic type is defined as
\begin{verbatim}
  type FTrav = Trav (
     String, NamePrefixMap, [SUERef], ItemProperties,
     (Bool,[String]), Maybe IdentDecl, LocalItemIdTable,
     (Int,Int), GlobItemMap, String)
\end{verbatim}
where \code{String} is the type used for storing the original C source file name in the user state,
\code{NamePrefixMap} is the type for the name prefix map described in Section~\ref{impl-ccode-names},
\code{ItemProperties} is the type for storing the item property map, and \code{LocalItemIdTable} is
the type for maintaining the table of item ids for local identifiers. The third component is the list for
maintaining tag definitions processed as nested, the fifth component is the list of directly used external type names 
together with the flag for activating or deactivating the list, the sixth component is the function definition
whenever traversing a function body, the eighth component is a pair of variable counters, the nineth component
is the mapping from item ids to definitions for all global variables, collected by the uhandler as described
in Section~\ref{impl-ccode-read}, and the last component is the translation configuration string.

\code{FTrav} is an
instance of \code{FileNameTrav} and \code{TypeNamesTrav}. As execution function for the monadic actions the functions
\begin{verbatim}
  runFTrav :: DefTable -> (
     String, NamePrefixMap, ItemProperties, (Bool,[String]),
     GlobItemMap, String)
    -> FTrav a -> IO a
  runWithTable :: DefTable -> FTrav a -> IO a
\end{verbatim}
are defined. The first one takes the symbol table, the original C source file name, the name prefix map, 
the item property map, the list of directly used external type names, the item id map for global variables, and the
configuration string as arguments to initialize the state. The tag definition list and the item id table
are always initialized as empty,
the function definition is set to \code{Nothing}, the variable counters are set to 0. The second
function leaves also the other five components empty and deactivated. The functions are themselves
\code{IO} actions and print error messages generated during traversal to the standard error stream.

To maintain the list of tag definitions processed as nested two monadic actions are defined:
\begin{verbatim}
  markTagAsNested :: SUERef -> FTrav ()
  isMarkedAsNested :: SUERef -> FTrav Bool
\end{verbatim}

The item property map can be accessed by the monadic actions
\begin{verbatim}
  getItems :: (String -> [String] -> Bool) -> FTrav [String]
  getProperties :: String -> FTrav [String]
  hasProperty :: String -> String -> FTrav Bool
\end{verbatim}
where the last \code{String} argument is an item identifier.  The first action takes a predicate 
on the item id and the property list as argument and returns the list of item ids for which the declaration satisfies
the predicate. 
The second action returns the list of all properties declared 
for the item, the third action tests whether the property named as first argument is declared for the item.

The current function definition can be maintained by the monadic actions
\begin{verbatim}
  getFunDef :: FTrav (Maybe FunDef)
  setFunDef :: FunDef -> FTrav ()
  clrFunDef :: FTrav ()
\end{verbatim}

The table of item ids for local identifiers can be maintained by the monadic actions
\begin{verbatim}
  enterItemScope :: FTrav ()
  leaveItemScope :: FTrav ()
  registerItemId :: String -> String -> FTrav ()
  getItemId :: String -> FTrav String
\end{verbatim}
The first two actions must be invoked whenever a nested C block is entered or left, respectively.

The variable counters can be maintained by the monadic action
\begin{verbatim}
  resetVarCounters :: FTrav ()
  resetValCounter :: FTrav ()
  getValCounter :: FTrav Int
  getCmpCounter :: FTrav Int
\end{verbatim}
The first counter is used for value variables, the second for component variables (see Section~\ref{impl-ccode-cexpr}).
The first action resets both counters to 0, the second action resets only the value variable counter. 
The other two actions return the current counter value and increment the counter.

\subsection{Creating and Using the C Call Graph}
\label{impl-ccode-callgraph}

In some Gencot components we use the C call graph. This is the mapping from functions to the functions
invoked in their body. Here we describe the module \code{Gencot.Util.CallGraph} which provides
utility functions for creating and using the call graph.

The set of invoked functions is determined by traversing the bodies of all function definitions after the analysis
phase. The callback handler is not used since it is only invoked for declarations and definitions and does not help
for processing function invocations.

Invocations can be identified purely syntactically as C function call expressions. The invoked function is usually 
specified by an identifier, however, it can be specified as an arbitrary C expression. We only support the cases
where the invoked function is specified as an identifier for a function or function pointer, by a chain of 
member access operations starting at an identifier for an object of struct or union type, or by an array index
expression where the array is specified as an identifier or member access chain and the element type is a function
pointer type. All other invocation where the invoked function is specified in a different way are ignored and not 
added to the call graph.

The starting identifier can be locally declared, such as a parameter of the function where the invocation occurs. The 
declaration information of these identifiers would not be available after the traversal which builds the call graph.
To make the full information about the invoked functions available, Gencot inserts the declarations into the call graph 
instead of the identifiers. In the case of a member access chain it uses the struct or union type which has the 
invoked function pointer or the indexed function pointer array as its direct member. This struct or union type
must have a declared tag, otherwise the invocation is ignored and not inserted into the call graph.

The information about such an invocation in a function body is represented by the following type:
\begin{verbatim}
  data CGInvoke =
      IdentInvoke IdentDecl Int
    | MemberTypeInvoke CompType MemberDecl Int
\end{verbatim}
The additional integer value specifies the number of actual arguments in this invocation.
Note that in a function definition
the parameters are represented in the symbol table by \code{IdentDecl}s, not by \code{ParamDecl}s. In the case
of an array element invocation the actual index is ignored, all array elements are treated in a common way.

The call graph has the form of a set of globally described invocations. These are triples consisting of the definition
of the invoking function, the invocation, and a boolean value telling whether the identifier in the case of an
\code{IdentInvoke} is locally defined in the invoking function:
\begin{verbatim}
  type CallGraph = Set CGFunInvoke
  type CGFunInvoke = (FunDef, CGInvoke, Bool)
\end{verbatim}
The equality relation for values of type \code{CGFunInvoke} is based on the location of the contained declarations
in the source file. This is correct since after the initial traversal every identifier has a unique declaration associated.

To access the declarations of locally declared identifiers, the symbol table with local declarations
must be available while building the call graph. Therefore we traverse the function bodies with the help of
the \code{FTrav} monad and \code{runWithTable} as described in Section~\ref{impl-ccode-trav}.

The call graph is constructed by the monadic action
\begin{verbatim}
  getCallGraph :: [DeclEvent] -> FTrav CallGraph
\end{verbatim}
It processes all function definitions in its argument list and ignores all other \code{DeclEvent}s.

The function 
\begin{verbatim}
  getIdentInvokes :: CallGraph -> Set LCA.IdentDecl
\end{verbatim}
returns the set of all invoked functions which are specified directly as an identifier. In particular, they include
all invoked functions which are no function pointers.

The declaration of an invoked function also tells 
whether the function or object is defined or only declared. Note that the traversal for collecting invocations is a ``second 
pass'' through the C source after the analysis phase of language-c. During analysis language-c replaces
declarations in the symbol table whenever it finds the corresponding definition.

To use the call graph the \code{CallGraph} module defines a traversal monad \code{CTrav} 
with the call graph in the user state. The corresponding execution function is
\begin{verbatim}
  runCTrav :: CallGraph -> DefTable -> (String,(Bool,[String])) -> CTrav a -> IO a
\end{verbatim}
The monadic action to access the call graph is
\begin{verbatim}
  lookupCallGraph :: Ident -> CTrav CallGraph
\end{verbatim}
It takes the identifier of an invoking function as argument and returns the part of the call graph for this function,
consisting of all invocations in its body.

The monad \code{CTrav} is an instance of classes \code{FileNameTrav} and \code{TypeNamesTrav}, so the own source file 
name can be accessed by \code{getFileName} and external type names can be tested for being directly used by 
\code{stopResolvTypeName} (see Section~\ref{impl-ccode-trav}). The corresponding information is passed as third argument
to \code{runCTrav}.
