The Cogent code generated for C expressions and statements in the first translation phase as described in 
Section~\ref{impl-ccode-cstats} is in general neither correct nor efficient. Therefore it must be improved, 
which is done by postprocessing. The postprocessing is done directly in the Cogent AST. 

This approach taken by Gencot has several advantages over generating the Cogent code in a single phase.
First, the actual translation step ist rather simple and straightforward and even needs not take the C types
into account. Second, the postprocessing is done on a restricted subset of a purely functional language where 
there is no difference between statements and expressions, so it tends to be simpler. Third, it can be separated
into arbitrary many different processing steps which can be freely combined, since they all process the same
data structures (the Cogent AST). The drawback is that the code generation is not very efficient, because it
first builds a quite voluminous code which is then simplified by the postprocessing. However, the quality 
of the resulting code has been considered more important than the performance of the Gencot translation.

In the following sections the postprocessing steps are described independently of each other and the last
section describes how they are combined. Every postprocessing step corresponds to a transformation from
a Cogent expression to a Cogent expression and is implemented by a Haskell function of the form
\begin{verbatim}
  Xproc :: GenExpr -> GenExpr
\end{verbatim}
Note that no monadic actions are used, all information required for the processing must already be present in the 
expressions.

Postprocessing is applied to all expressions which occur in the generated Cogent program. These are function 
body expressions, the expressions in constant definitions, and the expressions in array type size specifications.

\subsection{Evaluating Constant Expressions}
\label{impl-post-const}

In several cases the original translation phase or postprocessing steps result in constant expressions built
from predefined operators. Such expressions can be statically evaluated and the resulting constant then may
enable other postprocessing steps. Therefore a constant expression evaluation is defined as auxiliary 
function for other postprocessing steps. It is implemented by the function
\begin{verbatim}
  evalproc :: GenExpr -> GenExpr
\end{verbatim}
defined in module \code{Gencot.Cogent.Simplify}.

The \code{evalproc} step is not applied on its own to arbitrary expressions. The reason is that a constant
expression may be intentionally present in the C program to show how a value is calculated. In that case the 
translation should also result in a constant expression in Cogent. Only if the evaluation is useful for other 
postprocessing steps it is applied.

The \code{evalproc} step only processes operator expressions. For them it recurses into the arguments. If all arguments
are constants it evaluates the operator and replaces the expression by the resulting constant. All other forms
of expressions are left unmodified, in particular, \code{evalproc} does not recurse into subexpressions which are
not operator applications.

\subsection{Simplifying Operator Application}
\label{impl-post-op}

If an expression cannot be completely evaluated statically, there are cases where it can be simplified.
The following cases are implemented by Gencot postprocessing.

If the first argument of a boolean operation evaluates to a constant the operation can be simplified according 
to the rules
\begin{verbatim}
  True  || e --> True
  False || e --> e
  True  && e --> e
  False && e --> False
\end{verbatim}
Currently only the first argument is treated this way, because only that case occurs in actual examples of translation
and postprocessing, mainly for the translation of \code{switch} statements.

Simplifying operator expressions using these rules is implemented by the function
\begin{verbatim}
  opproc :: GenExpr -> GenExpr
\end{verbatim}
defined in module \code{Gencot.Cogent.Simplify}.

\subsection{Simplifying \code{let}-Expressions}
\label{impl-post-let}

One of the simplest and most straightforward postprocessing steps is substitution of bound variables by the
expression bound to them. In Cogent variables can be bound by \code{let} expressions and by \code{match} and \code{lambda}
expressions. Variables bound in \code{match} and \code{lambda} expressions can usually only be substituted in special cases, 
therefore this processing step only substitutes variables bound in \code{let} expressions. 

The basic transformation is for an expression
\begin{verbatim}
  let v = expr1 in expr2
\end{verbatim}
to replace it by \code{expr2} where every free occurrence of \code{v} is substituted by \code{expr1}. This is only 
possible if after the substitution all free variables in \code{expr1} are still free in the resulting expression, i.e., 
they are not ``drawn under a binding'' in \code{expr2}. This could be avoided by consistent renaming of variables bound in 
\code{expr2}. Gencot never renames variables and does not substitute in this case.

This scheme can directly be extended to expressions of the form \code{let v1 = e1 and ... vn = en in e} using the
equivalence to an expression of the form \code{let v1 = e1 in let ... in let vn = en in e}.

As of February 2022, Cogent does not support closures for lambda expression. This means that a lambda expression must not
contain free variables, therefore lambda expressions in \code{expr2} are never inspected for substituting.

In a Cogent \code{let} expression instead of a variable \code{v} an (irrefutable) pattern \code{p} can be used:
\begin{verbatim}
  let p = expr1 in expr2
\end{verbatim}
An irrefutable pattern
is a variable or wildcard or it is a pattern for a tuple, record, array or the unit value were the components are again
irrefutable patterns. In other words, it is a complex structure of variables which is bound to an expression \code{expr1}
of a type for which the values have a corresponding structure. Every variable may occur only once in a pattern.

Currently, the translation phase only creates bindings with patterns which are either a single variable, or a flat tuple pattern where
all components are variables or wildcards, or a take pattern where all sub patterns are variables. The postprocessing does not 
introduce more complex patterns. However, to make the code more robust, these restrictions are not assumed for binding processing,
the processing is always implemented to work for arbitrary patterns.

If the pattern occurs as a whole in \code{expr2} it can be
substituted by \code{expr1} as described above. If only parts of the pattern occur (such as a single variable) it depends
on the structure of \code{expr1} whether such a part can be substituted. Gencot tries to substitute as much parts as possible 
and only retains those parts of the pattern for which a substitution is not possible.

If the substitution is successful the \code{let} expression is replaced by \code{expr2} which may again be a \code{let}
expression or any other kind of expression. Therefore the simplification may reduce the number of \code{let} expressions
and may replace a \code{let} expression by an expression of another kind.

Substitution of bound variables may lead to exponentially larger code, which must be avoided. Gencot uses an expression metrics
which roughly measures the size of the printed expression in the Cogent surface syntax. A binding is only substituted if the 
resulting expression is not much larger than the original \code{let} expression.

Simplifying a \code{let} expression by substitution can reduce the variables which occur free in it. This is the case if no
parts of the pattern \code{p} occur free in \code{expr2}, then \code{expr1} is removed and all variables which only occur free
in \code{expr1} are removed with it.

Simplifying \code{let} expressions is implemented by the function
\begin{verbatim}
  letproc :: GenExpr -> GenExpr
\end{verbatim}
defined in module \code{Gencot.Cogent.Simplify}.

\subsubsection{Processing Subexpressions}

When an expression \code{let p = expr1 in expr2} is simplified, first the subexpressions \code{expr1} and \code{expr2} are
simplified by processing all contained \code{let} expressions. Simplifying \code{expr1} has the following advantages for the 
substitution:
\begin{itemize}
\item The resulting expression usually is smaller. Then its substitution into \code{expr2} leads to a lower increase of
size and may be allowed whereas substitution of the original \code{expr1} would not be accepted.
\item Simplifying may reduce the free variables so that it may be possible to substitute it in more places than
the original expression without drawing free variables under a binding.
\item If \code{expr1} is again a \code{let} expression the pattern can only be substituted as a whole. After simplification 
it may have a form which corresponds more with the pattern so that also parts of the pattern can be substituted.
\end{itemize}
Simplifying \code{expr2} has the following advantages for the substitution:
\begin{itemize}
\item Simplifying may reduce the free variables so that there are fewer places for substituting the pattern
or parts of it. This may allow substitutions of patterns which where not possible in the original \code{expr2}.
It may also allow substitutions which would have lead to a too large growth of the original \code{expr2}.
\end{itemize}

Since an expression \code{let p1 = expr1 and p2 = expr2 in expr3} is equivalent to \code{let p1 = expr1 in (let p2 = expr2
in expr3)} this means that a sequence of bindings connected by \code{and} in a \code{let} expression is processed
from its end backwards.

\subsubsection{Pattern Substitution}

If (after its simplification) \code{expr1} has the same structure as the pattern \code{p} the binding could be split and 
the parts could be substituted independently. This would correspond to the transformation of the binding \code{p = expr1}
to the sequence 
\begin{verbatim}
  p1 = expr11 and ... pn = expr1n
\end{verbatim}
where the \code{pi} are the subpatterns of \code{p} and the \code{expr1i} are the corresponding subexpressions of \code{expr1}.
Note that the variables in the \code{pi} are pairwise disjunct since every variable may occur only once in \code{p}.
Then the sequence could be processed from its end, as described above.

However, the transformation is only correct, if no variable in \code{pi} occurs free in an expression \code{expr1j} with 
\code{j > i}, otherwise the transformation would draw it under the binding \code{pi = expr1i}. It could be tried to sort
the bindings to minimize this problem but in general it cannot be avoided. Additionally, there may be cases where \code{expr1}
even after its simplification has no structure corresponding with that of \code{p}, which also prevents the transformation.

For this reason, instead of transforming the binding and substituting it sequentially, Gencot deconstructs the pattern while
searching for matches. Whenever it searches the binding \code{p = expr1} in an expression (starting with \code{expr2}) 
it determines the variables occurring free in the expression and ``reduces'' the binding to these. Reducing a binding to
a set of variables is done by first replacing in \code{p} all variables which are not in the set by a wildcard (underscore) 
pattern. This is always possible. Then it is tried to remove as much wildcard parts from the binding, this is only possible if
the corresponding part can be removed from \code{expr1}. If \code{p} is a tuple pattern where some components are wildcards
they can be removed if \code{expr1} is a corresponding tuple expression. If \code{expr1} is an application of a function to
an argument the wildcard parts cannot be removed, since the tuple returned by the function is not available.

If no variable in the set occurs in the pattern all variables are replaced by wildcards and the binding is reduced to the 
empty binding, represented by the ``unit binding'' \code{() = ()}.

If after reducing it the binding is not empty, it is matched with the expression, which is successful if it has the same structure with the same
variables (which is only possible if the pattern contains no wildcards). If it matches the search stops, if not the binding 
is searched recursively in all subexpressions (by first reducing it to the subexpression). When the search reaches a single 
variable, the binding has been reduced to that variable. If the pattern consists of the same variable it matches there.

Otherwise the pattern is empty or it contains the variable together with other parts which means that it cannot be used to substitute the 
variable at that position in the expression. In this case at least the binding for that variable must be retained. Gencot 
determines all variables in \code{expr2} for which that is the case. Then it reduces the original binding \code{p = expr1}
to that set to determine the binding \code{p' = expr1'} which must be retained in the \code{let} expression. Only if no
such variable exists the binding can be completely removed from the \code{let} expression.

If \code{p} contains a \code{take} pattern for a record or array it can only match a \code{put} subexpression 
of exactly the same form in \code{expr2}. That is only present if the component is taken and put back without modifying it or the 
remaining record or array. In this case the \code{put} expression is replaced by the part of \code{expr1} corresponding to 
the \code{take} pattern.

Wildcards in a \code{take} pattern can only be removed if the corresponding part of \code{expr1} is a \code{put} expression. 
In the original translation phase Gencot always generates all put operations after all take operations in a sequence of bindings.
However, during postprocessing bindings may be rearranged, so that this case may occur.

Even if a part of the binding successfully matches in \code{expr2}, substitution may be prevented because it would draw a 
free variable in \code{expr1} under a binding. Such a binding may be the retained part of the original binding or it may 
be a binding in a \code{let} subexpression which has been retained during the simplification of \code{expr2}
or it may be a binding in a \code{match} expression which is not processed by the simplification. These cases are handled
by splitting the binding for which matches are searched whenever it is drawn under another binding in a (maximal) part allowed
to draw under the binding and a rest which must be retained. The rest is still searched under the binding to determine whether
the variables in it occur at all, if that is not the case it is not required in the expression and is not retained.

A binding is split according to a set of variables not to occur free by first determining all bound variables so that the 
corresponding part of the bound expression contains a free occurrence of a variable from the set. Then the binding is reduced
to this set and to its complement, yielding the binding to retain and the binding for substitution.

If \code{expr1} is a \code{let} or \code{if} expression or a match expression the binding cannot be reduced or split directly.
In these cases Gencot constructs the reduced or split binding by recursively reducing or splitting the subexpressions (the 
let-body, the if-branches, the match-alternatives).

The substitution and binding simplification is implemented in two phases. In the first phase the matches for the pattern are 
searched in \code{expr2}, resulting in the part to be retained and for every matching part the number of successful matches
The matching parts are actually substituted in \code{expr2} in the second phase. If the retained part is not empty it is 
prefixed to the result.

\subsubsection{Banged Variables}

A binding may have ``banged'' variables, i.e., be of the form
\begin{verbatim}
  p = expr1 !v1 ... !vn
\end{verbatim}
which makes the variables \code{v1,...,vn} readonly in \code{expr1}. Banged variables are introduced by readonly processing 
(see~\ref{impl-post-readonly}). Simplification of \code{let}-expressions may be executed after readonly processing, therefore it
must deal with banged variables.

In Cogent banged variables can only appear at specific places in the code: in a \code{let} binding, in a \code{match}-expression, 
and in the condition of an \code{if}-expression. Therefore it is in general not possible to substitute (a part of) the pattern \code{p}
at arbitrary occurrences in \code{expr2} by \code{expr1} together with the banged variables. Gencot never tries, it retains those
parts of the binding in which the banged variables occur free in \code{expr1}.

The same mechanism for splitting a binding used to prevent drawing variables under a binding is used for banged variables. Whenever
a binding is split, the banged variables are added to the set of variables not to occur free.

\subsubsection{Growth Restriction}

As size metrics for an expression the number of characters appearing in its surface representation is used. It could be determined
by actually prettyprinting the expression and measuring the size of the resulting string. However, it is assumed to be more
efficient to traverse the expression and calculate the size from the number of characters in the names and literals and in
the keywords, special characters and separating blanks needed for constructing composed expressions.

After the first phase the metrics of the \code{let} expression is calculated. Since for each matching part to be substituted it 
has been determined in the first phase how often it occurs in \code{expr2} the metrics for the simplified expression can be 
calculated and it is known how much each subpattern contributes to its size. If the size is larger than for the original 
expression and its growth exceeds a fixed limit factor additional binding parts are determined which are retained. 
Beginning with the binding part with the largest contribution, parts are retained until the growth is below the limit.

Instead of only taking its contribution to the size into account, binding parts could also be selected according to the kind of
variables they contain. 
Gencot uses different kinds of variables in its generated code (see Section~\ref{impl-ccode-cstats}): value variables, component and 
index variables, the control and result variables, and variables corresponding to C object names. These could be prioritized
as follows: first as many value 
variables are substituted as possible in a complete expression, then the control variables, then the component and index variables and
finally the C object names. In this way the most ``technical'' variables are substituted before the more ``semantical''.

The reference metrics is calculated for the expression after simplifying its subexpressions. This means that the growth limit factor
applies to every subexpression simplification step separately. This has two implications. First, a subexpression simplification
may strongly reduce the size of the subexpression and that may also reduce the size of the \code{let} expression, which becomes 
the reference for its own simplification. Thus it is not possible to tolerate a larger growth after strongly reducing the size for
subexpressions. Alternatively, the reference size could be measured before simplifying the subexpressions. In the code generated
by Gencot there are typically large nestings of \code{let} expressions with unnecessary ``chain bindings''. It is assumed that it
does not yield good results when these unnecessary large expressions are used as reference, therefore Gencot uses the first approach.

Second, in the worst case each simplification step grows the expression by the limit factor which still results in an overall exponential growth
relative to the number of subexpressions. Therefore the growth limit factor should not be much larger than 1. The effect of this
factor and a good selection for it must be determined by practical tests. Alternatively the factor could be specified as an input 
parameter for Gencot so that it can be selected specifically for every translated C program.

\subsection{Simplifying If-Expressions}
\label{impl-post-if}

The most straightforward simplification of a conditional expression is replacing it by one of the branches, if the condition can be
statically evaluated. Gencot tries this, by recursing into the condition and then using \code{evalproc} (see Section~\ref{impl-post-const})
for evaluating the condition, before it recurses into the branches. This avoids processing a branch which is removed afterwards. 
If the condition cannot be statically evaluated, both branches are processed recursively.

\subsubsection{Other Used Transformations}

Afterwards, the following additional simplification rules are applied, if possible.
\begin{itemize}
\item If both branches are the same expression, the conditional expression is replaced by this expression.
\item If both branches statically evaluate to a boolean constant, the conditional expression is replaced
by the condition or the negated condition according to the rules
\begin{verbatim}
  if c then True else False --> c
  if c then False else True --> not c
\end{verbatim}
\item The condition is substituted by \code{True} in the \code{then} branch and by \code{False} in the \code{else} branch. This 
may enable additional simplifications in subsequent iterations (see Section~\ref{impl-post-combine}).
\end{itemize}

The following rule is applied to operator expressions where the first argument is a conditional expression and the second argument
can be statically evaluated:
\begin{verbatim}
  (if c then e1 else e2) <op> e -->
  if c then e1 <op> e else e2 <op> e
\end{verbatim}
This transformation may enable the static evaluation of the resulting branches. 

All these rules have been selected, because they specifically apply to conditional expressions resulting from the Gencot translation
and postprocessing, in particular for the control variable.

Simplifying \code{if} expressions using these rules is implemented by the function
\begin{verbatim}
  ifproc :: GenExpr -> GenExpr
\end{verbatim}
defined in module \code{Gencot.Cogent.Simplify}.

\subsubsection{Unused Transformations}

Other rules would transform conditional expressions where one branch can be statically evaluated to a boolean value according to
\begin{verbatim}
  if c then True else e  --> c || e
  if c then False else e --> not c && e
  if c then e else True  --> not c || e
  if c then e else False --> c && e
\end{verbatim}
This is not used, because it removes boolean constants which may be useful for static evaluation after other processing steps.

Other rules for simplifying conditionals with boolean values are
\begin{verbatim}
  if c then e else not e --> c == e
  if c then not e else e --> c /= e
\end{verbatim}
These are not used because they turn conditional expressions into equations, which currently are not processed any further.

If a branch is again a conditional expression, the following transformation is possible:
\begin{verbatim}
  if c then (if c' then e1 else e2) else e -->
  if c' then (if c then e1 else e)
        else (if c then e2 else e)
\end{verbatim}
It is not used because it duplicates expression \code{e} and does not reduce the structure of conditional expressions,
so there is the danger of cyclic transformation.

Another rule would split conditional tuples into a tuple of conditionals according to
\begin{verbatim}
  if c then (t1,..,tn) else (e1,..,en) --> 
  (if c then t1 else e1, .., if c then tn else en)
\end{verbatim}
which would allow further simplification for all components with \code{ti = ei} and it could allow additional substitutions
by \code{letproc}, because the components can be substituted or omitted separately. However, if both are not applicable, it 
tends to enlarge the expression by copying the condition \code{c}. Therefore the effect on \code{letproc} has been implemented
there by the way how conditional expressions are split and the rule is not used here for \code{ifproc}.

The substitution of the condition in the branches could be generalized by substituting values for variables which can be
inferred from the condition, such as in
\begin{verbatim}
  if i == 0 then e1 else e2
\end{verbatim}
where it is possible to substitute \code{i} by \code{0} in \code{e1}. Even more general, the condition can be interpreted as
a set of equations for its free variables, if it can be solved for some of them they can be substituted by their solution
in the first branch. It has not yet been considered whether such substitutions would have an effect that would pay for the 
additional complexity.

If the condition is itself a conditional expression, it may be possible to derive substitutions, although the condition does
not occur as a whole in the branches. As an example, the following transformation could be applied:
\begin{verbatim}
  if (if c then x else y) 
     then (if c then (if x then e1 else e2) else e3) 
     else e4 
  -->
  if (if c then x else y) 
     then (if c then e1 else e3)
     else e4
\end{verbatim}
It has not yet been considered, whether such transformations would be useful for cases occurring during translations of C programs.

\subsection{Function Processing}
\label{impl-post-function}

After the translation to Cogent, functions may have additional parameters or additional result components and parameters may have
been rearranged. Additionally, the parameter and/or result types may be translated in different ways. Function definitions and
function calls must be adapted to these possible modifications. The translation described in Section~\ref{impl-ccode-cstats} 
translates all C functions exactly as they are structured in C, the adaptations are done by postprocessing.

Postprocessing for functions is implemented by the function
\begin{verbatim}
  funproc :: GenExpr -> GenExpr
\end{verbatim}
defined in module \code{Gencot.Cogent.Functions}.

Function postprocessing also applies to operators in C, which are translated to Cogent operators in some cases, and to predefined
Cogent functions in others.

\subsection{Readonly Processing}
\label{impl-post-readonly}

\subsection{Take/Put Processing}
\label{impl-post-takeput}

For struct and array accesses in C (\code{s.m}, \code{s->m}, \code{a[i]}) the translation described in Section~\ref{impl-ccode-cstats} 
creates pairs of take/put bindings of the form
\begin{verbatim}
  <v>{m=pk’} = vn’
  ...
  <v> = <v>{m=pk’}
\end{verbatim}
(for struct access) and
\begin{verbatim}
  (<v> @{@vl’=pk’},ik’) = (vn’,vl’)
  ...
  <v> = <v> @{@ik’=pk’}
\end{verbatim}
(for array access). Here, \code{<v>} is the variable used for the container (struct or array) and \code{pk'} is the component variable 
used to bind the component (member or element). If the container has been specified by an expression in C, \code{<v>} is the wildcard \code{\_}
and the put binding is omitted.

Postprocessing for \code{take} and \code{put} bindings is implemented by the function
\begin{verbatim}
  tpproc :: GenExpr -> GenExpr
\end{verbatim}
defined in module \code{Gencot.Cogent.Takeput}.

The take/put pairs are postprocessed in two major steps. In the first step single take or put bindings are eliminated, because the component
has nonlinear type. In the second step, some of the remaining take/put pairs are converted to applications of the \code{modify} operation
(see section~\ref{design-operations-modify}). The steps are implemented by the functions
\begin{verbatim}
  tpelimproc :: GenExpr -> GenExpr
  tpmodifproc :: GenExpr -> GenExpr
\end{verbatim}
defined in module \code{Gencot.Cogent.Takeput}.

\subsubsection{Banging \code{take} Bindings}

A component of nonlinear type can freely by copied from a container without the need for a \code{take} operation. The same holds, if the 
component has linear type, but is only used in readonly form. Then the container can be ``banged'' before the component access and a readonly
access can be used instead of a \code{take} operation.

As a preparation step all \code{take} bindings are banged for which that is possible, i.e. the container is banged in the binding by appending
\code{!vn'} to it:
\begin{verbatim}
  <v>{m=pk’} = vn’
  ->
  <v>{m=pk’} = vn’ !vn'

  (<v> @{@vl’=pk’},ik’) = (vn’,vl’)
  ->
  (<v> @{@vl’=pk’},ik’) = (vn’,vl’) !vn'
\end{verbatim}

Whether a \code{take} binding can be banged depends on the taken component \code{pk'}. If it has a declared nonlinear type (according to the C 
type and the item properties), the \code{take} binding can always be banged. Otherwise, if it has a linear type, it depends on how the 
component \code{pk'} is used, i.e. the free occurrences of the \code{pk'} bound in the \code{take} binding. First, it must be used in 
the corresponding \code{put} binding, i.e., it must not be rebound before. This means the component is not modified in the container, 
which would prevent making the container readonly. Second, all other free occurrencies of \code{pk'} must be in a bang specification, 
possibly as a container in a banged \code{take} binding. To evaluate that, all following \code{take} bindings must be processed 
recursively before. 

The only possible other uses of \code{pk'} are:
\begin{itemize}
\item Actual parameter of an invoked function. If the formal parameter has a readonly type, \code{pk'} must be banged before (see 
Section~\ref{impl-post-function}, otherwise it is used unbanged.
\item Assignment to a variable or container component, or return value of the surrounding function. That must be unbanged, 
otherwise it would escape the banged context.
\item Dereferencing it using \code{*} or \code{->} in C. This is translated like a component access to a take/put pair and is
handled by the recursive processing of the \code{take} bindings.
\item Comparison with another pointer in C. There it will always be banged by the comparison postprocessing described in 
Section~\ref{impl-post-function}.
\end{itemize}
Together, it is sufficient to check whether all free occurrencies of \code{pk'} have been explicitly banged by previous 
postprocessings or the recursive \code{take} processing.

The component variable \code{pk'} may also be used indirectly, by binding it to another variable. In that case the free 
occurrencies of that variable must be checked in the same way. Usually, however, such ``chain bindings'' should have been 
removed by the simplification of \code{let} expressions in~\ref{impl-post-let}.

The banging of \code{take} bindings is implemented by the function
\begin{verbatim}
  tpbangproc :: GenExpr -> GenExpr
\end{verbatim}
defined in module \code{Gencot.Cogent.Takeput}.

If a \code{take} binding is banged, the explicit bangings of the \code{pk'} are redundant. However, they are only removed after
\code{tpelimproc} because they allow to check locally whether the container in a \code{take} binding is readonly.

\subsubsection{Eliminating \code{put} Bindings}

A \code{put} binding can be completely removed, if the put value \code{pk'} has only been bound in the corresponding \code{take}
binding. In this case the taken component is put back unmodified, which is redundant. 

If the \code{take} binding has been banged, the component and the container are readonly and the container's type will not be 
changed by accessing the component. Moreover, the put would be illegal in Cogent, since it is applied to a readonly container,
so in this case the \code{put} binding must be removed.

If the \code{take} binding has not been banged, the \code{take} binding changes the type of the container to that where the component
has been taken. The \code{put} binding is usually required to change the type back to the untaken form. However, if it was not possible
to bang the \code{take} binding, there must be another use of component \code{pk'} in linear form. Therefore the \code{put} would
be illegal in Cogent because the linear component is used twice. Therefore in this case the \code{put} binding is removed as well.

It may be that there is another take/put pair for the same component later, where the taken component is not used at all, so that 
the \code{take} binding is eliminated as described below. Then the remaining \code{put} binding changes the type back. Note, that
all cases in C where a pointer component in a container is accessed once and then overwritten by an assignment before it is 
accessed again is translated to a corresponding sequence of take/put pairs. The postprocessing turns it into valid Cogent code
which respects the linear use of the pointers.

Since the elimination of \code{put} bindings depends on insecting the corresponding \code{take} binding, it must be done before 
eliminating \code{take} bindings.

\subsubsection{Eliminating \code{take} Bindings}

A \code{take} binding can be replaced by a normal binding, if the taken component is not linear. After executing \code{tpbangproc}
this can be detected by checking whether the \code{take} binding is banged. If that is the case, it can be replaced by a binding
which binds the container and the component separately. A banged \code{take} binding is replaced according to
\begin{verbatim}
  <v>{m=pk’} = vn’ !vn'
  ->
  (<v>,pk') = (vn',vn'.m) !vn'

  (<v> @{@vl’=pk’},ik’) = (vn’,vl’) !vn'
  ->
  (<v>,pk',ik') = (vn',getArr(vn',vl'),vl') !vn'
\end{verbatim}
In case of a struct the Cogent member access \code{vn'.m} is used, in case of an array the Gencot array operation \code{getArr(vn',vl')}
is used.

Note, that banging and elimination also works for \code{take} bindings where \code{<v>} is the wildcard \code{\_}. In this case the 
\code{vn'} is simply discarded which is no problem, since it has been banged. The unnecessary wildcard binding will be removed by
\code{let} simplification. Only if a wildcard \code{take} binding cannot be banged and thus not eliminated, it may result in illegal
Cogent code, because the remaining container may still be linear after taking \code{pk'}, but it is discarded.

After eliminating all \code{take} bindings where possible, the redundant bangings are removed: Whenever a binding is banged, 
the bangings of all free occurrences of the bound variables (and possible chain bindings) are removed. 

\subsubsection{Repeated Access of the Same Component}

If a \code{take} binding is followed by another \code{take} binding for the same container and the same component before the 
corresponding \code{put} binding, this may cause illegal code in Cogent, because a component is taken twice. If one or both 
\code{take} bindings can be eliminated as described above, there is no problem because the component is accessed in a readonly 
way which can be done arbitrarily often.

If both \code{take} bindings cannot be eliminated this means that the linear component is used in linear form in both cases
which results in an illegal double use in Cogent. Nevertheless the case is still postprocessed as follows.

Since every \code{take} binding uses a new component variable \code{pk'} the double uses are related to two different variables 
\code{pi'} and \code{pj'}. To make the double use more apparent and reduce the
number of \code{take} bindings, the second \code{take} is replaced by a rebinding of \code{pj'} to the value of \code{pi'}. Since 
the \code{pi'} may have been rebound between the first and the second \code{take} binding, this rebinding is inserted immediately
after the first \code{take}. Together, a sequence of two repeated \code{take} bindings which cannot be eliminated is processed 
according to
\begin{verbatim}
  <v>{m=pi’} = vn’
  ...
  <v>{m=pj'} = <v>
  ->
  <v>{m=pi’} = vn’
  pj' = pi'
  ...
\end{verbatim}
for a struct. Note that for a struct it is easy to detect that two \code{take} bindings access the same component, because the coponent
names must be the same. 

In case of an array the components are the same, if the same index value is used for access, this cannot be 
statically decided in general. The postprocessing uses a heuristics to test whether two index expressions evaluate to the same
value. First, \code{evalproc} is applied to both so that constant subexpressions are evaluated. Then, simple integer operator
expressions are matched, so that, e.g., the expressions \code{i+5} and \code{i+5} are detected as having the same value, 
if \code{i} is not rebound in between. That should cover simple typical cases of indexing the same elements in C.

Then the transformation for arrays is
\begin{verbatim}
  (<v> @{@vl’=pi’},ii’) = (vn’,vl’)
  ...
  (<v> @{@vm’=pj’},ij’) = (<v>,vm’)
  ->
  (<v> @{@vl’=pi’},ii’) = (vn’,vl’)
  (pj',ij') = (pi',ii')
  ...
\end{verbatim}
if the index expressions \code{vl'} and \code{vm'} can be shown to evaluate to the same value.

If a \code{put} binding is followed by a \code{take} binding for the same container and the same component, and both bindings cannot
be eliminated, they can be replaced by a single binding of the component variable used in the \code{take} binding to the value 
put in the \code{put} binding. Neither the container nor its type is modified by putting a value into a component of linear type and then
taking the component out again. The corresponding transformation is
\begin{verbatim}
  <v> = <v>{m=pi’}
  ...
  <v>{m=pj'} = <v>
  ->
  pj' = pi'
  ...
\end{verbatim}
for structs and
\begin{verbatim}
  <v> = <v> @{@ii’=pi’}
  ...
  (<v> @{@vm’=pj’},ij’) = (<v>,vm’)
  ->
  pj' = pi'
  ...
\end{verbatim}
if the index expressions \code{ii'} and \code{vm'} can be shown to evaluate to the same value.

Note that the original translation in Section~\ref{impl-ccode-cstats} never creates a \code{take} binding after a \code{put} binding, 
but postprocessing of Cogent expressions resulting from a sequence of C statements may result in such a sequence. The processing
described above results in a pattern which is similar to a ``\code{do-with}'' construct where a component is selected once and then
processed several times.

Both transformations for repeated access of the same component are applied in \code{tpelimproc} after eliminating single \code{take}
and \code{put} bindings.

\subsubsection{Converting take/put Pairs to \code{modify} Expressions}

\subsection{Introducing \code{getref}/\code{modref}}
\label{impl-post-ref}


\subsection{Combining the Steps}
\label{impl-post-combine}

Generally, the postprocessing steps recurse into the structure of the processed expression. Thus it would be possible to combine them
on every recursion level by combining the non-recursive steps to a common postprocessing function which recurses into the expression
structure. Alternatively each step recurses on its own and the overall simplification applies the steps sequentially to the toplevel
expressions.

Some steps depend on each other in a cyclic way. These are in particular the functions \code{evalproc}, \code{letproc}, and \code{ifproc}.
After \code{letproc} substitutes variables it may be possible to evaluate more expressions by \code{evalproc} than before. This may
allow additional simplifications by \code{ifproc} since conditions may evaluate to a constant. These simplifications may remove code parts 
with occurrences of free variables which in turn may allow additional simplification by \code{letproc}. Therefore these steps must 
be applied in a loop until the expression does not change any more.

The \code{letproc} step works bottom up and is applied to subexpressions before it is applied to an expression. The \code{ifproc} step 
for a subexpression will only benefit if variables are substituted from the context. Thus it does not help to iterate these steps for
the same subexpression. Instead, both steps recurse on their own and are iterated on the toplevel expressions.

The \code{evalproc} step is only used as auxiliary step in other postprocessing steps. Since the other steps recurse into the control
structures like \code{if} and \code{let}, it is not necessary for \code{evalproc} to do this. Therefore \code{evalproc} only recurses
into operator subexpressions.

The \code{opproc} step recurses into arbitrary subexpressions. It processes cases which are typically created by \code{ifproc}.
Therefore it is executed after every toplevel execution of \code{ifproc}.

The \code{tpproc} step depends on the explicit banging of variables of linear type which are used in a readonly way. That is done 
in the \code{funproc} step, therefore \code{tpproc} must be executed after \code{funproc}.
